{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"MAGICC Lab Public Wiki","text":"<p>Note</p> <p>This is the public-facing MAGICC Lab wiki. The private wiki is found here: https://github.com/byu-magicc/wiki-private</p> <p>You need to be logged into GitHub and be a member of the byu-magicc organization for this link to work.</p> <p>Attention! REQUIRED READING for all lab members: Safety</p> <p></p>"},{"location":"safety/","title":"MAGICC SAFETY","text":"<p>There is nothing magic about it.</p> <p>Attention! Please research responsibly.</p> <p>Note: MAGICC Safety is an individual and a community responsibility.</p>"},{"location":"safety/#general-overview","title":"General Overview","text":"<ul> <li>Be up to date on your department training</li> <li>If you get a feeling like something could go wrong, change the environment</li> <li>Be careful with UAV propellors as brushless motors are powerfull and those blades will easily cut you if you let them</li> <li>Be very careful with using and charging batteries: misuse could easily lead to electrocution, serious burns or a fire in the lab</li> <li>Wear safety glasses anytime you are near flying UAVs</li> <li>Check FAA restrictions before flying outdoors and always use a Part 107 certified safety pilot</li> </ul>"},{"location":"safety/#uav-safety","title":"UAV Safety","text":"<ul> <li>Never configure a flight controller with the ESCs powered on and with the propellers attached to the motors</li> <li>If you've plugging your flight controller into a computer, either make sure the ESCs do not have power or that the propellors have been removed</li> <li>We have had multiple incedents where motors turned on uncontrollably during what seemed like harmless configuration; don't assume what you're doing will be OK</li> </ul>"},{"location":"safety/#battery-safety","title":"Battery Safety","text":"<p>Attention!  There are two buckets of sand under the battery charging workbench. In case of a battery fire, dump sand on top of the flaming battery. Do not use water or a fire extinguisher on the flaming battery. Only use water or a fire-extinguisher on other objects that catch fire in the vicinity.</p> <ul> <li>Read, study, and internalize Battery Basics</li> <li>Read, study, and internalize the Battery Charging Guide</li> <li>Never cut the postive and negative wires of the battery at the same time (e.g. when replacing a connector)</li> <li>This could short circuit</li> <li>This could ruin the battery</li> <li>This could kill you \ud83d\ude35</li> <li>Do NOT leave a charging battery unattended</li> <li>Attended means you are physically present in the room</li> <li>Definitely do NOT leave a battery charging/discharging over night or even while you go to class</li> <li>If you need to leave, you must get someone else present in the lab to take full responsibility for you</li> <li>Do NOT leave a discharging battery unattended</li> <li>Do NOT leave a battery plugged into any device unattended</li> <li>This means both the cell voltage wires and the main power line should be unplugged from everything</li> <li>Close the lid of the metal charging tray case while your battery is connected to the charger</li> <li>Place one of the orange rocks in your pocket</li> <li>Last person to leave the lab:</li> <li>Check if any of the charge cases are closed and, if so, disconnect all batteries and open the cases</li> <li>If the battery will sit dormant for more than 2 or 3 days, place the battery cell voltages at storage voltage (see Battery Basics)</li> <li>Store batteries either in metal ammo boxes or in li-po battery bags</li> <li>Do not use the \"discharge\" function of the charger</li> <li>It zeroes out the voltage, ruining the battery</li> <li>It is meant for battery disposal - we rarely need this</li> </ul>"},{"location":"safety/#build-room","title":"Build Room","text":"<ul> <li>Keep work environment clean and uncluttered, even while you are using it</li> <li>You will be less likely to (a) burn yourself with a soldering iron, or (b) cut yourself with a blade</li> <li>You will be less likely to make a mistake</li> <li>Use the correct tool for the job</li> <li>Flathead screwdrivers should not be used with force in the direction of your hand - it is very easy to slip and the screwdriver will insert itself into your hand</li> <li>When cutting small components, use tweezers or pliers to hold that component so ~~you do not cut your hand~~ you reduce the risk of cutting your hand</li> <li>Do not cut anything harder than copper with the wire cutters, it will damage the cutter's blade (some cutters have the names of metals on which they can be used stamped into the cutter, so if it says it can be used with aluminum, then sure, use it on aluminum)</li> <li>Always cut away from your body or appendages and do not cut anything near another person</li> <li>If using lead solder, strongly consider arranging good ventilation - then, whatever the consideration results may be, arrange good ventilation regardless</li> <li>Safety glasses must be worn while soldering</li> <li>It has happened more than once that hot solder splashed into the eye of a student</li> <li>If you are next to a person soldering, you should also wear safety glasses - it will splash when you least expect it</li> <li>Safety glasses must be worn when using the wire cutters</li> <li>The cutters can fling a piece of what is being cut with enough force to damage your eye</li> <li>If you are using a saw or power tools of any kind, make sure that the material you are working on is securly fastened or clamped down</li> </ul>"},{"location":"safety/#vehicle-build-design","title":"Vehicle Build Design","text":"<ul> <li>Incorporate a physical disconnect switch between the battery and the ESC of your vehicle (search something like \"emergency safety power switch\" on the internet and see image below)</li> <li>Use a switch that is rated for the amount of current that will be drawn from your batteries to your motors.</li> <li>If not possible, reconsider your decisions and ask for ideas from neighbors on how it might become possible</li> <li>The switch only works if you use it - make it the last thing to be engaged, and the first thing to be disengaged<ul> <li>If the switch is disengaged first thing upon landing, the risk from the flight controller firmware accidentally being switched to \"armed\" (either due to a bug or accidentally bumping the \"arming\" switch on your transmitter) will be reduced, as the physical power to the motors will be cut off</li> </ul> </li> <li>If there is no physical disconnect switch to the motors, and you need to work on the on-board computer(s), power the computer with a different power source than the main-board battery</li> <li>We do not need anyone getting chopped up at their desk because they powered the motors while changing code on a flight computer</li> <li>Every time you flash new firmware to a flight controller, do so with it unplugged from motors</li> <li>Any time you re-attach a freshly-flashed flight controller to your vehicle, remove the propellers first</li> <li>Once your vehicle is powered, tilt the vehicle by hand, and make sure the MIXER is correct by checking each motor is spinning when it should, and in the correct direction - e.g. the lower motors should spin faster, attempting to make the vehicle level</li> <li>You can correct any disparities with the MIXER</li> <li>Double check the direction of the spin of each motor</li> <li>Mount the propellers back on, making sure the correct handed-ness of each propeller is properly matched to the correct spin direction of the motor</li> <li>Every time you re-wire your vehicle, double and triple check all connections are strong</li> <li>Loose connections could cause loss of control to the vehicle in the air as vibrations can shake wires loose and disconnect the flight controller</li> <li>Most ESCs will hold the most recent command if they lose connection to the flight controller, granted power from the battery continues to flow</li> <li>Make sure no bare power lines are electrifying your frame - even if there is a small gap between a bare wire and a metal or carbon frame, their is often enough voltage to jump that gap (this has happened even up to a \u00bd\" gap on a UAS in the lab)<ul> <li>Good wire insulation and isolation are paramount - you do not want to fry your onboard electronics, nor yourself</li> </ul> </li> <li>Get a safety inspection from the safety officer for all newly constructed aircraft, or aircraft that has had major design changes, especially changes to the electrical circuit</li> </ul>"},{"location":"safety/#flight-room","title":"Flight Room","text":"<ul> <li>Safety glasses must be worn whenever you are in the flight room while hardware is being used</li> <li>Put on the glasses before connecting a battery to the vehicle</li> <li>Make sure everyone else is wearing glasses before you connect the battery or else politely ask them to leave - just communicate</li> <li>The landscape can change quickly -- wear the safety glasses</li> <li>Make sure there is a trained safety pilot whenever the vehicle is armed</li> <li>The safety pilot's sole responsibility is to operate the transmitter, ready to take control</li> <li>Do not set the transmitter down to tune gains or watch plots - request a lab safety pilot's help (see lab roster)</li> <li>If your vehicle is powered and you need to move/touch it \u2192 wear the welding gloves!</li> <li>Or alternately, switch off your safety switch (using a stick, or the glove)</li> <li>Be familiar with how to use the fire extinguisher (most departments' new-hire training includes this and it is available on the Y-train website)</li> </ul>"},{"location":"safety/#outdoor-flights","title":"Outdoor Flights","text":""},{"location":"safety/#flight-preparation","title":"Flight Preparation","text":"<ul> <li>Transport all lab supplies, especially batteries, in appropriately protective containers</li> <li>If a battery gets punctured, it will blow up and burn everything around it to the ground</li> <li>If a battery gets dented, it could very likely blow up and burn everything around it to the ground</li> <li>Do not allow batteries to come in contact with small metal objects that could cause a short circuit</li> <li>Use pelican cases - we have plenty</li> <li>Inspect all components of the UAS for equipment damage or malfunctions before flight; look for the following:</li> <li>Loose or exposed cables and connections</li> <li>Missing or loose screws</li> <li>Structural cracking</li> <li>Indication of electrical burning</li> <li>Damage to the batteries</li> <li>Do not carry hazardous materials on an aircraft, including Lithium batteries that are not in use</li> <li>Bring a device to check the voltage on your batteries so that they do not run below 30%</li> <li>Completely discharging a battery will render it useless</li> <li>Ensure that your aircraft is registered with the FAA and marked with its registration number - marking should be visible and legible</li> <li>Ensure that your UAS weighs less than 55 lbs, including payload</li> </ul>"},{"location":"safety/#asses-the-operating-environment","title":"Asses the Operating Environment","text":"<ul> <li>Verify that you will not be in a restricted airspace - in general stay 5 miles away from airports unless you recieve proper authorization from the FAA</li> <li>Choose a location that is sparsely poplulated - avoid areas with high traffic, pedestrians or property that could be damaged</li> <li>Check the weather for rain, snow, or fog</li> <li>Ensure that you have visiblity up to 3 statute miles from the control station</li> <li>Be aware of wind curents</li> <li>Obstructions or buildings may affect the flow of wind and may create rapidly changing wind gusts</li> <li>Plowed grounds, rocks, sand, and barren land may result in updrafts</li> <li>Water, trees, and other areas of vegetation can cause downdrafts</li> <li>Note that flying in high winds will likely consume more battery power</li> </ul>"},{"location":"safety/#flight-rules","title":"Flight Rules","text":"<ul> <li>Any outdoor lab related flights must be performed under supervision of someone with a 14 CFR part 107 license</li> <li>The remote pilot must carry thier remote pilot certificate and personal ID when supervising</li> <li>Have a trained safety pilot anytime the vehicle is armed ready to take control of the vehicle</li> <li>Do not fly your aircraft faster than 100 mph</li> <li>Do not fly higher than 400 ft above ground level - if you are within a 400 ft radius of a structure you may fly 400 ft above the tallest point of that structure</li> <li>Stay 500 ft below the clouds, and 2,000 ft horizontally away from clouds</li> <li>Keep aircraft within visual line-of-sight</li> <li>This means you are capable of determining its location, altitutde, attitude, and direction of travel without the aid of binoculors or other devices</li> <li>Do not fly an aircraft over another person unless that person is directly involved in the operation</li> <li>Do not engage in sustained flight over moving vehicles</li> <li>Do not operate an aircraft if you are impaired in any way, including impairment due to medication</li> </ul>"},{"location":"safety/#flying-at-night","title":"Flying at Night","text":"<p>The following rules apply anytime after sunset or before sunrise:</p> <ul> <li>The operating area should be surveyed during daylight hours to identify possible obstacles</li> <li>The UAS is equipped with anti-collision lights that are capable of being visible for at least 3 statue miles and have a flash rate sufficient to avoid collision</li> <li>There must be a visual observer designated to scan for other aircraft</li> <li>A night landing area is established that is dimly illuminated</li> </ul>"},{"location":"administration/conference_room_schedule/","title":"Scheduling the MAGICC Lab Conference Room (EB 146a)","text":"Reserve Now"},{"location":"administration/conference_room_schedule/#calendar-preview","title":"Calendar Preview","text":""},{"location":"administration/getting_started_in_research/","title":"Getting Started in Research","text":"Research Advice Dennis Bernstein, University of Michigan. An excellent description of the challenges of doing research, with advice on doing it right. More Advice 1 Article shared by Dr. McLain on what makes great research and how to pick a topic More Advice 2 Martin A. Schwarz, University of Virginia. The importance of stupidity in scientific research. Peer Review 1 Dennis Bernstein, University of Michigan. Eleven questions to ask when reviewing a paper. Peer Review 2 Alan Meier, University of California at Berkeley. How to review a technical paper. Mendeley Great cross-platform program (free!) to manage the papers you read and cite. (It also gives you space in the Cloud to store all of your pdf paper files)"},{"location":"administration/getting_started_in_research/#help-with-writing","title":"Help with Writing","text":"<ul> <li>BYU Writing Center</li> <li>Hints on Writing Technical Papers and Making Presentations Victor O.K. Li</li> <li>Publish or Perish: It's Not Just for Academics Anymore Harlan Howe Jr.</li> <li>Whats wrong with these equations N. David Mermin</li> <li>Getting started in LaTex</li> <li>Latex Beamer Presentation Template (So long PowerPoint!)</li> </ul>"},{"location":"administration/getting_started_in_research/#control-curriculum-at-byu","title":"Control Curriculum at BYU","text":""},{"location":"administration/new_member_tips/","title":"Tips on how to be a great lab member","text":""},{"location":"administration/new_member_tips/#research","title":"Research","text":"<ul> <li> <p>Richard Hamming (of the window): You and Your Research</p> </li> <li> <p>A Student's Guide to Peer Review</p> </li> </ul>"},{"location":"computers/headless/","title":"Headless vs Graphical Linux","text":"<p>When running your robot in hardware demonstrations and data gathering sessions, it is advantageous to run your companion computer in a headless (or text-based) mode with no Desktop Environment. This will save on resources like CPU and RAM, giving your algorithms slightly more computational power.</p> <p>To do this, we will use <code>systemctl</code> commands. For a brief overview of <code>systemctl</code>, read the Startup Scripts with systemd article.</p>"},{"location":"computers/headless/#making-headless-the-default-configuration","title":"Making Headless the Default Configuration","text":"<p>We will make the non-graphical boot the default configuration so that there is very little to do in the field. To change the default run the following commands</p> <pre><code>$ sudo systemctl set-default -f multi-user.target\n</code></pre> <p>Double-check by running</p> <pre><code>$ sudo systemctl get-default\n</code></pre> <p>You can change into the ''multi-user'' target by rebooting or running the following command</p> <pre><code>$ sudo systemctl enable multi-user.target\n</code></pre> <p>Note that on a reboot, if you have your computer connected to a monitor it will show the output of a form of <code>dmesg</code>. To get to a login screen you must change tty by using <code>Ctrl+Alt+F1</code>.</p>"},{"location":"computers/headless/#starting-the-graphical-environment-from-headless","title":"Starting the Graphical Environment from Headless","text":"<p>To get back into a graphical desktop environment, run the following command</p> <pre><code>$ sudo systemctl enable graphical.target\n</code></pre> <p>You can always switch back to having graphical boot being the default with</p> <pre><code>$ sudo systemctl set-default -f graphical.target\n</code></pre>"},{"location":"computers/headless/#resources","title":"Resources","text":"<ul> <li>Non-graphical boot with systemd</li> </ul>"},{"location":"computers/jetson/","title":"NVIDIA Jetson TX2","text":""},{"location":"computers/jetson/#setup","title":"Setup","text":"<p>When you unbox an NVIDIA Jetson TX2, it will come pre-flashed with Linux4Tegra (27.1, at the time of this writing). However none of the libraries/tools will be installed (i.e., CUDA, cuDNN, etc). Install JetPack 4.2.x on a host machine running (vanilla) Ubuntu 18.04. (You can attempt this process on other distributions or version numbers, but there are no guarantees of a working setup. We've got it running on Ubuntu Budgie 18.04, but it is finicky.)</p>"},{"location":"computers/jetson/#software-overview","title":"Software Overview","text":""},{"location":"computers/jetson/#jetpack","title":"JetPack","text":"<p>JetPack is the Jetson SDK that is installed on the Host machine to push libraries and an OS image onto the TX2.</p>"},{"location":"computers/jetson/#linux4tegra-l4t","title":"Linux4Tegra (L4T)","text":"<p>Linux with a kernel that has been patched specifically for Tegra devices.</p>"},{"location":"computers/jetson/#opencv4tegra","title":"OpenCV4Tegra","text":"<p>A Tegra CPU-optimized closed-sourced version of OpenCV. It is not CUDA-enabled (which seems rather silly...).</p>"},{"location":"computers/jetson/#cuda-enabled-opencv","title":"CUDA-Enabled OpenCV","text":"<p>See the installation instructions here.</p>"},{"location":"computers/jetson/#ros-melodic","title":"ROS Melodic","text":"<p>We have not had certificate issues on JetPack 4.2.x, so we recommend following the general install procedure on the ROS website.</p> <p>If you are interested and/or have issues, Jetson Hacks has a nice (albeit outdated) article illustrating how to install ROS on the TX2. Their <code>installROS.sh</code> script available in their repo is essentially the standard ROS installation procedure, just with an extra line that can fix supposedly messed up certificates.</p>"},{"location":"computers/jetson/#host-computer","title":"Host Computer","text":"<p>The host computer is the machine on which you install JetPack and which you use to flash the OS image and other libraries to the TX2. Although it is possible to run JetPack on Ubuntu 'Flavors,' e.g. Ubuntu Budgie, there are some weird quirks in the installation procedure. It is much easier if you use 'vanilla' Ubuntu 18.04 with JetPack 4.2.x.</p> <p>The following is a legacy issue that has not been encountered on JetPack 4.2.x. We leave the instructions here for edge cases that might crop up:</p> <p>You may find your host computer's <code>apt</code> package manager is doing weird things after you install JetPack and setup a TX2. If you find that <code>sudo apt update</code> leaves you with the following errors:</p> <pre><code>Reading package lists... Done\nN: Skipping acquire of configured file 'non-free/binary-arm64/Packages' as repository 'http://repository.spotify.com stable InRelease' doesn't support architecture 'arm64'\nN: Skipping acquire of configured file 'main/binary-arm64/Packages' as repository 'https://desktop-download.mendeley.com/download/apt stable InRelease' doesn't support architecture 'arm64'\nE: Failed to fetch http://us.archive.ubuntu.com/ubuntu/dists/xenial/main/binary-arm64/Packages  404  Not Found [IP: 91.189.91.26 80]\nE: Failed to fetch http://us.archive.ubuntu.com/ubuntu/dists/xenial-updates/main/binary-arm64/Packages  404  Not Found [IP: 91.189.91.26 80]\nE: Failed to fetch http://us.archive.ubuntu.com/ubuntu/dists/xenial-backports/main/binary-arm64/Packages  404  Not Found [IP: 91.189.91.26 80]\nE: Failed to fetch http://security.ubuntu.com/ubuntu/dists/xenial-security/main/binary-arm64/Packages  404  Not Found [IP: 91.189.88.152 80]\nE: Some index files failed to download. They have been ignored, or old ones used instead.\n</code></pre> <p>then the following workaround (found here) can be applied. Essentially, it seems that the installation of JetPack has opened <code>apt</code> to looking for some arm64 packages. However, your host machine is (likely) an x86_64 (AKA, amd64) architecture. To disable <code>apt</code> from looking for arm64 versions of standard Ubuntu packages, edit the <code>/etc/apt/sources.list</code> (and possibly others in the <code>/etc/apt/sources.list.d</code> directory) to be limited to amd64 as follows:</p> <pre><code>deb [arch=amd64] &lt;url&gt;\n</code></pre>"},{"location":"computers/jetson/#carrier-board-connecttech-orbitty","title":"Carrier Board: ConnectTech Orbitty","text":"<p>The Orbitty is fully compatible with both the TX1 and the TX2. See the compatibility report here.</p> <p>To use the Orbitty with the TX2, you will have to install COnnectTech Inc's (CTI) board support package (BSP), which is called CTI-L4T. \u2190 Read the whole thing! It has links to answer questions. At the time of this writing, CTI-L4T-V126 has been installed on the TX2/Orbitty successfully. Note that upon installing the BSP for your specific carrier board, the TX2 will not boot on other carrier boards, including the dev kit.</p> <p>To install CTI-L4T, you can follow the instructions, or walk through the steps laid out in the next subsection. You can read through the flow on the instructions web-page, but we have extensively tested the steps in this document, so probably just follow them. The installation steps below have been completed successfully using an Ubuntu 18.04 x86_64 host machine. To then install CUDA and the other packages that JetPack normally installs on the target Jetson TX2, run the Nvidia SDKManager again. On the STEP 01: Development Environment screen, uncheck \"Host Machine\" and change \"Target Hardware\" to \"Jetson TX2 (P3310),\" or whatever your applicable hardware is. The next screen is STEP 02: Details and License. Under Target Components, uncheck Jetson OS. This will prevent JetPack from overwriting the BSP changes, while still allowing JetPack to actually push CTI-L4T and any other components (like CUDA) under the Jetson SDK components section over to the TX2 device.</p> <p>Some have asked why we uncheck \"Host Machine\". It just installs a bunch of software (CUDA, Computer Vision {opencv?}, &amp; Developer Tools) that you probably do not need on your host machine. Their versions of CUDA and OpenCV probably are not the ones you want (see our versions: CUDA, OpenCV), and I would venture to bet you are not developing for Nvidia. If you are still curious, Google what exact software and their versions are included. IMHO, if I do not need it to successfully install software on the TX2, I do not need their automated versions clogging up my host machine resources with background processes. and stomping on my own carefully installed versions of libraries.</p>"},{"location":"computers/jetson/#instructions-start-to-finish","title":"Instructions: Start to Finish","text":"<p>If you have the Jetson TX2 on a Developer Kit, you will need a T-10H Security Torx screw bit to remove the TX2 from the dev kit (or a small flat head, just do not bend the screwdriver).</p> <ol> <li> <p>Connect the TX2 to the Orbitty.</p> </li> <li> <p>Install the dependencies for the Nvidia SDK Manager: <code>sudo apt install libgconf-2-4</code></p> </li> <li> <p>Download the Nvidia SDK Manager. This will allow you to select and download your targeted version of JetPack (e.g. 4.2.2).</p> </li> <li> <p>Download the Orbitty CTI-L4T BSP (e.g. CTI-L4T-V126.tgz). Make sure that the BSP from CTI plays nicely with your chosen JetPack from NVIDIA. For example, JetPack 4.2.2 ships L4T 32.2.1 for the TX2, so get the CTI-L4T BSP targeting that release of L4T, and make sure it supports the Orbitty. Some CTI-L4T releases only support a small subset of CTI carrier boards. Check compatibility using the release notes and download page links above. More information is available here.</p> </li> <li> <p>Run SDKManager, but only to download the files</p> </li> <li>Under STEP 01: Development Environment<ul> <li>Uncheck \"Host Machine\"</li> <li>Select your correct \"Target Hardware\" (e.g. \"Jetson TX2 (P3310)\")</li> <li>Select your target JetPack Version (e.g. JetPack 4.2.2)</li> </ul> </li> <li> <p>Under STEP 02: Details and License</p> <ul> <li>Leave \"Jetson OS\" checked</li> <li>Uncheck \"Jetson SDK Components\" &amp; \"Additional SDKs\"</li> <li>Under the \"Download &amp; Install Options\" drop-down menu, change both \"Download folder\" and \"Target HW image folder\" options to easily accessible, and JetPack version unique, locations (e.g. <code>~/jetson422/sdkm_downloads</code> and <code>~/jetson422/nvidia_sdk</code>)</li> <li>Accept the Terms &amp; Conditions</li> <li>Continue to Step 03</li> <li>After the download completes, the installation screen will appear (where it asks how the TX2 is connected)</li> <li>Cancel the JetPack setup here</li> </ul> </li> <li> <p>Make sure the TX2 is plugged into power</p> </li> <li> <p>Place the TX2 in recovery mode</p> <ul> <li>Connect a micro usb 2.0 cable between the Orbitty Carrier board and your Host machine</li> <li>Press &amp; hold the \"Recovery\" button</li> <li>Press &amp; release the \"Reset\" button</li> <li>Release the \"Recovery\" button</li> </ul> </li> <li> <p>Now that JetPack has pulled the relevant OS files to your local host machine, we need to patch the L4T kernel with driver support for the Orbitty carrier board using the CTI-L4T-V1xx BSP. The instructions are found here. You must follow the Manual Flashing instructions because the automatic script fails to flash the image (most times, but you can try if you like). Now, read the bright-orange \"Attention box.\" These instructions will actually build the patched OS image and flash it to the internal eMMC on the TX2.</p> <p>Attention: When you are ready to call the <code>./flash.sh &lt;profile&gt; mmcblk0p1</code> command as instructed in the Manual Flashing commands from the CTI instruction page, as of JetPack 4.2.2, you first need to run <code>sudo ./flash.sh ./cti/tx2/orbitty mmcblk0p1</code>. This will likely also fail, stalling with print statements in the terminal similar to: <pre><code>...\n[   4.3455 ] Boot Rom communication\n[   4.3463 ] tegrarcm_v2 --chip 0x18 0 --rcm rcm_list_signed.xml\n[   4.3469 ] BootRom is not running\n[   9.6155 ]\n[  10.6191 ] tegrarcm_v2 --isapplet\n[ 1020.5594 ]\n[ 1020.5768 ] tegradevflash_v2 --iscpubl\n[ 1020.5780 ] CPU Bootloader is not running on device.\n[ 2036.3675 ]\n[ 2037.3711 ] tegrarcm_v2 --isapplet\n[ 3052.1754 ]\n[ 3052.1779 ] tegradevflash_v2 --iscpubl\n[ 3052.1801 ] CPU Bootloader is not running on device.\n[ 4067.9835 ]\n[ 4068.9871 ] tegrarcm_v2 --isapplet\n...\n</code></pre> (If it does not fail/stall, you will see something like the following, and you may skip the rest of this block): <pre><code>...\n[   0.3570 ] Copying signatures\n[   0.3576 ] tegrahost_v2 --chip 0x18 0 --partitionlayout flash.xml.bin --updatesig images_list_signed.xml\n[   0.4085 ]\n[   0.4086 ] Boot Rom communication\n[   0.4097 ] tegrarcm_v2 --chip 0x18 0 --rcm rcm_list_signed.xml\n[   0.4104 ] BootRom is not running\n[   5.4682 ]\n[   6.4715 ] tegrarcm_v2 --isapplet\n[   6.4736 ] Applet version 01.00.0000\n[   6.4761 ]\n[   6.4762 ] Sending BCTs\n[   6.4784 ] tegrarcm_v2 --download bct_bootrom br_bct_BR.bct --download bct_mb1 mb1_bct_MB1_sigheader.bct.encrypt\n[   6.4792 ] Applet version 01.00.0000\n[   6.4814 ] Sending bct_bootrom\n[   6.4815 ] [................................................] 100%\n[   6.4830 ] Sending bct_mb1\n[   6.4841 ] [................................................] 100%\n[   6.5002 ]\n[   6.5002 ] Generating blob\n...\n</code></pre> Obviously you do not have to wait 4000 seconds to know it has stalled; I ran it this long for illustration. Best practice is to wait at least 90 seconds before determining it has stalled. If it does stall at the <code>tegrarcm_v2 --isapplet</code> print statement, check the printout history for something like: <pre><code>...\n4354: RAW:     6275072(   1532 blks) ==&gt;  4231167028:6275084\n4355: SKP:        4096(      1 blks) ==&gt;  4237442112:12\n4356: RAW:       81920(     20 blks) ==&gt;  4237442124:81932\n4357: SKP:  1935671296( 472576 blks) ==&gt;  4237524056:12\n-- Total: ---------------------------------------------------\n4358 CHUNK 30064771072(7340032 blks) ==&gt;  4237524068(1034539 blks)\n\ndone.\nsystem.img built successfully.\n...\n</code></pre> If you see similar lines, you may quit the stalled command with <code>CTRL + C</code>. (If you do not see them, I hope you said your morning prayers. Also, go get some help.) Next, run <code>sudo ./flash.sh -r ./cti/tx2/orbitty mmcblk0p1</code>. Note the <code>-r</code>! It is different than above. This will use the pre-built image from the previous install attempt, instead of building a new one. This allows the <code>flash.sh</code> script to start sending the image before the pseudo-network between the host and TX2 times out. If it fails to flash, on the Orbitty, try: (a) press &amp; hold the \"Recovery\" button, (b) press &amp; release the \"Reset\" button \u00a9 release the \"Recovery\" button a maximum of 0.3 seconds before pressing enter to run the flash command in the terminal. Because <code>sudo</code> is required for the flash command, first run a generic <code>sudo update</code> so the <code>sudo ./flash.sh ...</code> command does not pause waiting for your admin password. This also helps the pseudo-network timing.</p> </li> <li> <p>Now that Linux is actually flashed on the TX2, unplug the USB cable, press the \"Reset\" button on the Orbitty, and the TX2 should boot up into the Linux config screen. Accept the license, select a username, computer hostname, and password, and finish the setup process.</p> <p>Note: It may appear to hang during this process (specifically at a \"waiting for unattended upgrade...\" dialog box). Leave it be for at least an hour, if not overnight. It is not actually frozen. If you want a way to avoid waiting, you need to turn off \"unattended upgrades\" by patching a file in the <code>rootfs/etc/apt</code> directory in the Jetson system image source files on the host system before running the flash utility on the command line the final time. If you do not know what that means, just be patient and let it flash normally. You can really screw up your image if you do not know what your doing in this process.</p> </li> <li> <p>Reboot the TX2.</p> </li> <li> <p>Plug the micro USB cable back into the TX2.</p> </li> <li> <p>Start \"SDK Manager\" again, on the host machine.</p> </li> <li> <p>Make sure not to overwrite the OS image on the STEP 02 screen by un-checking Jetson OS, but leave the Jetson SDK components &amp; Additional SDKs checked.</p> </li> <li> <p>Press Continue to STEP 03, and follow the on screen instructions, entering first the Host machine password, then the username and password you configured for the TX2. JetPack should start copying the relevant packages (CUDA, etc) over to the TX2 and installing them. This can take a while. Go get a coffee.</p> <p>Note: If it fails, shut everything off, disconnect power, and boot everything back up, and try the SDKs again. It has happened once that I needed to re-flash the OS image a second time before the SDKs would successfully install.</p> </li> <li> <p>Make it \"Headless\" to save resources when flying. Follow the instructions here.</p> </li> <li> <p>You're all done!</p> </li> </ol> <p></p>"},{"location":"computers/jetson/#clocks-and-such","title":"Clocks and Such","text":""},{"location":"computers/jetson/#power-profiles-nvpmodel","title":"Power Profiles: <code>nvpmodel</code>","text":"<p>The Jetson TX2 has 5 power profiles that can be set with the following. You may also want to include the <code>jetson_clocks</code> command:</p> <pre><code>$ sudo nvpmodel -m [mode]\n$ sudo jetson_clocks\n</code></pre> <p>To see which mode is currently being used, run</p> <pre><code>$ sudo nvpmodel -q\n</code></pre> <p>You will probably want the highest power mode, using all available cores on the TX2.:</p> <pre><code>$ sudo nvpmodel -m 0\n$ sudo jetson_clocks\n</code></pre> <p>Good info on the NVIDIA Power Model (nvpmodel): JetsonHacks - nvpmodel.</p> <p>The following information is applicable to JetPack &lt;= 4.2.1, as far as I can tell. Using JetPack 4.2.2, if you set the nvpmodel once, your selected setting is persistent across a power cycle. If you are using Wi-Fi, instead of an Ubiquiti Bullet, you will still likely need to create the systemd service to turn off power saving on the Wi-Fi, but this is untested.</p> <p>It is advantageous to run this command on boot. You can do this with a <code>systemd service</code> file. First, create a <code>jetson-max-power.sh</code> file with execute permissions. (For security, it is recommended to place it in a directory owned by root, such as <code>/etc/&lt;max_power.d&gt;/jetson-max-power.sh</code>. Personally, I just place it at <code>~/software/jetson-max-power.sh</code>.) Wherever you place the <code>*.sh</code> script, make sure the <code>ExecStart</code> line in the <code>*.service</code> file points to it.</p> <p>The <code>*.service</code> and <code>*.sh</code> files are available on the MAGICC GitHub. Place the <code>*.service</code> file at <code>/etc/systemd/system/jetson-max-power.service</code>, and enable with <code>sudo systemctl enable jetson-max-power.service</code>.</p> <p>NOTE: CRITICAL     Be sure to fix any relevant paths in these two files before enabling the systemd service. If you have already enabled, and need to change the <code>*.service</code> file, you will need to either reboot, or run <code>sudo systemctl daemon-reload</code>.</p>"},{"location":"computers/jetson/#wifi-and-connectivity","title":"WiFi and Connectivity","text":"<p>The Jetson TX2 comes with embedded Wi-Fi/bluetooth. The dev kit comes with two antennas. The TX2 Wi-Fi can run with just 1 antenna connected to J9, which is the U.FL connector furthest from the S/N sticker. (See here.) The other U.FL connector is for Bluetooth.</p> <p>If you are only going to use a Ubiquiti Bullet hard-wired to the Orbitty ethernet port (this is highly recommended for MAGICC Lab Vehicles! see Lab Standard HW/SW Setup), we suggest disabling the Wi-Fi in the gui, or alternatively hard-blocking the wireless card with <code>rfkill</code>.</p> <p>You can view the Wi-Fi RSSI/link quality with the following command (with or without the <code>watch -n 0.1</code>):</p> <pre><code>$ watch -n 0.1 iw dev wlan0 link\n</code></pre> <p>It has also been noted that the RF chip has a power-saving feature which could introduce lag (see here). It can be turned off with:</p> <pre><code>$ sudo iw dev wlan0 set power_save off #- to disable power save and reduce ping latency.\n</code></pre> <p>You can add this line to the <code>.sh</code> script called by <code>jetson-max-power.service</code>. If you downloaded the file available on the GitLab server, it is already included. You're welcome. :)</p>"},{"location":"computers/jetson/#usb-devices","title":"USB Devices","text":"<p>Note! Update     As of JetPack 4.2.x, the following drivers are all included in the kernel by default. This information is left here for legacy use cases.</p> <p>Original Content</p> <p>It is likely that your USB devices do not work correctly out of the box with the TX2. This is especially the case for a flip32 board for ROSflight. To fix this you need to build some drivers in with the kernel. This process is pretty straight-forward.</p> <p>To build the kernel with additional USB drivers, follow the instructions and video found here. This video shows the ACM module being added, however there are a few additional drivers you will likely require. These include: - USB Winchiphead CH341 Single Port Serial Driver - USB Modem (CDC ACM) support - USB CP210x family of UART Bridge Controllers</p> <p>After following the instructions to add these drivers, reboot your TX2 and your USB devices should show up in /dev/ttyUSB? or /dev/ttyACM? as you would expect.</p> <p>Update: With Jetpack 3.2 and L4T 28.2, ttyACM devices appear to work out of the box, but you may still need to follow the above instructions if your device doesn't work. Also, please note that there is an updated video for building the kernel for L4T 28.2.</p>"},{"location":"computers/jetson/#cloning","title":"Cloning","text":"<p>Warning!     The following commands and information has not been tested on L4T 32.x.x as installed by using the JetPack 4.2.x software. Use at your own peril.</p> <p>The following commands only clone the OS partition, and do not affect the bootloader, so it is recommended that you first set up your new TX2 with the above instructions if you are going to be using an Orbity or other carrier board. Once both TX2's have the same bootloader, you can follow these steps for cloning derived from this guide.</p> <p>First, make sure you have at least 50GB of free space on the volume where you have Jetpack installed. cd into the directory containing the L4T installation package on the host PC. The command below will save the TX2's eMMC image to the specified file on the host.</p> <pre><code>$ sudo ./flash.sh -r -k APP -G backup.img jetson-tx2 mmcblk0p1\n</code></pre> <p>In this case, we call the file backup.img, so the same flash.sh script can be re-used to format and flash other Jetson's with the image. Copy the .raw file which containts the image of the OS partition to where the flashing script can find it. You may want to backup the vanilla image already in the bootloader directory.</p> <pre><code>$ sudo cp backup.img.raw bootloader/system.img\n</code></pre> <p>The recommended way to restore multiple units with different serial numbers is to save the image above as \"system.img\" and use the head L4T flashing script, flash.sh, with the -r option (to reuse your backed-up system.img without rebuilding the vanilla image from scratch):</p> <pre><code>$ sudo ./flash.sh -r -k APP jetson-tx2 mmcblk0p1\n</code></pre>"},{"location":"computers/jetson/#intel-realsense-d400-series","title":"Intel Realsense D400 Series","text":"<p>Below are some guides to help you get started using the Intel Realsense D400 series cameras on the TX2. (Some of this may be out-of-date, likely targeting L4T 28.x.x and below):</p> <ul> <li>First and foremost, our own wiki page: Intel RealSense D400 Camera</li> <li>Intel RealSense Camera Installation \u2013 NVIDIA Jetson TX2</li> <li>Github jetsonhacks/buildLibrealsense2TX</li> <li>Intel RealSense Package for ROS on NVIDIA Jetson TX2</li> </ul>"},{"location":"computers/jetson/#sources-and-drivers","title":"Sources and Drivers","text":"<p>For JetPack &gt;=4.2.x: Sources: https://developer.nvidia.com/embedded/dlc/l4t-jetson-driver-package-32-1-JAX-TX2 Drivers: https://developer.nvidia.com/embedded/dlc/l4t-sources-32-1-JAX-TX2</p> <p>For JetPack &lt;4.2.x: Sources: https://developer.nvidia.com/embedded/dlc/l4t-jetson-driver-package-28-3-tx2 Drivers: https://developer.nvidia.com/embedded/dlc/l4t-sources-28-3-tx2</p>"},{"location":"computers/pixhawk/","title":"Pixhawk","text":"<p>This page describes how to set up a Pixhawk autopilot for hardware research purposes in the lab.</p> <p>In addition to this page, there is also an excellent guide written by a former lab member here.</p>"},{"location":"computers/pixhawk/#pixhawk-hardware","title":"Pixhawk Hardware","text":"<p>The original Pixhawk hardware was open-source, and since then, many flavors of Pixhawk hardware have become available on the market. In the lab we have experience using the original 3DR Pixhawk (no longer manufactured), and the Pixhawk 2.1/The Cube (this is the hardware we currently recommend). Full lists of supported hardware for both PX4 and APM firmware versions can be found here and here.</p> <p></p>"},{"location":"computers/pixhawk/#pixhawk-setup","title":"Pixhawk Setup","text":"<p>The following sections describe the steps needed to configure the Pixhawk itself so that it is ready to fly the vehicle, stream sensor data, and accept offboard control commands.</p>"},{"location":"computers/pixhawk/#firmware-versions","title":"Firmware Versions","text":"<p>The Pixhawk hardware is typically used with either APM or PX4 firmware. Both firmware versions give the Pixhawk full autopilot capabilites, but there are some pros and cons to each.</p> <p>The PX4 flight stack is more geared toward researchers and allows streaming of vehicle state data at high rate (50+ Hz). We however only recommend using PX4 for multirotor-type aircraft as their fixed-wing development is not well documented.</p> <p>The APM flight stack is more popular with commerical companies and hobbyists. It is very stable and thoroughly tested. Some have also noted that APM is easier to tune for large multirotor-type aircraft than PX4. If you are using Pixahawk for fixed-wing, then you should opt to use APM. The most significant drawback to APM is that it provides its internal state data at a much lower rate (10-20 Hz).</p>"},{"location":"computers/pixhawk/#px4-setup","title":"PX4 Setup","text":"<p>PX4 for multirotors is well-documented and you should follow their setup and configuration guides. The main setup guide can be found at https://docs.px4.io/en/. A guide for developers and lower-level interfacing with PX4 can be found here https://dev.px4.io/en/. In order to set parameters and configure PX4 for your research, you will need to install the Ground Control Station (GCS) QGroundControl. A guide for installing QGroundControl can be found here https://docs.qgroundcontrol.com/en/.</p>"},{"location":"computers/pixhawk/#flight-parameters","title":"Flight Parameters","text":"<p>Follow the user guide to tune the PID loops of your multirotor with a safety pilot at the controls. Once the vehicle is tuned connect your vehicle to QGroundControl and navigate to the 'Parameters' -&gt; 'Multicopter Position Control' sub-menu. We recommend that you set the following parameters to give more docile, research-friendly flight during Auto and Offboard mode operations.</p> Parameter Recommended Value MPC_ACC_DOWN_MAX 5.0 MPC_ACC_HOR 2.0 MPC_ACC_HOR_MAX 5.0 MPC_ACC_UP_MAX 5.0 MPC_CRUISE_90 2.0 MPC_MAN_TILT_MAX 25.0 MPC_TILTMAX_AIR 25.0 MPC_TILTMAX_LND 10.0 MPC_XY_CRUISE 3.0 MPC_XY_VEL_MAX 5.0"},{"location":"computers/pixhawk/#startup-script","title":"Startup Script","text":"<p>If you are using PX4, a startup script can be placed on the Pixhawk's SD card and allows you to configure the rates that certain internal data streams (e.g., position, attitude) are made available. To add a startup script, create a folder called <code>etc</code> on the main level of the SD card. After creating the folder, create a file called <code>extras.txt</code> and place it in the <code>etc</code> folder. Now the next time PX4 boots up, this script will be read and the stream rates that you set will be setup. If you are using MAVROS, you can use <code>rostopic hz /mavros/local_position/pose</code> to verify that the rates you set in your <code>extras.txt</code> file have been applied. An example <code>extras.txt</code> file that has been used in the lab is given below:</p> <pre><code>leep 100000\n#start mavlink custom stream on telem2 (/dev/ttyS2 internally)\n# with 921600 and ftp enabled (-x)\nmavlink start -m custom -d /dev/ttyS2 -b 921600 -x\nusleep 100000\nmavlink stream -d /dev/ttyS2 -s HEARTBEAT -r 5\nusleep 100000\nmavlink stream -d /dev/ttyS2 -s STATUSTEXT -r 1\nusleep 100000\nmavlink stream -d /dev/ttyS2 -s SYS_STATUS -r 1\nusleep 100000\nmavlink stream -d /dev/ttyS2 -s PARAM_VALUE -r 5\nusleep 100000\nmavlink stream -d /dev/ttyS2 -s HIGHRES_IMU -r 100\nusleep 100000\nmavlink stream -d /dev/ttyS2 -s ATTITTUDE -r 60\nusleep 100000\nmavlink stream -d /dev/ttyS2 -s ATTITUDE_QUATERNION -r 60\nusleep 100000\nmavlink stream -d /dev/ttyS2 -s VFR_HUD -r 10\nusleep 100000\n#mavlink stream -d /dev/ttyS2 -s GPS_RAW_INT -r 5\n#usleep 100000\nmavlink stream -d /dev/ttyS2 -s GLOBAL_POSITION_INT -r 5\nusleep 100000\nmavlink stream -d /dev/ttyS2 -s LOCAL_POSITION_NED -r 60\nusleep 100000\nmavlink stream -d /dev/ttyS2 -s HOME_POSITION -r 5\n</code></pre> <p>Notice here that attitude and position data have been set to stream at 60 Hz over the Pixhawk's Telem2 port. Some have reported in the PX4 Issues section on GitHub that attitude data can be set to stream at up to 250 Hz. Keep in mind however that there is limited bandwidth on the serial port. Only set stream rates as high as you need, and realize that if you are also sending high-rate commands to the PX4, this also takes up bandwidth.</p>"},{"location":"computers/pixhawk/#apm-setup","title":"APM Setup","text":"<p>Documentation for APM can be found here.</p>"},{"location":"computers/pixhawk/#connection-to-a-companion-computer","title":"Connection to a Companion Computer","text":"<p>If you are using Pixhawk for research purposes, you will likely wish to send commands and process vehicle state data via a connection to an on-board companion computer (OBC). Documentation for companion computer setup can be found here for PX4, or here for APM. In both cases, you will setup a physical serial connection between the Telem2 port of the Pixhawk, and your OBC (e.g., Jetson TX2, Odroid XU4, Brix i7, RaspberryPi).</p>"},{"location":"computers/pixhawk/#using-an-ftdi-cable","title":"Using an FTDI Cable","text":"<p>You can use an FTDI cable to connect the TELEM2 on the Pixhawk to one of your OBC's USB ports. Use a 3.3V FTDI cable (3.3V I/O, 5V supply). The following table summarizes the connections to make (connect the TELEM2 pin in the left column to the FTDI pin or wire in the right column). Do not connect VCC (pin 1 on Pixhawk TELEM2 port, pin 3/red wire on FTDI cable). To know which pin is which, be sure to refer to the Telem2 pinout of your Pixhawk hardware, and the pinout of your FTDI device.</p> Telem2 FTDI TX RX RX TX CTS CTS RTS RTS GRD GRD"},{"location":"computers/pixhawk/#direct-uart-connection","title":"Direct UART Connection","text":"<p>If your OBC has an auxilary UART serial port that is made readily available (e.g., Raspberry Pi, TX2 with Orbitty Carrier board), then you can save yourself from using up a USB port, and conect the Telem2 port of the Pixhawk directly to the UART pins of your OBC using just 3 wires. When possible, we recommend connecting your Pixhawk and OBC in this way because it saves weight, allows you to use your USB port(s) for other things like cameras, and the phisical connection is typically more reliable (USB ports can wiggle loose in flight). Refer to the pinout of your Pixhaw hardware's Telem2 port and the pinout of your OBC's UART, and then connect the pins as shown in the following table (connect the Telem2 pin in the left column, to the UART pin in the right column).</p> Telem2 UART TX RX RX TX GRD GRD <p>If you are using the Pixhawk 2.1 with the Jetson TX2 and the Orbitty carrier board, you may refer to the pinout pictured below:</p> <p></p>"},{"location":"computers/pixhawk/#ros-overview","title":"ROS Overview","text":""},{"location":"computers/pixhawk/#mavros","title":"MAVROS","text":"<p>MAVROS is a widely used ROS package for communicating with Pixhawk and other MAVLink hardware. It can be thought of as a two-way communications bridge between your on-board computer and the Pixhawk that converts ROS messages to MAVLink messages, and MAVLink messages to ROS messages. MAVROS makes certain Pixhawk data available such as state data, IMU, and the Pixhawk's internal status. It also allows you to publish commands to the Pixhawk such as position, velocity, or attitude.</p>"},{"location":"computers/pixhawk/#installation","title":"Installation","text":"<p>This guide gives two steps to install mavros:</p> <p><pre><code>sudo apt install ros-kinetic-mavros ros-kinetic-mavros-extras\n</code></pre> and</p> <pre><code>wget https://raw.githubusercontent.com/mavlink/mavros/master/mavros/scripts/install_geographiclib_datasets.sh\n./install_geographiclib_datasets.sh\n</code></pre> <p>Once installed, you can launch MAVROS with your Pixhawk connected over USB by running <code>roslaunch mavros px4.launch</code> or <code>roslaunch mavros apm.launch</code> depending on which firmware (PX4 or APM) that your Pixhawk is running. After launching, opening a new terminal and running <code>rostopic list</code> should now display several topics of Pixhawk data.</p> <p>It is not recommended to connect to the Pixhawk over USB when you are conducting actual flight tests. In this case, you should connect to the Pixhawk via the Telem2 port. To do this, you can use an FTDI cable or a direct UART connection as was discussed earlier on this page.</p>"},{"location":"computers/pixhawk/#coordinate-frames","title":"Coordinate Frames","text":"<p>Although both APM and PX4 firmware do their own internal state estimation and control in the local NED coordinate frame, and the front-right-down (FRD) body frame, MAVROS converts Pixhawk state data to be expressed in the ENU local frame and the FLU body frame. MAVROS does this to be consistent with standard ROS conventions. In our lab however, we generally prefer to use the NED/FRD coordinate systems and therefore you will need to convert MAVROS data back to being expressed in NED/FRD. There are two ways to do this: The first way (and the most correct way), is to setup your TF tree to handle the coordinate frame conversions for you. The second way would be to write a re-publisher node that subscribes to the MAVROS ENU/FLU data, performs the necessary ENU to NED rotations, and then publishes new data in NED/FRD.</p>"},{"location":"computers/systemd/","title":"systemd","text":"<p>Often it is desirable to have your embedded Linux computer run a script or application on startup. Examples include capturing camera video data on a quad when you turn power on to the onboard computer, setting up and running your ROS nodes on a fixed-wing, or setting up the ROS Whirlybird network on a Raspberry Pi.</p> <p>There are a few ways of running startup scripts which makes the waters more muddy. This is mainly because of historical reasons between SysV Init, Upstart, and systemd. We will use systemd to run userland services.</p>"},{"location":"computers/systemd/#historical-background","title":"Historical Background","text":"<p>UNIX System V (\"System Five\") was an early commercial OS developed at AT&amp;T in 1983. They introduces a new style of system startup configuration that we now call SysV-style init. Nowadays, Linux still has support for SysV init for backward compatibility even though it was technically replaced in Ubuntu 6.10 by Upstart. Scripts for SysVinit are found in <code>/etc/init.d</code> and are run using those executable scripts directly (e.g., <code>sudo /etc/init.d/apache2 start</code>).</p> <p>Upstart was the successor to SysVinit and was the default system configuration from Ubuntu 6.10 to 14.10. Upstart was made just to replace SysVinit -- i.e., it did nothing else other than manage processes that you wanted to be able to start and stop at boot or during the system uptime. Upstart introduced non-executable <code>*.conf</code> files found in <code>/etc/init</code>. These configuration files describe services that can be called with the <code>start</code>, <code>stop</code>, and <code>status</code> commands (e.g., <code>sudo start apache2</code>).</p> <p>While Upstart was the default, a new command showed up on the block that aimed at providing inter-operability to Linux system administrators. This command is the <code>service</code> command. It's goal was to provide a common interface to both Upstart and SysVinit configurations and services. It runs as <code>sudo service apache2 start</code> and tells you whether it is using the <code>/etc/init.d/</code> script or the <code>/etc/init</code> Upstart conf file.</p> <p>With the release of Ubuntu 15.04, Ubuntu switched from upstart to systemd as the default configuration manager. systemd is a powerful tool that has caused a lot of debate in the Linux community. Not only does it deal with the starting and stopping of system services, but it takes care of mounting, networking, process management, login, etc. In short, it breaks the UNIX idea of doing one thing and doing it well. But, it does run services cleanly and is rather flexible. Systemd service files (called units) are found in multiple places, most importantly in <code>/etc/systemd/system</code> and are managed with the <code>systemctl</code> command (e.g., <code>sudo systemctl start apache2</code>). Also, here is a discussion on systemd vs upstart.</p>"},{"location":"computers/systemd/#why-not-use-etcrclocal","title":"Why not use <code>/etc/rc.local</code> ?","text":"<p>This script is available and will run Bash scripts during boot, but processes are owned by root and it's really part of the old SysVinit system and isn't that clean.</p>"},{"location":"computers/systemd/#why-not-use-cron","title":"Why not use cron?","text":"<p>I don't know. It will work and it can be owned by the appropriate user and set with <code>@reboot</code>, but it runs in a <code>/bin/sh</code> (shell) environment so you have to remember to call <code>/bin/bash</code> to get into the right environment. It just doesn't feel right.</p>"},{"location":"computers/systemd/#systemd-systemctl-commands","title":"systemd <code>systemctl</code> Commands","text":"<pre><code>$ sudo systemctl start myrobot   # the .service extension is optional\n$ sudo systemctl stop myrobot\n$ sudo systemctl enable myrobot  # installs the service to be run at boot -- requires an [Install] stanza\n$ sudo systemctl disable myrobot\n</code></pre> <p>Read more about managing your system with systemctl here.</p>"},{"location":"computers/systemd/#example-systemctl-unit-file","title":"Example <code>systemctl</code> Unit File","text":"<p>Here is the service unit file for the ROS Whirlybird setup used in ECEn 483</p> <pre><code># /etc/systemd/system/whirlybird.service\n[Unit]\nDescription=\"Whirlybird ROS Serial Bridge\"\nAfter=network-online.target\n\n[Service]\nType=simple\nUser=louie\nGroup=louie\nExecStart=/home/louie/ros_start.sh\n\n[Install]\nWantedBy=default.target\n</code></pre> <p>And here is the <code>ros_start.sh</code> script that is run on startup as the <code>louie</code> user</p> <pre><code>#!/usr/bin/env bash\n# Setup the ROS environment for this Whirlybird and start the serial node\n#\n# This file should be in ~/ros_start.sh and be marked as executable (chmod +x ros_start.sh)\n\nexport ROS_MASTER_URI=http://localhost:11311\nexport ROS_IP=`hostname -I`\n\nsource ~/catkin_ws/devel/setup.bash\nroslaunch whirlybird_serial serial.launch\n</code></pre> <p>Before rebooting, you can test the service with</p> <pre><code>$ sudo systemctl start whirlybird\n</code></pre> <p>And you can see if it is running or failed with</p> <pre><code>$ sudo systemctl status whirlybird\n</code></pre> <p>or you can check the log output with</p> <pre><code>$ sudo journalctl -u whirlybird\n</code></pre> <p>Make sure to \"install\" the service with</p> <pre><code>$ sudo systemctl enable whirlybird\n</code></pre> <p>Reboot and it should start automagically!</p> <p>More information about writing unit files can be found:</p> <ul> <li>at DigitalOcean</li> <li>these RedHat docs</li> <li>at this SO question about running as a specific user</li> <li>this ROS-specific SO question about systemd</li> <li>Make systemd wait until the network is really up using network-online.target</li> </ul>"},{"location":"computers/systemd/#gotchas","title":"Gotchas","text":""},{"location":"computers/systemd/#sourcing-bashrc-doesnt-work","title":"Sourcing <code>~/.bashrc</code> Doesn't Work","text":"<p>In your equivalent <code>ros_start.sh</code> entry point, you may notice that if you try to source your <code>~/.bashrc</code> it does not seem to work (i.e., your ROS network setup, aliases, etc). This is because it is being sourced from a non-interactive session and at the top of the <code>~/.bashrc</code> you will see code that makes the script bail when that's the case. A solution is to use a secondary script like <code>~/.bash_profile</code> to put all of your specific changes in and source that script in <code>~/.bashrc</code> for normal use and in the <code>ros_setup.sh</code> for robot use. In my opinion, this is the proper way to do that anyways because then you can source control or share the <code>~/.bash_profile</code> with other computers/robots.</p> <p>For the alias problem it's because expanding aliases is not the default option in non-interactive mode. This can be changed by adding that option before you source a script:</p> <pre><code>$ shopt -s expand_aliases\n$ source ~/.bash_profile\n</code></pre>"},{"location":"computers/systemd/#systemd-version-230-breaks-screen-and-tmux","title":"systemd Version 230 Breaks screen and tmux","text":"<p>Ubuntu 16.04 ships with systemd version 229 (<code>systemd --version</code>). Apparently in version 230, screen and tmux are broken by default which seems silly. Likely, Ubuntu 18.04 will be confusing for users (and us) if systemd keeps this as the default.</p> <p>Read here for a long discussion of systemd and links about this issue and here for how to change this default behavior.</p>"},{"location":"control_tutorials/overview/","title":"Overview of Control Systems","text":"<p>These are basic tutorials for controlling a system. If you want to learn about estimating a system's state, check out this tutorial: https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python</p>"},{"location":"control_tutorials/overview/#pid-control","title":"PID Control","text":"<p>The technique of PID control is used both in the lab, and widely in industrial control systems. It's probably the simplest and oldest form of control and is found in your car's cruise control, almost all of the autopilots we use in the lab, and tons of other places. PID controls is named because of the 3 parts of the algorithm:</p> <p>P = proportional I = integral D = derivative</p> <p>Not all systems require all three components, and you will learn about each one individually starting with P controls, but just so you can get an idea of the big picture before focusing in on each constituent part, the ensemble of PID controls is briefly presented now.</p> <p>From Wikipedia, \"A PID controller continuously calculates an 'error value' as the difference between a measured variable and a desired setpoint.\" In other words, it is how we get an autonomous vehicle to move from one point to another.</p> <p>The equation looks like this</p> u(t) = K_p e(t) + K_i \\int^t_0{e(\\tau)} d\\tau + K_d\\frac{d_e}{d_t} <p>You can see the three coefficients, K, each multiplied by an error value, e(t)</p> <p>P -&gt; accounts for present values of error</p> <p>I -&gt; accounts for past values of error. Error accumulates over time through use of integration and is added to the proportional term to help reduce error value if proptional term isn't doing enough.</p> <p>D -&gt; predicts and accounts for future values of error, based on current rate of change of the error.</p>"},{"location":"control_tutorials/p_controller/","title":"Controls tutorials: P Controller","text":""},{"location":"control_tutorials/p_controller/#example","title":"Example","text":"<p>Let's use an example to illustrate:</p> <p></p> <p>In this image, we have a jetski rider, who is trying to approach the dock. He has the jet out the back of the ski, which we will model as a linear force on the back of the jetski. The question is, how much force should he apply to get where he wants to go?</p> <p>The simplest answer is for the jetski rider to apply a lot of force when he is far away from the goal, and less if he is closer. Say, he applies a force \"proportional\" to his position error. That is the idea behind P control.</p>"},{"location":"control_tutorials/p_controller/#p-control","title":"P Control","text":"<p>Let's look at P control in the context of turtlesim since that is your next assignment. All you will be doing in this assignment is using a linear force to drive the turtle and a torque to steer the turtle towards a destination. The magnitude of the force and torque will be proportional to a calculated error (difference between where you are and where you want to be). If you remember the P term of the entire PID equation it looked like this  t </p> K_p e(t) <p>K is just a gain coefficient - a constant. Error is what's important. The point is to constantly check your error and output a force and torque scaled according to the amount of error. If you're way off your mark, your error is large and your applied force will be larger than if you were really close.</p>"},{"location":"control_tutorials/p_controller/#turtlesim-example","title":"TurtleSim Example","text":"<p>Use the picture below as an example. Pretend like the turtle's current position is point B and he is pointing to D. The turtle's goal is point A. Line BC will be used as a reference 0 degrees.</p> <p></p> <p>There will be two errors that you need to calculate in the turtle's positioning. They are 1) distance from goal and 2) difference between current angle and desired angle. Thus you will have distance error and angle error which will scale both a linear force and an angular torque respectively.</p>"},{"location":"control_tutorials/p_controller/#the-math","title":"The Math","text":"<p>Let's use the Pythagorean theorem to calculate the distance to the goal (distance error).</p>  d_e = \\sqrt{(Goal_x - Current_x)^2 + (Goal_y - Current_y)^2}  <p>Use the arc-tangent to calculate the goal angle (ABC), the angle to which you need to align yourself.</p>  \\psi_{goal} = arctan(\\frac{Goal_y - Current_y}{Goal_x - Current_x})  <p>The angle error (ABD) is then calculated as the difference between goal angle and current angle (DBC).</p>  \\psi_e=\\psi_g-\\psi_c  <p>where \\( \\psi_e \\), \\( \\psi_g \\) and \\( \\psi_c \\) are the error, goal and current values for \\( \\psi \\).</p> <p>You can then use these calculated errors to drive your turtle to your goal!</p>"},{"location":"control_tutorials/pd_controller/","title":"PD Controller","text":""},{"location":"control_tutorials/pd_controller/#derivative-term","title":"Derivative Term","text":"<p>Hopefully you noticed in the last assignment that your turtle consistently overshot his destination. This is because he couldn't predict the future of arriving at the destination and slow down. In this assignment we will add the derivative term which will correct this problem by providing prediction through linear extrapolation. Your equation will now look like this.</p> <p>A human will recognize that it is ok to go really fast when far away from the destination but when approaching, it might be a good idea to slow down. If you think about what a human intuitively knows in order to do this, you recognize that it will be necessary to know the velocity so you can know if you're going too fast and need to slow down as you approach. But you also need to know the destination location. Combining the two, you need to know your velocity in relation to where you are relative to your destination. This is what the derivative of error yields.</p> <p>The derivative of the error is the change in error (distance from destination) over time. If you think about what that actually means you will recognize that this is similar to velocity. After all it is a change in position over time. You will find, however, that it is a little more specific than velocity in the fact that it gives you change in position relative to your destination. Let's compare velocity with error derivative so you can understand the difference. Consider the two situations below of approaching a destination (star).</p> <p>$$ u(t) = K_p e(t) + K_d \\frac{de}{dt} $$</p> <p>A human will recognize that it is ok to go really fast when far away from the destination but when approaching, it might be a good idea to slow down. If you think about what a human intuitively knows in order to do this, you recognize that it will be necessary to know the velocity so you can know if you're going too fast and need to slow down as you approach. But you also need to know the destination location. Combining the two, you need to know your velocity in relation to where you are relative to your destination. This is what the derivative of error yields.</p> <p>The derivative of the error is the change in error (distance from destination) over time. If you think about what that actually means you will recognize that this is similar to velocity. After all it is a change in position over time. You will find, however, that it is a little more specific than velocity in the fact that it gives you change in position relative to your destination. Let's compare velocity with error derivative so you can understand the difference. Consider the two situations below of approaching a destination (star).</p> <p>Approaching a destination in a straight line.</p> \\( \\frac{de}{dt} \\propto velocity \\) \\( \\frac{de}{dt}=0 \\) and \\( velocity \\ne 0 \\) The derivative of the error is proportional to velocity The derivative of the error equals zero while the velocity does not <p>Can you now see how the error derivative is more than just a measure of velocity? It is a measure of velocity with relation to your destination.</p> <p>The below illustration explains this concept more precisely. The turtle's destination is in the top left corner from where he spawned at the center.</p>  ![velocity_error_estimation.png](figures/velocity_error_estimation.png) $$ \\frac{de}{dt} = \\frac{error - error_{previous}}{dt} $$  <p>If you think carefully about the error derivative as the turtle goes around the curve, you will notice it is positive (red lines) when the turtle first starts out. The turtle is moving away from the destination and so error is increasing. At the end of the journey the turtle is getting closer to the destination, thus error is decreasing and the error derivative is negative (green arrows). At some point it must transition between positive and negative and will thus be zero (black arrow, similar to circle case above).</p> <p>The ability to be either positive or negative is very valuable and that is how we can either increase or decrease the value of the controls, by adding to, or subtracting from the original P term. If the turtle is moving away from the destination, the derivative term is positive and says, \"lets step on the gas a little and travel around this curve a little faster,\" so it adds to the P term. When the turtle is moving towards the destination the D term is negative and says, \"we are going to hit our mark pretty quick, lets slow down a little\" and so it subtracts from the P term. This is what is meant by \"ability to predict the future through use of derivation.\"</p> <p>As with the P control assignment, there is a linear component and an angular component in D controls. This tutorial only explained linear D controls since it is easier to visualize. The principles are the same and easily applied to the angular component.</p>"},{"location":"control_tutorials/pid_controller/","title":"PID Controller","text":""},{"location":"control_tutorials/pid_controller/#integration","title":"Integration","text":"<p>We are now going to add wind to make our simulation a little more life-like. Go into the turtlesim_dynamics/src folder that you installed in order to complete the PD controller. Edit the turtle.cpp file to have wind by making the wind_x and wind_y parameters non zero values, or simply assign these values in a launch file. If you run the PD controller that you made in the last assignment you will notice that the turtle never reaches his destination because of the wind. You might see something similar to the situation below.</p> <p></p> <p>The turtle is trying to reach a destination at coordinates (7, 9). He has turned to face straight into the wind which is blowing from top right to bottom left. You can see his position has stalled at (6.7, 8.7). We can correct this problem by adding the third and final term to our equation, the long awaited integral of error. Our final equation is what you saw in the overview.</p>  u(t) = K_p e(t) + K_i \\int{e(\\tau)d\\tau}{0}{t} + K_d \\frac{d_e}{d_t}  <p>If the turtle has stalled just shy of the destination, we can sum the error continuously (integrating) and add it to our P and D terms. This is the I term. As time passes and you still haven't reached the destination, the integral builds thus increasing the I term, and the turtle has the extra force needed in order to make the final push home.</p>"},{"location":"control_tutorials/assignments/p_turtle/","title":"P Controller with TurtleSim","text":""},{"location":"control_tutorials/assignments/p_turtle/#assignment-1","title":"Assignment 1","text":"<p>Using the concepts of P control only, create a node that controls the turtle towards a goal. The below example shows a turtle trying to obtain a goal point somehwere in the top left corner from where he originally spawned.</p> <p></p> <p>Requirement: The regular turtlesim node has a turtle with no mass or inertia etc so it will not behave as any real object would. In order to complete this assignment you will need to install a turtlesim node that has dynamics. This is a link to a git repo containing the package. You can either download the zip or clone it into your workspace.</p> <p>Requirement: You may have noticed by now that using only P control may be insufficient for certain systems as it would be for the jetski example previously given. As requirement one said, the turtle now has mass and inertia so when you reach the destination there is nothing to stop the turtle from continuing to drift. So when your turtle repeatedly overshoots the destination and loops back to try again (shown below), don't worry about it. You will be correcting this inadequacy in the next assignment by using D controls in combination with P controls.</p> <p></p> <p>Requirement: Make sure that your turtle turns through the smallest possible angle. Don't rotate right through 300 degrees when you could have rotated left through 60 degrees.</p> <p>Requirement: Don't use geometry_msgs/Twist to publish linear and angular velocities in order to control the turtle. In real life you cant just tell a vehicle to go a certain speed. So instead use forces and torques. Think of thrusters on a spaceship. In the turtlesim_dynamics node mentioned above, force and torque are messages that are sent over the geometry_msgs/Wrench topic.</p> <p>Hint: The node needs to listen to turtle's current position, do proportional control calculations, then publish your control message (forces and torques) to the turtle to adjust his position.</p> <p>Hint: You may want to use the C++ function atan2(double_y, double_x) which returns the computed arctangent of X and Y coordinates with the appropriate corresponding sign (negative or positive) rather than always positive for both first and third quadrants or always negative for both second and fourth quadrants which is what the regular arctangent function returns.</p>"},{"location":"control_tutorials/assignments/pd_turtle/","title":"PD Controller with TurtleSim","text":""},{"location":"control_tutorials/assignments/pd_turtle/#assignment-2","title":"Assignment 2","text":"<p>Use a PD controller to drive the turtle towards a destination without overshooting the mark. As you complete this assignment, do so in the absence of wind. You can either edit the wind parameters in the turtle.cpp file of the turtlesim_dynamics folder that you installed in the last tutorial, or you could create a launch file with parameter arguments to set the wind values (might be useful for the next assignment anyway).</p> <p>To set a param inside a node, use this syntax <pre><code>&lt;node name=\"turtle\" pkg=\"turtlesim_dynamics\" type=\"turtlesim_node\"&gt;\n  &lt;rosparam name=\"parameter_name\" value=\"2\"/&gt;\n&lt;/node&gt;\n</code></pre></p> <p></p>"},{"location":"control_tutorials/assignments/pid_turtle/","title":"PID Controller with TurtleSim","text":""},{"location":"control_tutorials/assignments/pid_turtle/#assignment-3","title":"Assignment 3","text":"<p>Use a PID controller to drive the turtle (with dynamics) to a destination in the presence of wind. The turtle should not overshoot the destination and should not stop short of it because of the wind. The turtle should always be approaching the goal (even if slowly). Notice the turtle below from the same situation as before. He now does not stop at (6.7, 8.7) but continues to approach the destination (7, 9). You may have to play with the gains a little in order for the gains of all three terms to work together harmoniously.</p> <p></p> <p>While you're at it, if you haven't already, make your node subscribe to some kind of goal message. We should be able to run a rostopic pub on some topic to change the goal of the turtle and make it go wherever we want, without re-compiling the code!</p>"},{"location":"gazebo_tutorials/adding_an_image_to_the_ground_plane/","title":"Adding a Ground Image","text":""},{"location":"gazebo_tutorials/adding_an_image_to_the_ground_plane/#adding-a-ground-plane-image","title":"Adding a Ground Plane Image","text":"<p>It can be helpful in gazebo to have an image on the ground plane rather than the default background. For instance, several applications in the lab deal with visual odometry or navigation. In this lesson, we learn how to add a ground plane image and add it to our gazebo texture library. While the method put forth here works, it may not be the ideal way of doing it.</p>"},{"location":"gazebo_tutorials/adding_an_image_to_the_ground_plane/#image-selection-and-location","title":"Image Selection and Location","text":"<p>Any image can be used as the ground image, but ideally it is a high-resolution image. JPEG, PNG, and BMP images have been shown to work, but other static image types probably work as well.</p> <p>Gazebo keeps all image textures in the protected directory /usr/share/gazebo-(version_number)/media/materials/textures/ (make sure to replace (version_number) with the appropriate path. My current version is gazebo-2.2). Navigating to that location in Ubuntu, you can see a number of images. Move your desired image to this location using sudo. For this tutorial, we are using the image shown below with the name <code>Byu.jpg</code>.</p> <p></p> <p>Image textures in gazebo are stored as models, so we want to make a new model file in gazebo. To make a non-root model, we create a new directory in ~/.gazebo/models, naming the directory our desired model name. We'll call our model directory 'byu'.</p> <p>In the byu directory, we want to create the following directory structure:</p> <p><pre><code>+---byu\n    \\---model.config\n    \\---model.sdf\n    +---materials\n        +---scripts\n            \\---byu.material\n</code></pre> In the root of this directory, we fill <code>model.config</code> with <pre><code>&lt;model&gt;\n  &lt;name&gt;BYU Ground&lt;/name&gt;\n  &lt;version&gt;1.0&lt;/version&gt;\n  &lt;sdf version=\"1.4\"&gt;model.sdf&lt;/sdf&gt;\n\n  &lt;description&gt;\n    My image ground plane\n  &lt;/description&gt;\n\n&lt;/model&gt;\n</code></pre> and make <code>model.sdf</code> <pre><code>&lt;?xml version=\"2.0\"?&gt;\n&lt;sdf version=\"1.4\"&gt;\n&lt;model name=\"byu\"&gt;\n  &lt;static&gt;true&lt;/static&gt;\n    &lt;link name=\"link\"&gt;\n      &lt;collision name=\"collision\"&gt;\n        &lt;geometry&gt;\n          &lt;plane&gt;\n            &lt;normal&gt;0 0 1&lt;/normal&gt;\n            &lt;size&gt;10 10&lt;/size&gt;\n          &lt;/plane&gt;\n        &lt;/geometry&gt;\n        &lt;surface&gt;\n          &lt;friction&gt;\n            &lt;ode&gt;\n              &lt;mu&gt;100&lt;/mu&gt;\n              &lt;mu2&gt;50&lt;/mu2&gt;\n            &lt;/ode&gt;\n          &lt;/friction&gt;\n        &lt;/surface&gt;\n      &lt;/collision&gt;\n      &lt;visual name=\"visual\"&gt;\n        &lt;cast_shadows&gt;false&lt;/cast_shadows&gt;\n        &lt;geometry&gt;\n          &lt;plane&gt;\n            &lt;normal&gt;0 0 1&lt;/normal&gt;\n            &lt;size&gt;100 100&lt;/size&gt;\n          &lt;/plane&gt;\n        &lt;/geometry&gt;\n        &lt;material&gt;\n          &lt;script&gt;\n            &lt;uri&gt;model://byu/materials/scripts/byu.material&lt;/uri&gt;\n            &lt;name&gt;BYU/ground&lt;/name&gt;\n          &lt;/script&gt;\n        &lt;/material&gt;\n      &lt;/visual&gt;\n    &lt;/link&gt;\n  &lt;/model&gt;\n&lt;/sdf&gt;\n</code></pre> We now only have one more file to set up - <code>byu.material</code>. In this file, we put: <pre><code>material BYU/ground\n{\n  technique\n  {\n    pass\n    {\n      ambient 1.0 1.0 1.0 1.0\n      diffuse 0.8 0.8 0.8 1.0\n      specular 0.0 0.0 0.0 1.0 2.0\n\n      texture_unit\n      {\n        texture byu.jpg\n        filtering trilinear\n      }\n    }\n  }\n}\n</code></pre> In this file, the name of the texture image must match the name of the image you put in the gazebo textures directory at the very beginning. The ambient, diffuse, and specular parameters change the lighting on the figure; you can play around with these if you wish.</p> <p>Notice the lines for \"uri\" and \"name\" in the <code>model.sdf</code> file. It is important that these match the name of the <code>.material</code> file and the material parameter in the first line of that file, if you choose to change the name of the material to be more descriptive of your application. For instance, if you wanted to make a model named \"magicc\", you would need to change your material file to the name <code>magicc.material</code>, your uri to \"model://(name of directory)/materials/scripts/magicc.material\", and your texture name to the name of the image. It is also good practice to name your root directory to the name of the material as well as changing your model name (here BYU/ground) to something descriptive of your ground image. Make sure to change that name both in your material file as well as in your <code>model.sdf</code> file. The <code>&lt;model name=\"byu\"&gt;</code> needs to be changed as well.</p>"},{"location":"gazebo_tutorials/adding_an_image_to_the_ground_plane/#place-the-ground-image","title":"Place The Ground Image","text":"<p>From here, you should be able to start gazebo and import your image plane. Start a vanilla instance of gazebo, go to the \"insert\" tab, and you should see \"BYU Ground\" listed under your models. Click the model, and you should be able to place it in your gazebo simulation. The ground plane size may be too large for you; you can change that under the <code>&lt;size&gt;</code> tag immediately before the <code>&lt;material&gt;</code> tag in <code>model.sdf</code>. The size is set to 100x100 in the model as given.</p>"},{"location":"gazebo_tutorials/adding_plugins/","title":"Adding Plugins","text":""},{"location":"gazebo_tutorials/adding_plugins/#adding-plugins_1","title":"Adding Plugins","text":"<p>Plugins are compiled executables which are installed in gazebo. You can attach these plugins to links on your robot and they can pretty much do anything you can imagine. They are able to access pretty much any information about the simulation, and can publish ROS messages, apply forces, move joints, etc... Typically, we have used them to simulate sensors and simulate aerodynamics, but they could certainly be used for other things.</p> <p>In this tutorial, we will have you add an RGBD camera to your robot.</p> <p>We have gathered a number of useful xacro files that make this a lot easier. Look in the fcu_sim meta package, in the fcu_sim_plugins package. In the xacro file, there will be a number of macros which allow you to quickly attach a plugin to your robot.</p> <pre><code>rotor_simulator\n+-- attitude_controller\n+-- joy_sim\n+-- rotor_gazebo\n+-- rotor_gazebo_plugins\n|    |-- CMakeLists.txt\n|    |-- package.xml\n|    +-- include\n|    +-- src\n|    |-- xacro\n|    |    |-- rgbd.xacro\n|    |    |-- wind.xacro\n|    |    |-- imu.xacro\n|    |    |-- ...\n|    |    |\n+-- sim_reset\n</code></pre>"},{"location":"gazebo_tutorials/adding_plugins/#rgbdxacro","title":"rgbd.xacro","text":"<p>Let's look at the rgbd.xacro file. It is split into two macros, first , on line 6 defines the \"xtion\" macro</p> <p><pre><code>&lt;?xml version=\"1.0\"?&gt;\n&lt;robot xmlns:xacro=\"https://wiki.ros.org/xacro\"&gt;\n  &lt;xacro:property name=\"pi\" value=\"3.14159265359\" /&gt;\n\n  &lt;!-- XTION --&gt;\n  &lt;xacro:macro\n    name=\"xtion\"\n    params=\"namespace\n            parent_link\"&gt;\n    &lt;xacro:depth_camera\n      namespace=\"${namespace}\"\n      parent_link=\"${parent_link}\"\n      camera_suffix=\"\"\n      frame_rate=\"30\"\n      depth_range=\"6.5\"\n      rgb_range=\"\"\n      image_topic=\"/camera/rgb/image_raw\"\n      depth_topic=\"/camera/depth/image_raw\"\n      image_camera_info_topic=\"/camera/rgb/camera_info\"\n      depth_camera_info_topic=\"/camera/depth/camera_info\"\n      pointcloud_topic=\"/camera/pointcloud\"&gt;\n      &lt;origin xyz=\"0.127 0 -0.0889\" rpy=\"0 0 0\" /&gt; &lt;!-- for shredder --&gt;\n    &lt;/xacro:depth_camera&gt;\n  &lt;/xacro:macro&gt;\n  ...\n</code></pre> This sets up the parameters for the plugin to match the characteristics of the xtion camera, it then calls the generic rgbd camera macro defined on line 26, there is a macro which defines a generic RGBD camera. <pre><code>  &lt;!-- Macro to add a depth camera. --&gt;\n    &lt;xacro:macro\n    name=\"depth_camera\"\n    params=\"namespace\n            parent_link\n            camera_suffix\n            frame_rate\n            depth_range\n            rgb_range\n            image_topic\n            depth_topic\n            image_camera_info_topic\n            depth_camera_info_topic\n            pointcloud_topic\n            *origin\"&gt;\n  ...\n</code></pre> Because there are so many parameters to change in the generic macro, it is easier to build a wrapper around that macro which sets the parameters for a known sensor. All you need to do is to include the xacro file in your new URDF, and call the xtion macro, setting the namespace and parent link appropriately.</p>"},{"location":"gazebo_tutorials/adding_plugins/#adding-the-plugin","title":"Adding the Plugin","text":"<p>Let's go ahead and add the rgbd camera to the pioneer robot.</p> <pre><code>&lt;robot name=\"pioneer\" xmlns:xacro=\"https://wiki.ros.org/xacro\"&gt;\n  &lt;xacro:property name=\"mass\" value=\"0.5755\" /&gt;\n  &lt;xacro:property name=\"width\" value=\"0.1\" /&gt;\n  &lt;xacro:property name=\"height\" value=\"0.2\" /&gt;\n  &lt;xacro:property name=\"length\" value=\"0.4\" /&gt;\n  &lt;xacro:property name=\"wheel_radius\" value=\"0.1\" /&gt;\n  &lt;xacro:property name=\"wheel_length\" value=\"0.06\" /&gt;\n  &lt;xacro:property name=\"caster_radius\" value=\"0.05\" /&gt;\n  &lt;xacro:property name=\"body_inertia\"&gt;\n    &lt;inertia ixx=\"0.007\" ixy=\"0.0\" ixz=\"0.0\" iyy=\"0.007\" iyz=\"0.0\" izz=\"0.012\" /&gt;\n  &lt;/xacro:property&gt;\n\n  &lt;link name=\"chassis\"&gt;\n    &lt;inertial&gt;\n      &lt;mass value=\"${mass}\" /&gt;\n      &lt;origin xyz=\"0 0 0.1\"/&gt;\n      &lt;xacro:insert_block name=\"body_inertia\"/&gt;\n    &lt;/inertial&gt;\n\n    &lt;visual name='visual'&gt;\n      &lt;origin xyz=\"0 0 0.1\" rpy=\"0 0 0\" /&gt;\n      &lt;geometry&gt;\n        &lt;box size=\"${body_width} ${body_width} ${body_height}\"/&gt;\n      &lt;/geometry&gt;\n    &lt;/visual&gt;\n    &lt;visual name='visual_caster'&gt;\n      &lt;origin xyz=\"-0.15 0 0.05\" rpy=\"0 0 0\" /&gt;\n      &lt;geometry&gt;\n        &lt;sphere radius=\"${caster_radius}\"/&gt;\n      &lt;/geometry&gt;\n    &lt;/visual&gt;\n\n    &lt;collision name='collision'&gt;\n      &lt;origin xyz=\"0 0 0.1\" rpy=\"0 0 0\" /&gt;\n      &lt;geometry&gt;\n        &lt;box size=\"${body_width} ${body_width} ${body_height}\" /&gt;\n      &lt;/geometry&gt;\n    &lt;/collision&gt;\n    &lt;collision name='collision_caster'&gt;\n      &lt;origin xyz=\"0 0 0.1\" rpy=\"0 0 0\" /&gt;\n      &lt;contact_coefficients mu=\"0\"/&gt;\n      &lt;geometry&gt;\n        &lt;sphere radius=\"${caster_radius}\"/&gt;\n      &lt;/geometry&gt;\n    &lt;/collision&gt;\n  &lt;/link&gt;\n\n  &lt;link name=\"right_wheel\"/&gt;\n    &lt;inertial&gt;\n      &lt;mass value=\"0.1\" /&gt;\n      &lt;origin xyz=\"0.1 -0.13 0.1\" rpy=\"0 1.5707 1.5707\"/&gt;\n      &lt;inertia ixx=\"0.01\" ixy=\"0.0\" ixz=\"0.0\" iyy=\"0.01\" iyz=\"0.0\" izz=\"0.2\"/&gt;\n    &lt;/inertial&gt;\n\n    &lt;visual name=\"visual\"/&gt;\n      &lt;geometry&gt;\n        &lt;cylinder length=\"0.05\" radius=\"0.1\"/&gt;\n      &lt;/geometry&gt;\n    &lt;/visual&gt;\n\n    &lt;collision name=\"collision\"/&gt;\n      &lt;geometry&gt;\n        &lt;cylinder length=\"0.05\" radius=\"0.1\"/&gt;\n      &lt;/geometry&gt;\n    &lt;/collision&gt;\n  &lt;/link&gt;\n\n  &lt;link name=\"right_wheel\"/&gt;\n    &lt;inertial&gt;\n      &lt;mass value=\"0.1\" /&gt;\n      &lt;origin xyz=\"0.1 0.13 0.1\" rpy=\"0 1.5707 1.5707\"/&gt;\n      &lt;inertia ixx=\"0.01\" ixy=\"0.0\" ixz=\"0.0\" iyy=\"0.01\" iyz=\"0.0\" izz=\"0.2\"/&gt;\n    &lt;/inertial&gt;\n\n    &lt;visual name=\"visual\"/&gt;\n      &lt;geometry&gt;\n        &lt;cylinder length=\"0.05\" radius=\"0.1\"/&gt;\n      &lt;/geometry&gt;\n    &lt;/visual&gt;\n\n    &lt;collision name=\"collision\"/&gt;\n      &lt;geometry&gt;\n        &lt;cylinder length=\"0.05\" radius=\"0.1\"/&gt;\n      &lt;/geometry&gt;\n    &lt;/collision&gt;\n  &lt;/link&gt;\n\n  &lt;joint name=\"left_wheel_joint\" type=\"revolute\"&gt;\n    &lt;axis xyz=\"0 1 0\"/&gt;\n    &lt;limit effort=\"1000.0\" velocity=\"0.5\"/&gt;\n    &lt;origin rpy=\"0 0 0\" xyz=\"0 0.03 0\"/&gt;\n    &lt;parent link=\"chassis\"/&gt;\n    &lt;child link=\"left_wheel\"/&gt;\n  &lt;/joint&gt;\n\n  &lt;joint name=\"right_wheel_joint\" type=\"revolute\"&gt;\n    &lt;axis xyz=\"0 1 0\"/&gt;\n    &lt;limit effort=\"1000.0\" velocity=\"0.5\"/&gt;\n    &lt;origin rpy=\"0 0 0\" xyz=\"0 -0.03 0\"/&gt;\n    &lt;parent link=\"chassis\"/&gt;\n    &lt;child link=\"left_wheel\"/&gt;\n  &lt;/joint&gt;\n\n  &lt;xacro:include filename=\"$(find fcu_sim_plugins)/xacro/rgbd.xacro\"/&gt;\n  &lt;xacro:xtion namespace=\"\" parent_link=\"chassis\"/&gt;\n\n&lt;/robot&gt;\n</code></pre>"},{"location":"gazebo_tutorials/interfacing_with_gazebo/","title":"Interfacing ROS With Gazebo","text":""},{"location":"gazebo_tutorials/interfacing_with_gazebo/#interfacing-ros-with-gazebo_1","title":"Interfacing ROS With Gazebo","text":"<p>Okay, so now we have our MAV showing up in Gazebo, let's tell it to do something with ROS.</p> <p>Go ahead and launch your test.launch file for the multirotor and look at the <code>rqt_graph</code>. It should look something like this. </p> <p></p> <p>You may have additional sensors beyond ground_truth and imu, but the idea is the same.</p> <p>All we need to do to make our MAV fly is publish to the <code>/hummingbird/gazebo/command/motor_speed</code> topic.</p> <p>We can manually override the position of the MAV by publishing to the <code>/gazebo/set_model_state</code> topic, and we can retrieve truth information from the <code>/hummingbird/ground_truth/*</code> topics. Our Cortex motion capture system publishes the same kind of message as the <code>/hummingbird_ground_truth/transform</code> topic, so if you leverage that message, then it is a drop-in replacement for the <code>cortex_ros</code> package.</p> <p>The <code>attitude_controller</code> package can be used to publish the motor commands to gazebo, and it accepts roll, pitch, yaw_rate and thrust commands. The <code>joy_sim</code> package publishes these kinds of commands based on joystick inputs, and the <code>pid_controller</code> package publishes these commands based on velocity inputs from other nodes. Here is an example of the <code>rqt_graph</code> for <code>joy_sim -&gt; attitude_controller -&gt; gazebo</code>. </p> <p></p> <p>Here is the launch file that produced this graph: make sure you are on the <code>attitude_controller</code> branch as of 4/16/2016 </p> <p><pre><code>&lt;launch&gt;\n  &lt;arg name=\"mav_name\"            default=\"hummingbird\"/&gt;\n\n  &lt;include file=\"$(find gazebo_ros)/launch/empty_world.launch\"&gt;\n    &lt;arg name=\"world_name\" value=\"$(find fcu_sim)/worlds/basic.world\"/&gt;\n    &lt;arg name=\"paused\" value=\"false\"/&gt;\n    &lt;arg name=\"gui\" value=\"true\"/&gt;\n  &lt;/include&gt;\n\n  &lt;!-- Spawn MAV --&gt;\n  &lt;include file=\"$(find rotor_gazebo)/launch/spawn_mav.launch\"&gt;\n    &lt;arg name=\"mav_name\"            value=\"$(arg mav_name)\" /&gt;\n    &lt;arg name=\"model\"               value=\"$(find fcu_sim)/urdf/$(arg mav_name)/$(arg mav_name)_base.xacro\" /&gt;\n  &lt;/include&gt;\n\n  &lt;!-- Joystick --&gt;\n  &lt;node name=\"xbox\"                pkg=\"joy\"                 type=\"joy_node\"/&gt;\n  &lt;node name=\"joy_sim\" pkg=\"joy_sim\" type=\"joy_sim\" &gt;\n    &lt;rosparam command=\"load\" file=\"$(find joy_sim)/param/$(arg mav_name).yaml\"/&gt;\n  &lt;/node&gt;\n\n  &lt;!-- Attitude Control --&gt;\n  &lt;rosparam command=\"load\" file=\"$(find attitude_controller)/param/$(arg mav_name).yaml\"/&gt;\n  &lt;node name=\"attitude_controller\" pkg=\"attitude_controller\" type=\"attitude_controller_node\"&gt;\n    &lt;rosparam command=\"load\" file=\"$(find fcu_sim)/param/$(arg mav_name).yaml\"/&gt;\n    &lt;remap from=\"odometry\" to=\"$(arg mav_name)/ground_truth/odometry\"/&gt;\n    &lt;remap from=\"command/motor_speed\" to=\"$(arg mav_name)/gazebo/command/motor_speed\"/&gt;\n  &lt;/node&gt;\n</code></pre> As you can see, we have developed the simulator such that it is easy to replace the hardware with the actual software. For example, the same <code>/command topic</code> is accepted by <code>naze_ros</code> and <code>mavros</code> for controlling the Naze and Pixhawk autopilots, respectively. With the drop-in replacement for <code>cortex_ros</code>, simulations can be performed in a simulated motion capture room, then moved right in and flown on hardware with only a few changes in launch files! </p>"},{"location":"gazebo_tutorials/make_a_robot/","title":"Make a Robot","text":""},{"location":"gazebo_tutorials/make_a_robot/#make-a-robot_1","title":"Make a Robot","text":"<p>In this tutorial, we will make ourselves our own robot. We will be using an xacro file, rather than a straight SDF as described in the official Gazebo Tutorials. xacro is read by Gazebo, then converted to SDF, and it uses far less typing to create an xacro. (xacro means \"xml-macro\") which allows us to leverage parts of other files within individual xacro files. You'll find this very useful later.</p> <p>Lets make the same robot you make in the official gazebo tutorials, starting with a blank file named <code>pioneer_base.xacro</code></p>"},{"location":"gazebo_tutorials/make_a_robot/#starting-the-file","title":"Starting the File","text":"<p>The first thing you'll do is define the the xml version and the fact you're building a robot. <pre><code>&lt;?xml version=\"1.0\"?&gt;\n\n&lt;robot name=\"pioneer\" xmlns:xacro=\"https://wiki.ros.org/xacro\"&gt;\n&lt;/robot&gt;\n</code></pre></p>"},{"location":"gazebo_tutorials/make_a_robot/#setting-parameters","title":"Setting Parameters","text":"<p>Next, let's define some parameters, like the robot mass, length, width, height, wheel radius, inertia, and so on... <pre><code>&lt;?xml version=\"1.0\"?&gt;\n\n&lt;robot name=\"pioneer\" xmlns:xacro=\"https://wiki.ros.org/xacro\"&gt;\n  &lt;xacro:property name=\"mass\" value=\"0.5755\" /&gt;\n  &lt;xacro:property name=\"width\" value=\"0.1\" /&gt;\n  &lt;xacro:property name=\"height\" value=\"0.2\" /&gt;\n  &lt;xacro:property name=\"length\" value=\"0.4\" /&gt;\n  &lt;xacro:property name=\"wheel_radius\" value=\"0.1\" /&gt;\n  &lt;xacro:property name=\"wheel_length\" value=\"0.06\" /&gt;\n  &lt;xacro:property name=\"caster_radius\" value=\"0.05\" /&gt;\n  &lt;xacro:property name=\"body_inertia\"&gt;\n    &lt;inertia ixx=\"0.007\" ixy=\"0.0\" ixz=\"0.0\" iyy=\"0.007\" iyz=\"0.0\" izz=\"0.012\" /&gt;\n  &lt;/xacro:property&gt;\n&lt;/robot&gt;\n</code></pre></p>"},{"location":"gazebo_tutorials/make_a_robot/#defining-links-and-joints","title":"Defining Links and Joints","text":"<p>A link is the part of gazebo that has mass, and can collide with other objects. It's the fundamental building block of gazebo. In a single robot, you may have any number of links, but make sure that there are joints between them. There is no such thing as a \"fixed\" joint between links, but a workaround is to create a \"revolute\" link with zero range. In this robot, we make the body and the caster a single link, because then gazebo only calculates dynamics and contacts for the two parts as one, rather than trying to treat them as individual objects. Instead of the caster rolling though, we'll just give it zero friction, and that will simulate the real thing well enough.</p> <p>Every link must have an inertial block. Otherwise gazebo won't load it. Sometimes, I'll make links with mass of 0.001 kg to get around this, but if it's not defined then the link won't exist in the model. I don't know any other way around this.</p> <pre><code>&lt;?xml version=\"1.0\"?&gt;\n\n&lt;robot name=\"pioneer\" xmlns:xacro=\"https://wiki.ros.org/xacro\"&gt;\n  &lt;xacro:property name=\"mass\" value=\"0.5755\" /&gt;\n  &lt;xacro:property name=\"width\" value=\"0.1\" /&gt;\n  &lt;xacro:property name=\"height\" value=\"0.2\" /&gt;\n  &lt;xacro:property name=\"length\" value=\"0.4\" /&gt;\n  &lt;xacro:property name=\"wheel_radius\" value=\"0.1\" /&gt;\n  &lt;xacro:property name=\"wheel_length\" value=\"0.06\" /&gt;\n  &lt;xacro:property name=\"caster_radius\" value=\"0.05\" /&gt;\n  &lt;xacro:property name=\"body_inertia\"&gt;\n    &lt;inertia ixx=\"0.007\" ixy=\"0.0\" ixz=\"0.0\" iyy=\"0.007\" iyz=\"0.0\" izz=\"0.012\" /&gt;\n  &lt;/xacro:property&gt;\n\n  &lt;link name=\"chassis\"&gt;\n    &lt;inertial&gt;\n      &lt;mass value=\"${mass}\" /&gt;\n      &lt;origin xyz=\"0 0 0.1\"/&gt;\n      &lt;xacro:insert_block name=\"body_inertia\"/&gt;\n    &lt;/inertial&gt;\n\n    &lt;visual name='visual'&gt;\n      &lt;origin xyz=\"0 0 0.1\" rpy=\"0 0 0\" /&gt;\n      &lt;geometry&gt;\n        &lt;box size=\"${body_width} ${body_width} ${body_height}\"/&gt;\n      &lt;/geometry&gt;\n    &lt;/visual&gt;\n    &lt;visual name='visual_caster'&gt;\n      &lt;origin xyz=\"-0.15 0 0.05\" rpy=\"0 0 0\" /&gt;\n      &lt;geometry&gt;\n        &lt;sphere radius=\"${caster_radius}\"/&gt;\n      &lt;/geometry&gt;\n    &lt;/visual&gt;\n\n    &lt;collision name='collision'&gt;\n      &lt;origin xyz=\"0 0 0.1\" rpy=\"0 0 0\" /&gt;\n      &lt;geometry&gt;\n        &lt;box size=\"${body_width} ${body_width} ${body_height}\" /&gt;\n      &lt;/geometry&gt;\n    &lt;/collision&gt;\n    &lt;collision name='collision_caster'&gt;\n      &lt;origin xyz=\"0 0 0.1\" rpy=\"0 0 0\" /&gt;\n      &lt;contact_coefficients mu=\"0\"/&gt;\n      &lt;geometry&gt;\n        &lt;sphere radius=\"${caster_radius}\"/&gt;\n      &lt;/geometry&gt;\n    &lt;/collision&gt;\n  &lt;/link&gt;\n\n&lt;/robot&gt;\n</code></pre> <p>Notice that in this case the visual and collision blocks are identical. This is not always the case. Often, meshes are used for the visual block, while a primitive is used for the collision. This is helpful because gazebo would have a hard time calculating contacts on a mesh, but the simple primitive is much easier and faster.</p>"},{"location":"gazebo_tutorials/make_a_robot/#adding-joints","title":"Adding Joints","text":"<p>Now that we have the link, we can add links for both of the wheels, and a joint between them. I'm taking the liberty of limiting both the amount of effort allowed on the joint and limiting the velocity to show, but you can also limit the travel in the same way. More information about urdf joints can be found in the URDF ROS tutorials.</p> <pre><code>&lt;?xml version=\"1.0\"?&gt;\n\n&lt;robot name=\"pioneer\" xmlns:xacro=\"https://wiki.ros.org/xacro\"&gt;\n  &lt;xacro:property name=\"mass\" value=\"0.5755\" /&gt;\n  &lt;xacro:property name=\"width\" value=\"0.1\" /&gt;\n  &lt;xacro:property name=\"height\" value=\"0.2\" /&gt;\n  &lt;xacro:property name=\"length\" value=\"0.4\" /&gt;\n  &lt;xacro:property name=\"wheel_radius\" value=\"0.1\" /&gt;\n  &lt;xacro:property name=\"wheel_length\" value=\"0.06\" /&gt;\n  &lt;xacro:property name=\"caster_radius\" value=\"0.05\" /&gt;\n  &lt;xacro:property name=\"body_inertia\"&gt;\n    &lt;inertia ixx=\"0.007\" ixy=\"0.0\" ixz=\"0.0\" iyy=\"0.007\" iyz=\"0.0\" izz=\"0.012\" /&gt;\n  &lt;/xacro:property&gt;\n\n  &lt;link name=\"chassis\"&gt;\n    &lt;inertial&gt;\n      &lt;mass value=\"${mass}\" /&gt;\n      &lt;origin xyz=\"0 0 0.1\"/&gt;\n      &lt;xacro:insert_block name=\"body_inertia\"/&gt;\n    &lt;/inertial&gt;\n\n    &lt;visual name='visual'&gt;\n      &lt;origin xyz=\"0 0 0.1\" rpy=\"0 0 0\" /&gt;\n      &lt;geometry&gt;\n        &lt;box size=\"${body_width} ${body_width} ${body_height}\"/&gt;\n      &lt;/geometry&gt;\n    &lt;/visual&gt;\n    &lt;visual name='visual_caster'&gt;\n      &lt;origin xyz=\"-0.15 0 0.05\" rpy=\"0 0 0\" /&gt;\n      &lt;geometry&gt;\n        &lt;sphere radius=\"${caster_radius}\"/&gt;\n      &lt;/geometry&gt;\n    &lt;/visual&gt;\n\n    &lt;collision name='collision'&gt;\n      &lt;origin xyz=\"0 0 0.1\" rpy=\"0 0 0\" /&gt;\n      &lt;geometry&gt;\n        &lt;box size=\"${body_width} ${body_width} ${body_height}\" /&gt;\n      &lt;/geometry&gt;\n    &lt;/collision&gt;\n    &lt;collision name='collision_caster'&gt;\n      &lt;origin xyz=\"0 0 0.1\" rpy=\"0 0 0\" /&gt;\n      &lt;contact_coefficients mu=\"0\"/&gt;\n      &lt;geometry&gt;\n        &lt;sphere radius=\"${caster_radius}\"/&gt;\n      &lt;/geometry&gt;\n    &lt;/collision&gt;\n  &lt;/link&gt;\n\n  &lt;link name=\"right_wheel\"&gt;\n    &lt;inertial&gt;\n      &lt;mass value=\"0.1\" /&gt;\n      &lt;origin xyz=\"0.1 -0.13 0.1\" rpy=\"0 1.5707 1.5707\"/&gt;\n      &lt;inertia ixx=\"0.01\" ixy=\"0.0\" ixz=\"0.0\" iyy=\"0.01\" iyz=\"0.0\" izz=\"0.2\"/&gt;\n    &lt;/inertial&gt;\n\n    &lt;visual name=\"visual\"&gt;\n      &lt;geometry&gt;\n        &lt;cylinder length=\"0.05\" radius=\"0.1\"/&gt;\n      &lt;/geometry&gt;\n    &lt;/visual&gt;\n\n    &lt;collision name=\"collision\"&gt;\n      &lt;geometry&gt;\n        &lt;cylinder length=\"0.05\" radius=\"0.1\"/&gt;\n      &lt;/geometry&gt;\n    &lt;/collision&gt;\n  &lt;/link&gt;\n\n  &lt;link name=\"left_wheel\"&gt;\n    &lt;inertial&gt;\n      &lt;mass value=\"0.1\" /&gt;\n      &lt;origin xyz=\"0.1 0.13 0.1\" rpy=\"0 1.5707 1.5707\"/&gt;\n      &lt;inertia ixx=\"0.01\" ixy=\"0.0\" ixz=\"0.0\" iyy=\"0.01\" iyz=\"0.0\" izz=\"0.2\"/&gt;\n    &lt;/inertial&gt;\n\n    &lt;visual name=\"visual\"&gt;\n      &lt;geometry&gt;\n        &lt;cylinder length=\"0.05\" radius=\"0.1\"/&gt;\n      &lt;/geometry&gt;\n    &lt;/visual&gt;\n\n    &lt;collision name=\"collision\"&gt;\n      &lt;geometry&gt;\n        &lt;cylinder length=\"0.05\" radius=\"0.1\"/&gt;\n      &lt;/geometry&gt;\n    &lt;/collision&gt;\n  &lt;/link&gt;\n\n  &lt;joint name=\"left_wheel_joint\" type=\"revolute\"&gt;\n    &lt;axis xyz=\"0 1 0\"/&gt;\n    &lt;limit effort=\"1000.0\" velocity=\"0.5\"/&gt;\n    &lt;origin rpy=\"0 0 0\" xyz=\"0 0.03 0\"/&gt;\n    &lt;parent link=\"chassis\"/&gt;\n    &lt;child link=\"left_wheel\"/&gt;\n  &lt;/joint&gt;\n\n  &lt;joint name=\"right_wheel_joint\" type=\"revolute\"&gt;\n    &lt;axis xyz=\"0 1 0\"/&gt;\n    &lt;limit effort=\"1000.0\" velocity=\"0.5\"/&gt;\n    &lt;origin rpy=\"0 0 0\" xyz=\"0 -0.03 0\"/&gt;\n    &lt;parent link=\"chassis\"/&gt;\n    &lt;child link=\"right_wheel\"/&gt;\n  &lt;/joint&gt;\n\n&lt;/robot&gt;\n</code></pre>"},{"location":"gazebo_tutorials/make_a_robot/#loading-the-robot-in-gazebo","title":"Loading the Robot in Gazebo","text":"<p>Because we are using URDF files, rather than SDFs, we load the models a bit differently than as described in the Gazebo tutorials. The easiest way to load a model into gazebo is to use a modified version of the launch file provided in the rotorS_gazebo package developed by the ASL lab at ETH Zurich. Here is a copy of that file (it's found in rotor_gazebo-&gt;launch)</p> <pre><code>&lt;!-- spawn_mav.launch --&gt;\n&lt;launch&gt;\n  &lt;arg name=\"mav_name\" default=\"shredder\"/&gt;\n  &lt;arg name=\"model\" default=\"$(find fcu_sim)/urdf/$(arg mav_name)/$(arg mav_name).xacro\"/&gt;\n  &lt;arg name=\"tf_prefix\" default=\"$(optenv ROS_NAMESPACE)\"/&gt;\n  &lt;arg name=\"x\" default=\"0.0\"/&gt;\n  &lt;arg name=\"y\" default=\"0.0\"/&gt;\n  &lt;arg name=\"z\" default=\"1.0\"/&gt;\n  &lt;arg name=\"enable_ground_truth\" default=\"true\"/&gt;\n  &lt;arg name=\"enable_wind\" default=\"true\"/&gt;\n\n  &lt;!-- send the robot XML to param server --&gt;\n  &lt;param name=\"robot_description\" command=\"\n    $(find xacro)/xacro.py '$(arg model)'\n    enable_ground_truth:=$(arg enable_ground_truth)\n    mav_name:=$(arg mav_name)\"\n  /&gt;\n  &lt;param name=\"tf_prefix\" type=\"string\" value=\"$(arg tf_prefix)\" /&gt;\n\n  &lt;!-- push robot_description to factory and spawn robot in gazebo --&gt;\n  &lt;node name=\"spawn_$(arg mav_name)\" pkg=\"gazebo_ros\" type=\"spawn_model\"\n   args=\"-param robot_description\n         -urdf\n         -x $(arg x)\n         -y $(arg y)\n         -z $(arg z)\n         -model $(arg mav_name)\"\n   respawn=\"false\" output=\"screen\"&gt;\n  &lt;/node&gt;\n&lt;/launch&gt;\n</code></pre> <p>If you put your newly created .xacro file in the rotor_gazebo/xacro folder (as described in line 6), then call the spawn_mav launch file with \"pioneer\" as the \"mav_name\" argument, it will launch. Here is the example launch file code we use for loading shredder into gazebo</p> <pre><code>&lt;launch&gt;\n\n  &lt;arg name=\"mav_name\" default=\"shredder\"/&gt;\n  &lt;arg name=\"world_file\" default=\"cylinders4.world\"/&gt;\n\n\n  &lt;!-- Simulator --&gt;\n  &lt;include file=\"$(find gazebo_ros)/launch/empty_world.launch\"&gt;\n    &lt;arg name=\"world_name\" value=\"$(find fcu_sim)/worlds/$(arg world_file)\"/&gt;\n    &lt;arg name=\"paused\" value=\"true\"/&gt;\n    &lt;arg name=\"gui\" value=\"true\"/&gt;\n  &lt;/include&gt;\n  &lt;include file=\"$(find rotor_gazebo)/launch/spawn_mav.launch\"&gt;\n    &lt;arg name=\"mav_name\"            value=\"$(arg mav_name)\" /&gt;\n    &lt;arg name=\"model\"               value=\"$(find fcu_sim)/urdf/$(arg mav_name)/$(arg mav_name)_base.xacro\" /&gt;\n    &lt;arg name=\"enable_ground_truth\" value=\"true\" /&gt;\n    &lt;arg name=\"z\"                   value=\"0.08\"/&gt;\n  &lt;/include&gt;\n&lt;/launch&gt;\n</code></pre> <p>This is only a snippet from the actual launch file (relative_nav-&gt;sim.launch), but if you've done this part right, you should see your robot in the gazebo world.</p>"},{"location":"gazebo_tutorials/make_a_world/","title":"Make a World","text":""},{"location":"gazebo_tutorials/make_a_world/#making-a-world","title":"Making a World","text":"<p>One of the best parts of gazebo is how well it simulates environments.  In this lesson, we'll learn how to build our own environments and use them in our simulations. Worlds in gazebo are defined as SDFs.  These are very much like the xacro files we were using earlier, so like the xacros it's very strongly typed.  (most of the world files I've made are in the 1000's of lines long).  Don't let that dissuade you though, it's not very hard.</p>"},{"location":"gazebo_tutorials/make_a_world/#using-primitives","title":"Using Primitives","text":"<p>First, let's just use primitive shapes (the box, the cylinder, and the sphere).  Let's make an empty world, with one of each of them inside.  Open up a terminal and type</p> <pre><code> gazebo\n</code></pre> <p>This will open a blank gazebo window.  On the top toolbar, click the box and drag it somewhere in the world.  Repeat with the cylinder, and the sphere until you have one of each.</p> <p></p> <p>Then on the window menu, click \"Save World As\" and save the world somewhere. We can now use the resulting file to build the world.  You'll find different blocks in the file such as the one below which defines the box.</p> <pre><code>&lt;pre class=\"prettyprint\"&gt;\n    &lt;model name='unit_box_2'&gt;\n      &lt;pose&gt;1.41311 -4 0.5 0 -0 0&lt;/pose&gt;\n      &lt;link name='link'&gt;\n        &lt;inertial&gt;\n          &lt;mass&gt;1&lt;/mass&gt;\n          &lt;inertia&gt;\n            &lt;ixx&gt;1&lt;/ixx&gt;\n            &lt;ixy&gt;0&lt;/ixy&gt;\n            &lt;ixz&gt;0&lt;/ixz&gt;\n            &lt;iyy&gt;1&lt;/iyy&gt;\n            &lt;iyz&gt;0&lt;/iyz&gt;\n            &lt;izz&gt;1&lt;/izz&gt;\n          &lt;/inertia&gt;\n        &lt;/inertial&gt;\n        &lt;collision name='collision'&gt;\n          &lt;geometry&gt;\n            &lt;box&gt;\n              &lt;size&gt;1 1 1&lt;/size&gt;\n            &lt;/box&gt;\n          &lt;/geometry&gt;\n          &lt;max_contacts&gt;10&lt;/max_contacts&gt;\n          &lt;surface&gt;\n            &lt;bounce/&gt;\n            &lt;friction&gt;\n              &lt;ode/&gt;\n            &lt;/friction&gt;\n            &lt;contact&gt;\n              &lt;ode/&gt;\n            &lt;/contact&gt;\n          &lt;/surface&gt;\n        &lt;/collision&gt;\n        &lt;visual name='visual'&gt;\n          &lt;geometry&gt;\n            &lt;box&gt;\n              &lt;size&gt;1 1 1&lt;/size&gt;\n            &lt;/box&gt;\n          &lt;/geometry&gt;\n          &lt;material&gt;\n            &lt;script&gt;\n              &lt;uri&gt;file://media/materials/scripts/gazebo.material&lt;/uri&gt;\n              &lt;name&gt;Gazebo/Grey&lt;/name&gt;\n            &lt;/script&gt;\n          &lt;/material&gt;\n        &lt;/visual&gt;\n        &lt;velocity_decay&gt;\n          &lt;linear&gt;0&lt;/linear&gt;\n          &lt;angular&gt;0&lt;/angular&gt;\n        &lt;/velocity_decay&gt;\n        &lt;self_collide&gt;0&lt;/self_collide&gt;\n        &lt;kinematic&gt;0&lt;/kinematic&gt;\n        &lt;gravity&gt;1&lt;/gravity&gt;\n      &lt;/link&gt;\n      &lt;static&gt;0&lt;/static&gt;\n    &lt;/model&gt;\n&lt;/pre&gt;\n</code></pre> <p>You don't need everything in the above block to make it work.  But there are some important parts.</p> <ul> <li><code>pose</code> - This is the coordinates for the center of the box. x y z r p y</li> <li><code>mass</code>/<code>inerital</code> - you need these blocks for anything to appear at all</li> <li><code>collision</code> - you don't need to worry about the surface part of the block, but you will want to make sure collision is defined if you want it</li> <li><code>visual</code> - you can change the color by replacing Gazebo/Grey with something else.  This is a list of all available colors link</li> <li><code>velocity_decay</code>/<code>self_collide</code>/kinematic - you can ignore these block entirely</li> <li><code>static</code> - if 0, then it will move if it is crashed into.  If 1, then it will not move.  I generally make everything in my worlds static.</li> </ul> <p>After making those adjustments, I then copy the primitive block over and over, naming the subsequent models \"<code>box_1</code>, <code>box_2</code> ...\" and changing the pose and sizes as necessary.  This is how I made the cylinders worlds and the box worlds in the <code>rotor_gazebo</code> package.  Look at those files for reference.</p>"},{"location":"gazebo_tutorials/make_a_world/#editing-world-parameters","title":"Editing World Parameters","text":"<p>There are couple of other useful blocks in the file we just made.  Let's highlight a few of them.</p> <pre><code>&lt;pre class=\"prettyprint\"&gt;\n    &lt;physics type=\"ode\"&gt;\n      &lt;max_step_size&gt;0.001&lt;/max_step_size&gt;\n      &lt;real_time_factor&gt;1&lt;/real_time_factor&gt;\n      &lt;real_time_update_rate&gt;1000&lt;/real_time_update_rate&gt;\n      &lt;gravity&gt;0 0 -9.8&lt;/gravity&gt;\n    &lt;/physics&gt;\n&lt;/pre&gt;\n</code></pre> <p>This block is really useful if you are finding that your computer cannot run the simulation fast enough.  By increasing the <code>max_step_size</code>, and decreasing the <code>real_time_update_rate</code>, you can reduce the computational load.  You do have to make sure that <code>max_step_size</code> x <code>real_time_update_rate</code> = 1.0.  Otherwise, you'll run at slower than or faster than real time.  Here is an example of an ode block that lets us run our full simulation on a 5 year old computer.</p> <pre><code>&lt;pre class=\"prettyprint\"&gt;\n    &lt;physics name=\"ode_fast\" type=\"ode\" default=\"true\"&gt;\n      &lt;max_step_size&gt;0.03&lt;/max_step_size&gt;\n      &lt;gravity&gt;0 0 -9.8&lt;/gravity&gt;\n      &lt;real_time_factor&gt;1&lt;/real_time_factor&gt;\n      &lt;real_time_update_rate&gt;34&lt;/real_time_update_rate&gt;\n      &lt;ode&gt;\n        &lt;solver&gt;\n          &lt;type&gt;quick&lt;/type&gt;\n          &lt;iters&gt;70&lt;/iters&gt;\n        &lt;/solver&gt;\n      &lt;/ode&gt;\n    &lt;/physics&gt;\n&lt;/pre&gt;\n</code></pre> <p>I also changed the default number of ode solve iterations from 1000 to 70 to reduce computation as well.</p> <p>The next useful block is the gui block, as follows:</p> <pre><code>&lt;pre class=\"prettyprint\"&gt;\n    &lt;gui fullscreen='0'&gt;\n      &lt;camera name='user_camera'&gt;\n        &lt;pose&gt;8.68371 -6.64602 3.18089 0 0.275643 2.35619&lt;/pose&gt;\n        &lt;view_controller&gt;orbit&lt;/view_controller&gt;\n      &lt;/camera&gt;\n    &lt;/gui&gt;\n&lt;/pre&gt;\n</code></pre> <p>Namely, the fullscreen and pose parts.  This positions the camera view for the simulation. I find that the best way to get this is to build your world, move the camera into position, then save the world and copy just this block to get the camera right.</p> <p>There is usually a very large state block.  This describes exactly how all of your models are oriented in the world, which is unnecessary for what we want to do.  I generally delete this block entirely.</p> <p>Any other block in the file should probably be left.  I'm not sure what everything in there does, so I can't say for sure whether it's important or not.</p>"},{"location":"gazebo_tutorials/make_a_world/#more-complicated-worlds","title":"More Complicated Worlds","text":"<p>You can add more complicated models by using the \"Insert\" Tab, and looking under the http:gazebosim.org/models.  This will download the model you click on and add it to the world.  There are  number of models there which you can use to build more complicated environments (such as the international space station and the fire hydrant blow).  When you're done building, simply click \"Save World As\" and put it somewhere you can find it.  (<code>rotor_gazebo/worlds</code> is a great place to put it).</p> <p></p> <p>These models can be saved into a world file just like the primitives and manipulated the same way.</p> <p>If you're interested in building your own models and adding them to the world, you'll have to read up on the gazebo tutorials</p>"},{"location":"gazebo_tutorials/overview/","title":"Gazebo","text":""},{"location":"gazebo_tutorials/overview/#gazebo-overview","title":"Gazebo Overview","text":"<p>Gazebo is a simulator engine used with ROS.  It uses Ogre3d to render the simulation, and has a built-in physics engine to calculate friction, dynamics, forces, gravity, etc... and can be a very powerful tool for simulating any variety of sensors such as cameras, laser scanners, IMUs, GPS, etc...  We can use the simulator to test ROS code before putting it in hardware, effectively increasing the rate at which we develop code, and help ensure we don't do something stupid with the hardware.</p> <p>Gazebo loads worlds from xml files called SDF's.  These define all the parts of a robot, the \"links\" which are the parts of a robot that has mass, the \"joints\" which hold all the links together, and the \"plugins\" which are executables attached to links.  These plugins are used for simulating sensors (and for simulating aerodynamics in our case).</p> <p>The MAGICC lab has simulators built up for multirotor and fixed wing UAVs wrapped around ROSPlane and ROSCopter. These can be found on the MAGICC github. </p>"},{"location":"gazebo_tutorials/assignments/flying_your_mav/","title":"Flying Your MAV","text":""},{"location":"gazebo_tutorials/assignments/flying_your_mav/#flying-your-mav_1","title":"Flying Your MAV","text":"<p>In this assignment, you'll fly the MAV you made earlier. </p>"},{"location":"gazebo_tutorials/assignments/flying_your_mav/#multirotor","title":"Multirotor","text":"<p>Use the launch file in the previous lesson to launch your MAV with joystick commands. (You'll need a joystick). Because different joysticks have different mappings, you may need to change the parameters in the launch file to get your MAV to act appropriately. While that sounds easy, getting parameters to agree is probably the hardest part of getting the simulation to work properly, hence that is your assignment. The default mapping is included in the yaml file loaded by the <code>joy_sim</code> node. The <code>sim_reset</code> node is also included to allow you to restart your simulation without closing gazebo and re-launching. It writes to the <code>set_model_state</code> topic and resets everything when you press the reset button (default is start if your mappings are right). </p> <pre><code>&lt;launch&gt;\n  &lt;arg name=\"mav_name\"            default=\"hummingbird\"/&gt;\n\n  &lt;!-- Start Gazebo --&gt;\n  &lt;include file=\"$(find gazebo_ros)/launch/empty_world.launch\"&gt;\n    &lt;arg name=\"world_name\" value=\"$(find rotor_gazebo)/worlds/basic.world\"/&gt;\n    &lt;arg name=\"paused\" value=\"false\"/&gt;\n    &lt;arg name=\"gui\" value=\"true\"/&gt;\n  &lt;/include&gt;\n\n  &lt;!-- Spawn MAV --&gt;\n  &lt;include file=\"$(find rotor_gazebo)/launch/spawn_mav.launch\"&gt;\n    &lt;arg name=\"mav_name\"            value=\"$(arg mav_name)\" /&gt;\n    &lt;arg name=\"model\"               value=\"$(find rotor_gazebo)/urdf/$(arg mav_name)/$(arg mav_name)_base.xacro\" /&gt;\n  &lt;/include&gt;\n\n  &lt;!-- Joystick --&gt;\n  &lt;node name=\"xbox\"                pkg=\"joy\"                 type=\"joy_node\"/&gt;\n  &lt;node name=\"joy_sim\" pkg=\"joy_sim\" type=\"joy_sim\" &gt;\n    &lt;rosparam command=\"load\" file=\"$(find joy_sim)/param/xbox.yaml\"/&gt;\n    &lt;rosparam command=\"load\" file=\"$(find joy_sim)/param/$(arg mav_name).yaml\"/&gt;\n  &lt;/node&gt;\n  &lt;node name=\"sim_reset\" pkg=\"sim_reset\" type=\"sim_reset_node\"&gt;\n    &lt;param name=\"reset_button\" value=\"9\"/&gt;\n    &lt;param name=\"model_name\" value=\"$(arg mav_name)\"/&gt;\n  &lt;/node&gt;\n\n  &lt;!-- Attitude Control --&gt;\n  &lt;rosparam command=\"load\" file=\"$(find attitude_controller)/param/$(arg mav_name).yaml\"/&gt;\n  &lt;node name=\"attitude_controller\" pkg=\"attitude_controller\" type=\"attitude_controller_node\"&gt;\n    &lt;rosparam command=\"load\" file=\"$(find rotor_gazebo)/param/$(arg mav_name).yaml\"/&gt;\n    &lt;remap from=\"odometry\" to=\"$(arg mav_name)/ground_truth/odometry\"/&gt;\n    &lt;remap from=\"command/motor_speed\" to=\"$(arg mav_name)/gazebo/command/motor_speed\"/&gt;\n  &lt;/node&gt;\n&lt;/launch&gt;\n</code></pre>"},{"location":"gazebo_tutorials/assignments/flying_your_mav/#tune-the-attutude-controller","title":"Tune the Attutude Controller","text":"<p>You'll also need to tune your attitude controller. Lucky for you, the attitude controller has been built with dynamic reconfigure. This means that you can change parameters on the fly. When you first launch the controller, it will read defaults from the yaml file in the attitude controller node block, however, if while the simulation is running, you type </p> <pre><code>rosrun rqt_reconfigure rqt_reconfigure\n</code></pre> <p>Something like the following window will appear  This will allow you to change the gains on the fly. Parameters from <code>rqt_reconfigure</code> are not saved on close. Once you've tuned in your gains, change the defaults in the yaml file loaded by the attitude controller node. </p>"},{"location":"gazebo_tutorials/assignments/flying_your_mav/#fixed-wing","title":"Fixed Wing","text":"<p>Flying the Fixed Wing is even easier. Well, it's easier to set up in ROS, but it's actually really hard to fly in gazebo with joysticks. The same <code>joy_sim</code> node can be used, but gazebo will use the <code>/FWcommand</code> topic.</p> <pre><code>  &lt;arg name=\"mav_name\"            default=\"junker\"/&gt;\n\n  &lt;include file=\"$(find gazebo_ros)/launch/empty_world.launch\"&gt;\n    &lt;arg name=\"world_name\" value=\"$(find rotor_gazebo)/worlds/blue.world\"/&gt;\n    &lt;arg name=\"paused\" value=\"false\"/&gt;\n    &lt;arg name=\"gui\" value=\"true\"/&gt;r\n  &lt;/include&gt;\n\n  &lt;!-- Spawn MAV --&gt;\n  &lt;include file=\"$(find rotor_gazebo)/launch/spawn_mav.launch\"&gt;\n    &lt;arg name=\"mav_name\"            value=\"$(arg mav_name)\" /&gt;\n    &lt;arg name=\"model\"               value=\"$(find rotor_gazebo)/urdf/$(arg mav_name)/$(arg mav_name)_base.xacro\" /&gt;\n  &lt;/include&gt;\n\n  &lt;!-- Joystick --&gt;\n  &lt;node name=\"xbox\"                pkg=\"joy\"                 type=\"joy_node\"/&gt;\n  &lt;node name=\"joy_sim\" pkg=\"joy_sim\" type=\"joy_sim\" &gt;\n    &lt;rosparam command=\"load\" file=\"$(find joy_sim)/param/xbox.yaml\"/&gt;\n  &lt;/node&gt;\n  &lt;node name=\"sim_reset\" pkg=\"sim_reset\" type=\"sim_reset_node\"&gt;\n    &lt;param name=\"reset_button\" value=\"9\"/&gt;\n    &lt;param name=\"model_name\" value=\"$(arg mav_name)\"/&gt;\n  &lt;/node&gt;\n\n&lt;/launch&gt;\n</code></pre> <p>It is also really difficult to get orientation in gazebo. As a result, I have created a world with a blue floor instead of gray. It's boring, and really quite ugly, but it allows you to see the horizon. The following launch file will generate the junker model and allow you to fly it. </p> <p>you may wish to view the chase camera, rather than the gazebo window. To do this, simply type  <pre><code>rosrun image_view image_view image:=/junker/camera/chase/rgb\n</code></pre> or add it to the launch file as follows:  <pre><code>  &lt;node name=\"chase_camera\" pkg=\"image_view\" type=\"image_view\"&gt;\n    &lt;remap from=\"image\" to=\"$(arg mav_name)/camera/chase/rgb\"/&gt;\n  &lt;/node&gt;\n</code></pre> As with the multirotor, you will probably need to change the mappings on your joystick to control it properly, but it flies like an airplane! </p>"},{"location":"gazebo_tutorials/assignments/make_a_fixed_wing_mav/","title":"Making a Fixed Wing MAV","text":""},{"location":"gazebo_tutorials/assignments/make_a_fixed_wing_mav/#making-a-fixed-wing-mav_1","title":"Making a Fixed Wing MAV","text":"<p>In this assignment, we will build a fixed wing MAV. This is very similar to the previous assignment, except this time we will be copying the junker files in <code>rotor_gazebo</code> instead of the multirotor files.</p> <p>The xacro file is particularly intimidating, mostly because of the large number of parameters required for the forces and moments plugin. Don't let this bother you. It's just a text file.</p> <p>As an example, in the case you skipped the multirotor assignment, if I were building a new fixed wing MAV called \"ares\" the file structure would appear as follows, with the new files highlighted in bold, based on the junker equivalents. In the case of a fixed-wing. We don't need a yaml file for a ROS-based attitude controller like we do to calculate mixing in the multirotor.</p> <pre><code>fcu_sim\n+-- attitude_controller\n+-- joy_sim\n+-- fcu_sim\n|    |-- CMakeLists.txt\n|    |-- package.xml\n|    +-- cmake\n|    +-- include\n|    |-- launch\n|    |    |-- spawn_mav.launch\n|    |    |-- test.launch\n|    |    |-- ...\n|    |    |\n|    |-- meshes\n|    |    |-- shredder.dae\n|    |    |-- junker.dae\n|    |    |-- ares.dae\n|    |    |-- ...\n|    |    |\n|    +-- msg\n|    +-- param\n|    |-- urdf\n|    |    +-- shredder\n|    |    +-- hummingbird\n|    |    |-- ares\n|    |    |   |-- ares_base.xacro\n|    |    |-- ...\n|    |    |\n|    +-- worlds\n+-- fcu_sim_plugins\n+-- sim_reset\n</code></pre>"},{"location":"gazebo_tutorials/assignments/make_a_fixed_wing_mav/#the-forces-and-moments-plugin","title":"The Forces and Moments Plugin","text":"<p>Just like the multirotor, because Gazebo doesn't support aerodynamics, we apply a plugin to the MAV which takes the various states of the aircraft in the simulator and applies forces and moments to the parent_link. The forces and moments plugin is built following the method in the UAV book. We will talk about how that file is built in the next tutorial.</p>"},{"location":"gazebo_tutorials/assignments/make_a_fixed_wing_mav/#launch-file","title":"Launch File","text":"<p>To help you a little more, here is a sample <code>test.launch</code> that you might use to launch your MAV. If your file structure is correct, this will launch gazebo and put your new MAV in the gazebo world. <pre><code>&lt;launch&gt;\n  &lt;arg name=\"mav_name\"            default=\"titan\"/&gt;\n\n  &lt;include file=\"$(find gazebo_ros)/launch/empty_world.launch\"&gt;\n    &lt;arg name=\"world_name\" value=\"$(find fcu_sim)/worlds/basic.world\"/&gt;\n    &lt;arg name=\"paused\" value=\"false\"/&gt;\n    &lt;arg name=\"gui\" value=\"true\"/&gt;\n  &lt;/include&gt;\n\n  &lt;!-- Spawn MAV --&gt;\n  &lt;include file=\"$(find rotor_gazebo)/launch/spawn_mav.launch\"&gt;\n    &lt;arg name=\"mav_name\"            value=\"$(arg mav_name)\" /&gt;\n    &lt;arg name=\"model\"               value=\"$(find fcu_sim)/urdf/$(arg mav_name)/$(arg mav_name)_base.xacro\" /&gt;\n  &lt;/include&gt;\n&lt;/launch&gt;\n</code></pre></p>"},{"location":"gazebo_tutorials/assignments/make_a_multirotor/","title":"Making a Multirotor","text":""},{"location":"gazebo_tutorials/assignments/make_a_multirotor/#making-a-multirotor_1","title":"Making a Multirotor","text":"<p>For this assignment, you are to make your own multirotor. It doesn't need to fly, but you should be able to load your model into gazebo and see it.</p> <p>If I were making a new MAV, I would duplicate either the hummingbird or the shredder files and rename them, then make the necessary changes. This is by far the easiest way to build a multirotor. For example, if I were making a new multirotor called \"titan\" the new file structure would look as follows, with new files bolded, based on the hummingbird and shredder equivalents.</p> <pre><code>fcu_sim\n+-- attitude_controller\n+-- joy_sim\n+-- fcu_sim\n|    |-- CMakeLists.txt\n|    |-- package.xml\n|    +-- cmake\n|    +-- include\n|    |-- launch\n|    |    |-- spawn_mav.launch\n|    |    |-- test.launch\n|    |    |-- ...\n|    |    |\n|    |-- meshes\n|    |    |-- firefly.dae\n|    |    |-- hummingbird.dae\n|    |    |-- titan.dae\n|    |    |-- ...\n|    |    |\n|    +-- msg\n|    |-- param\n|    |    |-- hummingbird.yaml\n|    |    |-- shredder.yaml\n|    |    |-- titan.yaml\n|    |    |-- ...\n|    |    |\n|    |-- urdf\n|    |    +-- shredder\n|    |    +-- hummingbird\n|    |    |-- titan\n|    |    |   |-- titan_base.xacro\n|    |    |-- ...\n|    |    |\n|    +-- worlds\n+-- fcu_sim_plugins\n+-- sim_reset\n</code></pre>"},{"location":"gazebo_tutorials/assignments/make_a_multirotor/#yaml-file","title":"YAML File","text":"<p>We haven't yet talked about the YAML file. For now, the YAML file describes the same physical constants in the .xacro file. As it currently stands, the YAML file is used by ROS to correctly implement the attitude controller whereas the xacro file is used by gazebo to define the dynamics. In future iterations of the rotor_gazebo package, these could maybe be combined into a single YAML file, but that is complicated to get right. Until then, you'll need to make sure that the two match. It's a little confusing to have the two files, but it's necessary to ensure that both ROS and Gazebo know how the MAV is configured. (An example of how this could be done.)</p>"},{"location":"gazebo_tutorials/assignments/make_a_multirotor/#xacro-file-features","title":"Xacro File Features","text":"<p>Another thing to note is that because gazebo doesn't understand aerodynamics natively, there is a \"multirotor_base_plugin\" included in the relevant xacro. This plugin applies forces and torques to its parent_link based on motor speeds. The rotors are also connected to a plugin which are instantiated by the \"vertical rotor\" xacro. They model the propellers speeding up and slowing down as a first-order system based on the time_constant arguments. After building your model, you may need to adjust these constants to better reflect the performance of your MAV.</p>"},{"location":"gazebo_tutorials/assignments/make_a_multirotor/#launch-file","title":"Launch File","text":"<p>To help you a little more, here is a sample <code>test.launch</code> that you might use to launch your MAV. If your file structure is correct, this will launch gazebo and put your new MAV in the gazebo world. <pre><code>&lt;launch&gt;\n  &lt;arg name=\"mav_name\"            default=\"titan\"/&gt;\n\n  &lt;include file=\"$(find gazebo_ros)/launch/empty_world.launch\"&gt;\n    &lt;arg name=\"world_name\" value=\"$(find fcu_sim)/worlds/basic.world\"/&gt;\n    &lt;arg name=\"paused\" value=\"false\"/&gt;\n    &lt;arg name=\"gui\" value=\"true\"/&gt;\n  &lt;/include&gt;\n\n  &lt;!-- Spawn MAV --&gt;\n  &lt;include file=\"$(find rotor_gazebo)/launch/spawn_mav.launch\"&gt;\n    &lt;arg name=\"mav_name\"            value=\"$(arg mav_name)\" /&gt;\n    &lt;arg name=\"model\"               value=\"$(find fcu_sim)/urdf/$(arg mav_name)/$(arg mav_name)_base.xacro\" /&gt;\n  &lt;/include&gt;\n&lt;/launch&gt;\n</code></pre></p>"},{"location":"gazebo_tutorials/assignments/make_your_own_world/","title":"Make Your Own Gazebo World","text":""},{"location":"gazebo_tutorials/assignments/make_your_own_world/#make-your-own-gazebo-world_1","title":"Make Your Own Gazebo World","text":"<p>Using the methods described in the previous lesson, build a world, and fly your MAV in it.  You will probably want to use your multirotor unless you want to make a really big world for your fixed wing MAV.</p> <p>save the world in <code>rotor_gazebo/worlds</code> and use the <code>test.launch</code> file supplied below, changing the <code>mav_name</code> and <code>world_file</code> lines appropriately</p> <pre><code>&lt;pre class=\"prettyprint\"&gt;\n&lt;launch&gt;\n  &lt;arg name=\"mav_name\"            default=\"hummingbird\"/&gt;\n  &lt;arg name=\"world_file\"          default=\"your_world.world\"/&gt;\n\n  &lt;include file=\"$(find gazebo_ros)/launch/empty_world.launch\"&gt;\n    &lt;arg name=\"world_name\" value=\"$(find rotor_gazebo)/worlds/$(arg world_file)\"/&gt;\n    &lt;arg name=\"paused\" value=\"false\"/&gt;\n    &lt;arg name=\"gui\" value=\"true\"/&gt;r\n  &lt;/include&gt;\n\n  &lt;!-- Spawn MAV --&gt;\n  &lt;include file=\"$(find rotor_gazebo)/launch/spawn_mav.launch\"&gt;\n    &lt;arg name=\"mav_name\"            value=\"$(arg mav_name)\" /&gt;\n    &lt;arg name=\"model\"               value=\"$(find rotor_gazebo)/urdf/$(arg mav_name)/$(arg mav_name)_base.xacro\" /&gt;\n  &lt;/include&gt;\n\n  &lt;!-- Joystick --&gt;\n  &lt;node name=\"xbox\"                pkg=\"joy\"                 type=\"joy_node\"/&gt;\n  &lt;node name=\"joy_sim\" pkg=\"joy_sim\" type=\"joy_sim\" &gt;\n    &lt;rosparam command=\"load\" file=\"$(find joy_sim)/param/xbox.yaml\"/&gt;\n    &lt;rosparam command=\"load\" file=\"$(find joy_sim)/param/$(arg mav_name).yaml\"/&gt;\n  &lt;/node&gt;\n  &lt;node name=\"sim_reset\" pkg=\"sim_reset\" type=\"sim_reset_node\"&gt;\n    &lt;param name=\"reset_button\" value=\"9\"/&gt;\n    &lt;param name=\"model_name\" value=\"$(arg mav_name)\"/&gt;\n  &lt;/node&gt;\n\n  &lt;!-- Attitude Control --&gt;\n  &lt;rosparam command=\"load\" file=\"$(find attitude_controller)/param/$(arg mav_name).yaml\"/&gt;\n  &lt;node name=\"attitude_controller\" pkg=\"attitude_controller\" type=\"attitude_controller_node\"&gt;\n    &lt;rosparam command=\"load\" file=\"$(find rotor_gazebo)/param/$(arg mav_name).yaml\"/&gt;\n    &lt;remap from=\"odometry\" to=\"$(arg mav_name)/ground_truth/odometry\"/&gt;\n    &lt;remap from=\"command/motor_speed\" to=\"$(arg mav_name)/gazebo/command/motor_speed\"/&gt;\n  &lt;/node&gt;\n&lt;/launch&gt;\n&lt;/pre&gt;\n</code></pre> <p>Here is a screenshot of the motion capture room with the hummingbird MAV inside.  To build this world, I used only boxes of different colors.</p> <p></p>"},{"location":"hw_guides/asus_xtion_pro_live/","title":"ASUS Xtion Pro Live","text":""},{"location":"hw_guides/asus_xtion_pro_live/#asus-xtion-pro-live","title":"ASUS Xtion Pro Live","text":"<p>ASUS Xtion Pro Live</p>"},{"location":"hw_guides/asus_xtion_pro_live/#firmware-update","title":"Firmware Update","text":"<p>Out of the box this sensor will not function properly if plugged into a USB 3.0 port (or on some computers where the USB 2.0 ports actually run through a USB 3.0 hub). This can be fixed by upgrading the firmware on the sensor using the following steps:</p> <ol> <li>Boot into Windows (sorry)</li> <li>Download the firmware update tool from the ASUS website (https://dlcdnet.asus.com/pub/ASUS/MM/Xtion_Pro/FWUpdate_5_8_22.zip)</li> <li>Unzip the archive and run FWUpdate_RD180x-5.8.22.exe</li> </ol> <p>Note that after upgrading the firmware, the sensor is only compatible with OpenNI2 and not OpenNI. It will still work if plugged into a USB 2.0 port.</p>"},{"location":"hw_guides/c94_m8p/","title":"RTK GPS: C94-M8P Evaluation Boards","text":"<p>Real Time Kinematics (RTK) is a GNSS technique to achieve high accuracy (about 2-5cm) in the vicinity of the GPS receiver designated as the base station. RTK falls under the umbrella of differential GPS (DGPS) methods and so requires at least two GPS receivers. One of the GPS modules is termed the base station while the GPS module(s) that move are termed rovers.</p> <p>Because RTK GPS often requires additional infrastructure (i.e., a stationary base station), it may not be ideal for algorithms, but can be extremely helpful for analysis (i.e., \"ground truth\" comparisons for visual tracking). However, it is possible to have a moving baseline where both the base station and the rover move. You could imagine a base station and a rover attached to a left and right wing of a plane. The result is called GPS compassing and while the absolute positioning accuracy is low, the attitude determination is very good.</p> <p>You can learn more about the operating principle of RTK GPS at navipedia's article on RTK Fundamentals.</p>"},{"location":"hw_guides/c94_m8p/#rtk-enabled-gnss-modules","title":"RTK-Enabled GNSS Modules","text":"<p>One of the most popular GNSS companies is u-blox, a Swiss company that has its roots in ETH-Zurich. They provide the NEO-M8P GNSS module that has integrated RTK capability (as opposed to the M8T module that provides raw information and requires the use of off-board RTK processing from something like <code>RTKLIB</code>). There are two products in this series:</p> <ul> <li>NEO-M8P-0: GNSS module with rover functionality (i.e., essentially a regular GPS module). [around $100]</li> <li>NEO-M8P-2: GNSS module with rover and base station functionality. [around $120]</li> </ul> <p>You should probably always prefer the NEO-M8P-2 because of its flexibility.</p>"},{"location":"hw_guides/c94_m8p/#c94-m8p-evaluation-boards","title":"C94-M8P Evaluation Boards","text":"<p>For $300, u-blox sells evaluation boards (EVBs) for the NEO-M8P-2.</p> <p>The C94-M8P is a $300 package that contains two evaluation boards (EVBs) based on the NEO-M8P-2. Not only do these boards have the RTK-enabled NEO-M8P GNSS module, but they also have an integrated radio link (which is based on the HopeRF HM-TRP with SiK 1.9 firmware -- think 3DR telemetry radio for the Pixhawk). The purpose of the integrated radio is to transmit GPS/RTK corrections (via RTCM3 messages) from the base station to the rover.</p> <p>At the time of this writing (May 2018), the Electromagnetic Measurement Group (Dr. Brian Mazzeo's lab) has two sets of EVBs (total of 4 boards):</p> <ul> <li>C94-M8P-B</li> <li>C94-M8P-E</li> </ul> <p>Note the difference between Rev B and Rev E (currently the newest revision).</p>"},{"location":"hw_guides/c94_m8p/#getting-rtk-running-with-two-c94-m8p-evbs","title":"Getting RTK Running with Two C94-M8P EVBs","text":"<p>We will follow the User Guide to get the RTK working with two EVBs. A video tutorial on the hardware and configuration of the C94-M8P boards for RTK GPS can be found here. Note that the u-center configuration program that is used for connecting to the EVB is a Windows-only application. However, we will forgive u-blox because we can use Wine to run u-center on Linux.</p>"},{"location":"hw_guides/c94_m8p/#setup","title":"Setup","text":""},{"location":"hw_guides/c94_m8p/#configuration","title":"Configuration","text":""},{"location":"hw_guides/c94_m8p/#field-test","title":"Field Test","text":""},{"location":"hw_guides/c94_m8p/#using-one-c94-m8p-base-station-with-multiple-rovers","title":"Using One C94-M8P Base Station with Multiple Rovers","text":""},{"location":"hw_guides/c94_m8p/#pixhawkapm-rtk-gps-integration","title":"Pixhawk/APM RTK GPS Integration","text":""},{"location":"hw_guides/c94_m8p/#running-u-center-on-linux-with-wine","title":"Running u-center on Linux with Wine","text":"<p>This has been tested with u-center v8.29 and Wine 3.0.1 on Ubuntu 16.04. More discussion can be found here.</p>"},{"location":"hw_guides/c94_m8p/#install-wine","title":"Install Wine","text":"<p>Because the Wine that is packaged with Ubuntu is outdated, install Wine directly from WineHQ's repository following these instructions.</p> <pre><code>sudo dpkg --add-architecture i386\n\nwget -nc https://dl.winehq.org/wine-builds/Release.key\nsudo apt-key add Release.key\nsudo apt-add-repository https://dl.winehq.org/wine-builds/ubuntu/\n\nsudo apt update\n\nsudo apt install --install-recommends winehq-stable\n</code></pre> <p>Note: Make sure that you remove old installations and any old PPAs with Wine in them (check <code>/etc/apt/sources.list</code> and <code>/etc/apt/sources.list.d/</code>. While you are there, make sure that the <code>i386</code> architecture is not disabled for <code>universe</code> package -- i.e., there are no <code>[arch=amd64]</code> to only use <code>amd64</code>).</p> <p>Configure Wine using <code>winecfg</code> to use Windows Version 10.</p>"},{"location":"hw_guides/c94_m8p/#install-u-center","title":"Install u-center","text":"<p>Download u-center for Windows. Install in default location. After installation, u-center should launch.</p>"},{"location":"hw_guides/c94_m8p/#add-an-alias-for-convenience","title":"Add an Alias for Convenience","text":"<p>In order to run u-center, you have give the <code>wine</code> command the full path. Instead, you could create an alias in your <code>~/.bashrc</code>:</p> <pre><code>alias ucenter='wine \"/home/user/.wine/drive_c/Program Files (x86)/u-blox/u-center_v8.29/u-center.exe\"'\n</code></pre> <p>After re-sourcing (<code>. ~/.bashrc</code>) you can use the <code>ucenter</code> command to open u-center.</p>"},{"location":"hw_guides/c94_m8p/#add-a-udev-rule","title":"Add a <code>udev</code> Rule","text":"<p>Everything in Linux is considered a file. For example, hardware devices appear in <code>/dev/</code> as files (<code>inodes</code>). Adding a <code>udev</code> rule tells the OS Device Manager to create a symlink at specific spot each time the same device (as determined by its <code>idProduct</code>, <code>idVendor</code>, and other identifiers) is plugged in.</p> <p>Create the following <code>udev</code> rule and place it in <code>/etc/udev/rules.d/99-ublox-gps.rules</code>:</p> <pre><code># u-blox C94-M8P\nACTION==\"add\", SUBSYSTEM==\"tty\", ATTRS{idProduct}==\"01a8\", ATTRS{idVendor}==\"1546\", SYMLINK+=\"ublox\"\n</code></pre> <p>Then, reload and trigger with:</p> <pre><code>sudo udevadm control --reload-rules\nsudo udevadm trigger # alternatively, unplug and plug back in\n</code></pre> <p>Now every time the EVB is plugged in, it will show up as <code>/dev/ublox</code>. Note that this was only tested for a single EVB at a time.</p>"},{"location":"hw_guides/c94_m8p/#link-a-winewindows-com-port-to-the-linux-device","title":"Link a Wine/Windows COM port to the Linux Device","text":"<p>Windows uses COM ports and Linux uses <code>/dev</code> devices. Wine creates a bridge between the two in <code>~/.wine/dosdevices</code>. Create COM port that u-center can see with:</p> <pre><code>cd ~/.wine/dosdevices\nln -s /dev/ublox com40\n</code></pre> <p>In u-center, COM40 will always point to your device.</p>"},{"location":"hw_guides/charging_lipo_batts/","title":"Li-Po Battery Charger User Guide","text":"<p>Attention! Please charge responsibly.</p> <p>Attention! Please read through this entire document before you begin the process of following the instructions in each line item.</p> <p>Note: MAGICC Safety is an individual and a community responsibility. There is nothing magic about it.</p> <ol> <li>Read the MAGICC Lab Wiki page on Safety: magicc.byu.edu/wiki/safety</li> <li>Read the MAGICC Lab Wiki page on Batteries: magicc.byu.edu/wiki/hw_guides/lipo_batts</li> <li>Internalize the Safety page - etch it onto your brainstem</li> <li>Internalize the Battery page - etch it onto your frontal lobe</li> <li>Place your battery in a metal case atop the charging cases</li> <li>Press \"Type\" until the display says \"Li-Po\" (if you get this step wrong, there will be a fire)</li> <li>Triple check how many cells your battery has</li> <li>Press \"Next\" until the display flashes \"X__s\" where __X is the number of cells in your battery</li> <li>Press the up/down arrows until the number of cells of your battery is displayed</li> <li>Press \"Next\"</li> <li>Triple check the capacity of your battery (e.g. 2000mAh, which is also 2Ah)</li> <li>Press the up/down arrows until your battery's capacity is shown</li> <li>Press \"Next\"</li> <li>Charge rate:</li> <li>If you are on a short timeline, and need the battery to charge quickly, reassess your timeline. The more often that you charge your battery at a high amperage rate, the shorter the longevity of your battery will be. Please do not waste lab resources more quickly than necessary. If you can charge the battery a little slower, that is always better</li> <li>Besides, slower charge rates lower risk of fire</li> <li>For slower charging (but still reasonable) multiply your battery's capacity (in Ah) by 0.5/hour (e.g. for a 2000mAh battery, \u2192 2Ah * (0.5/h) = 1A)</li> <li>If you have all day, use a lower multiplier. Trickle charging is best, and safest</li> <li>For faster charging, multiply your battery's capacity (in Ah) by 1/hour. (e.g. 2000mAh battery \u2192 2Ah * (1/h) = 2A charge rate)</li> <li>Some batteries claim to safely charge at a \"5C\" charge rate. I personally strongly discourage charge rates that high. We can't afford to burn the engineering building to the ground. On such batteries, though, if you absolutely must charge faster than \"1C\", reconsider your timeline. It may be inconvenient to re-schedule a flight test, but that is infinitely more convenient than the building burning down over your impatience</li> <li>The MAGICC Lab protocol allows for \"2C\" max in the most dire of situations (e.g. 2000mAh battery \u2192 2Ah * (2/hour) = 4A charging on the charger display)</li> <li>Plug the cell wires into the balancer board</li> <li>Plug the main power wires into the charge port</li> <li>Long press the \"Start\" button</li> <li>Wait for the confirmation that charging has started</li> <li>Put an orange rock in your pocket, or, in the middle of your keyboard (i.e. the point is, somewhere where you will NOT forget about it)</li> <li>Do NOT leave the lab while the battery is charging</li> <li>If you must leave, even for 1 second, ask another person in the lab to take full responsibility for the battery</li> <li>If the other person accepts, give the orange rock to them</li> <li>If they do not accept, you may not leave the lab without first stopping the charge process, and completely unplugging the battery from the charger</li> <li>When the charge cycle completes, verify the voltages are similar across all cells in battery; this can be done by cycling through MODE on the charger display</li> <li>Make sure the charge process has actually stopped (i.e. real-time amperage is 0.0A)</li> <li>Press STOP a few times, just to be sure</li> <li>Unplug the main power connector from your battery</li> <li>Unplug the cell voltage wires from the balancer board</li> <li>You may now return your orange rock to the appropriate location on the charging bench</li> <li>You may now use your charged battery. Please do not drop it, as even dented cells are not worth the risk of burning down the building, or your vehicle. It is cheaper to replace a battery than the building, and batteries are cheaper and easier to replace than most vehicles</li> </ol>"},{"location":"hw_guides/design_propulsion_system/","title":"Designing a Propulsion System","text":""},{"location":"hw_guides/design_propulsion_system/#vehicle-power-system-recommendations","title":"Vehicle Power-System Recommendations","text":""},{"location":"hw_guides/design_propulsion_system/#best-practices","title":"Best Practices","text":"<p>Please read thoroughly all of the following instructions and tips. DJI has expensive vehicles because a lot of effort is necessary to assemble a successful vehicle. If you skimp on effort at the design and assembly stage, by not being aware of the following tips learned through extensive experience and research, you could end up having to start over to replace a pile of ashes. That becomes expensive very quickly.</p> <p>When building a vehicle, reliable power-system architecture is critical for a robust vehicle. It is best to ensure a 15% upgrade (if not 20%) in rated capability (typically amperage, but consider total power [wattage] as well) for each component of the power-system, starting at the output (i.e. load. Typically, the motor).</p> <p>Many factors can affect the power at the motor, including:</p> <ul> <li>motor size</li> <li>diameter</li> <li>length</li> <li>kv rating</li> <li>propeller</li> <li>diameter</li> <li>pitch</li> <li>battery</li> <li>number of cells</li> <li>cold solder joints</li> </ul> <p>Changing any one of these factors will change the wattage, and hence amperage, at the motor.</p> <p>e.g.:</p> <ul> <li> <p>If you expect (or can measure) the amperage into a motor at 100A continuous, then, ideally, you should aim to have a motor whose spec sheet claims to be rated to at least 115A continuous</p> </li> <li> <p>Moving up the power-system, the electronic speed controller (ESC) should add an additional 15% on the motor rating. Therefore, the ESC would ideally be rated for at least 132A</p> </li> <li> <p>The next, and final, component in the system is the battery. Adding 15% on top of the ESC rating would be 152A. So, in this (very) hypothetical case, if you have a 5,000mAh battery, you should make sure its 'C' rating is at least 30C</p> </li> <li> <p>Finally, make sure a proper connectors are used throughout the system for this max computed amperage out of the battery. You will need two different types of connectors for the system. Bullet connectors will connect the motors to the ESCs, and a polarized connector will be used for all connections and splitters between the ESC and battery. Research connectors to find the right size that satisfies the amperage/power requirement. Additionally, pair the connectors with appropriately sized #-awg wire throughout the system as well, to avoid both insulation-break-down and melting</p> </li> <li>Bullet connectors: usually differentiated by diameter size in millimeters. The larger diameter, the more current and power can be safely pushed through them</li> <li>Polarized connectors: Many different brands exist, such as XT##, Dean's, EC#, Anderson Powerpole (APP##), etc. Find a properly sized/specced one for your amperage and power requirements. Do not attempt to force nor accidentally connect polarized connectors into each other 'the wrong way.' Reverse polarization can destroy the ESC and/or the battery</li> <li>You'll see a lot of XT60 and Dean's in the MAGICC lab, with some XT90, depending on preference of the person who assembled the vehicle power system. Feel free to go with preference on connector type, as long as the size is large enough for the amperage of your system</li> </ul> <p>Following a scheme like this will avoid putting unnecessary wear and tear on system components, especially with the dangers of over-heating Li-Po batteries. We would rather not have the lab vehicles burning up, and your mother would rather not have you burning up (and I don't mean sunburn, though I'm sure she'd rather not that, either).</p>"},{"location":"hw_guides/design_propulsion_system/#note","title":"Note:","text":"<p>The 15% upgrade in capability for each compoenent is not on the base power output, but is calculated as compounding on each component up the chain. Hence, the battery should be rated for 152A, not just 145A. Likewise for the ESC, it is not 130A, but 132A. The difference may not be large, but safer is better when dealing with Li-Po's. If you can, try to push the factor to 20% or more.</p>"},{"location":"hw_guides/design_propulsion_system/#example","title":"Example","text":""},{"location":"hw_guides/design_propulsion_system/#note_1","title":"Note","text":"<p>The purpose of the following example build was to experiment how much thrust we could harvest from as small a package as possible. This build was completed at a different facility, not affiliated with the MAGICC Lab. It was purposefully designed to push 'small' size hardware to its limits, disregarding some of the safety tips above.</p> <p>DO NOT attempt to disregard the guidelines above. The only thing you will gain is ashes and charcoal. The purpose of this example is to demonstrate HOW NOT TO DO IT.</p> <p>I personally have built an X-8 vehicle, capable of lifting a 65 lb payload. The vehicle itself weighed 25 lb. Total gross thrust was 90 lb. Using a power analyzer, we measured upwards of 115A continuous (depending on the propeller) to each of the eight motors at full throttle. This was our build:</p> <ul> <li>Connectors:</li> <li>EC5 (battery to splitter to ESC)</li> <li>5mm bullet connectors (motor to ESC)</li> <li>Wire: 10-awg (2 lines in parallel out of battery, before splitter to each of two ESCs)</li> <li>Propeller: APC 16x10</li> <li>Motor: Great Planes Rimfire 1.20 50-65-450 Outrunner Brushless DC (rated to 85A continuous)</li> <li>ESC: KDEXF-UAS95+, rated for 95+A continuous, bursts up to 120+A</li> <li>Battery: Pulse Li-Po, 6S, 5000mAh, 65C</li> <li>quantity: 4</li> <li>one battery for each arm, powering two motors</li> <li>total amperage draw from the battery, for two motors at full throttle: ~210A</li> <li>battery amperage rating: 325A</li> <li>soldered splitters from the battery to two ESCs, using 10-awg wire to each of the ESCs</li> <li>This was a pain, because you have two wires, both 10-awg, that have to solder to the positive terminal of the male connector, as well as two additional 10-awg wires soldered to the negative terminal of the male connector. This male connector then plugs into the female connector on the battery</li> <li>When splitting power from a battery, be 110% certain ALL joints are well soldered. A cold joint can raise resistance, leading to a power imbalance to the different ESCs, and can lead to inadvertant overloading of one of the ESCs</li> <li>Be sure to adequately cover all joints with heat shrink for safety</li> </ul>"},{"location":"hw_guides/gpu/","title":"CUDA and GPGPUs","text":"<p>CUDA (initially released in 2007) is an API built by NVIDIA for parallel computing using Graphics Processor Units (GPUs). Because it allows general-purpose use of the GPU, it is commonly referred to as GPGPU programming. CUDA can be used to increase the speed and efficiency of routines in OpenCV and TensorFlow (and other deep learning libraries), as well as custom CUDA-specific code. To use CUDA you must have an CUDA-enabled NVIDIA graphics card (e.g., the GeForce GTX 1050 Ti). An alternative is to use OpenCL, a less-supported open source unified API for a variety of different hardware vendors. Basically, it's not as good as NVIDIA hardware/CUDA and in a research setting we should probably just focus on CUDA and creating cool things with it.</p>"},{"location":"hw_guides/gpu/#software","title":"Software","text":"<p>There are a number of software packages that can be found in the Tools &amp; Ecosystem section of the NVIDIA Developer CUDA ZONE. It is important that you choose the correct CUDA Toolkit version for the specific NVIDIA graphics driver of your GPU. More information can be found from this SO answer. At the time of this writing, CUDA Toolkit 8.0 was the most current which supports minimum of driver version 367.4x. My desktop machine is running driver version 375.39 for a GeForce GTX 1050 Ti.</p>"},{"location":"hw_guides/gpu/#cuda-toolkit","title":"CUDA Toolkit","text":"<p>The CUDA Toolkit provides a comprehensive environment (API/SDK) for C/C++ developers building GPU-accelerated applications. This includes CUDA-specific compilers needed by GPU-accelerated libraries (cuDNN, OpenCV, etc) or your own CUDA-enabled code.</p>"},{"location":"hw_guides/gpu/#cuda-enabled-libraries","title":"CUDA-Enabled Libraries","text":""},{"location":"hw_guides/gpu/#cudnn","title":"cuDNN","text":"<p>This is a required CUDA-enabled library for GPU-accelerated TensorFlow and other deep neural network libraries.</p>"},{"location":"hw_guides/gpu/#opencv","title":"OpenCV","text":"<p>The go-to open source computer vision library does have built-in CUDA-enabled code. For CUDA-enabled installation instructions, see here.</p>"},{"location":"hw_guides/gpu/#ffmpeg","title":"FFmpeg","text":"<p>If you do anything that uses ffmpeg for video editing / splicing / management, this would be useful for you.</p>"},{"location":"hw_guides/gpu/#installation-instructions","title":"Installation Instructions","text":"<p>Download the appropriate runfile installer from developer.nvidia.com.</p> <p>During the setup of the installation, you will be asked about installing a graphics driver that may be outdated (i.e., your machine already has a newer version). The correct response is to decline this driver installation:</p> <pre><code>Install NVIDIA Accelerated Graphics Driver for Linux-x86_64 375.26? n\n</code></pre> <p>If you do this, you can ignore the <code>WARNING</code> about CUDA driver missing at the end of the installation summary.</p> <p>Put the following in your <code>~/.bashrc</code> for post-installation and environment setup:</p> <pre><code># CUDA Toolkit\nexport PATH=\"/usr/local/cuda-8.0/bin:$PATH\"\nexport LD_LIBRARY_PATH=\"/usr/local/cuda-8.0/lib64:$LD_LIBRARY_PATH\"\n</code></pre>"},{"location":"hw_guides/gpu/#cuda-accelerated-samples","title":"CUDA-accelerated samples","text":"<p>To see how cool CUDA has made your machine, install build and play with some of the NVIDIA CUDA samples found in either <code>/usr/local/cuda/samples</code> or <code>~/NVIDIA_CUDA-8.0_Samples</code>:</p> <pre><code>$ cuda-install-samples-8.0.sh\n$ cd ~/NVIDIA_CUDA-8.0_Samples\n$ make\n</code></pre> <p>Building the sample files can take about 15-20 minutes. So go get the mormon equivalent of a coffee.</p> <p>If you get an error about <code>-lnvcuvid</code> not being found, it is because your graphics driver is not exactly what the samples are looking for. A lazy fix would be to</p> <pre><code>$ cd ~/NVIDIA_CUDA-8.0_Samples\n$ find . -type f -execdir sed -i 's/UBUNTU_PKG_NAME = \"nvidia-367\"/UBUNTU_PKG_NAME = \"nvidia-375\"/g' '{}' \\;\n</code></pre> <p>Some interesting samples are:</p> <pre><code>./smokeParticles #(60 fps)\n./particles #(60 fps)\n</code></pre> <p>Note that this works if your driver is 375.xx (i.e., we are replacing 367 with 375).</p>"},{"location":"hw_guides/gpu/#uninstall","title":"Uninstall","text":"<p>To uninstall the CUDA Toolkit, run the uninstall script in <code>/usr/local/cuda-8.0/bin</code></p>"},{"location":"hw_guides/gpu/#resources","title":"Resources","text":"<ul> <li> <p>CUDA Toolkit Documentation</p> </li> <li> <p>CUDA_Installation_Guide_Linux.pdf found in <code>/usr/local/cuda/doc/pdf</code>: Good for post-installation information / environment setup.</p> </li> <li> <p>Udacity Intro to Parallel Programming</p> </li> </ul>"},{"location":"hw_guides/intel_rs_d400/","title":"Intel RealSense D4xx","text":""},{"location":"hw_guides/intel_rs_d400/#intel-realsense-d400-camera","title":"Intel RealSense D400 Camera","text":"<p>D415 and D435</p>"},{"location":"hw_guides/intel_rs_d400/#firmware-update","title":"Firmware Update","text":"<ol> <li>Boot into Windows (sorry)</li> <li>Download the firmware update tool from the Intel website (https://downloadcenter.intel.com/download/27514/Windows-Device-Firmware-Update-Tool-for-Intel-RealSense-D400-Product-Family)</li> <li>Follow instructions on the site to install latest firmware</li> </ol>"},{"location":"hw_guides/intel_rs_d400/#force-hardware-reset-on-startup","title":"Force Hardware Reset on Startup","text":"<p>As of June 13 2018, the RealSense driver has a bug that after launching the realsense node once, the camera crashes and needs to be unplugged and plugged back in to work. This is a work around to force the camera to reset on startup so that it works.</p> <p>Replace <code>realsense2_camera_manager/src/realsense_node_factory.cpp</code> with this file and replace <code>realsense2_camera_manager/include/realsense_node_factory.h</code> with this file</p> <p>Then rebuild your catkin workspace</p>"},{"location":"hw_guides/intel_rs_d400/#restart-depth-auto-exposure","title":"Restart Depth Auto exposure","text":"<p>As of 6-1-18 the RealSense driver has a bug that it thinks the IR auto-exposure is turned on when it is not. This can be fixed by toggling the setting using <pre><code>rosrun rqt_reconfigure rqt_reconfigure\n</code></pre> but that can be annoying everytime you start the camera up, so this is a work around to force it to toggle the rs435_depth_enable_auto_exposure.</p> <p>first you will need to install the timed_roslaunch package from source and put it in your workspace</p> <pre><code>git clone https://github.com/MoriKen254/timed_roslaunch.git\n</code></pre> <p>Then put the following lines in your launch file</p> <p><pre><code>&lt;include file=\"$(find timed_roslaunch)/launch/timed_roslaunch.launch\"&gt;\n  &lt;arg name=\"time\" value=\"4\" /&gt;\n  &lt;arg name=\"pkg\" value=\"mapping_3d\" /&gt;\n  &lt;arg name=\"file\" value=\"ir_exp_off.launch\" /&gt;\n  &lt;arg name=\"node_name\" value=\"depth_auto_exp_off\" /&gt;\n&lt;/include&gt;\n\n&lt;include file=\"$(find timed_roslaunch)/launch/timed_roslaunch.launch\"&gt;\n  &lt;arg name=\"time\" value=\"5\" /&gt;\n  &lt;arg name=\"pkg\" value=\"mapping_3d\" /&gt;\n  &lt;arg name=\"file\" value=\"ir_exp_on.launch\" /&gt;\n  &lt;arg name=\"node_name\" value=\"depth_auto_exp_on\" /&gt;\n&lt;/include&gt;\n</code></pre> but change the value in <code>&lt;arg name=\"pkg\" value=\"mapping_3d\" /&gt;</code> to whatever package you put the following launch files in</p> <p>Make two new launch files in your workspace called <code>ir_expo_off.launch</code> <pre><code>&lt;launch&gt;\n&lt;!--turn off Depth auto exposure--&gt;\n  &lt;node pkg=\"dynamic_reconfigure\" type=\"dynparam\" name=\"set_ir_autoexposure_off\"\n        args=\"set camera/realsense2_camera_manager rs435_depth_enable_auto_exposure 0\"&gt;\n  &lt;/node&gt;\n&lt;/launch&gt;\n</code></pre> and <code>ir_expo_on.launch</code> <pre><code>&lt;launch&gt;\n  &lt;!-- Turn on depth auto exposure --&gt;\n  &lt;node pkg=\"dynamic_reconfigure\" type=\"dynparam\" name=\"set_ir_autoexposure_on\"\n        args=\"set camera/realsense2_camera_manager rs435_depth_enable_auto_exposure 1\"&gt;\n  &lt;/node&gt;\n&lt;/launch&gt;\n</code></pre> NOTE:to work on a RealSense D415 camera, change <code>rs435_depth_enable_auto_exposure</code> in the above files to <code>rs415_depth_enable_auto_exposure</code></p> <p>it is kind of a lame workaround, but at least it works.</p>"},{"location":"hw_guides/intel_rs_d400/#tips-and-tricks-for-better-quality","title":"Tips and tricks for better quality","text":"<p>The D435's optimal depth resolution is 848x480 and the D415's optimal depth resolution is 1280x720. The depth images will be the most accurate and least noisy at these resolutions. This link has some other tips for tuning for better performance</p>"},{"location":"hw_guides/lipo_batts/","title":"Lithium-Polymer (Li-Po) Batteries","text":""},{"location":"hw_guides/lipo_batts/#general-hardware-thoughts-and-tips","title":"General Hardware Thoughts and Tips","text":""},{"location":"hw_guides/lipo_batts/#from-tools-tutorials","title":"From: Tools Tutorials","text":"<p>This module is meant to help learn how to use the hardware we use in this lab. There is really no particular order in which you need to complete these tutorials, complete them as you find necessary in your work.</p> <p>If you intend to become seriously involved in building and/or flying aircraft in the lab, it is worth noting that you should demonstrate some experience before working on lab equipment. This may include purchasing your own components, building your own airframes and getting practice on your own. Members of the lab can be a great resource for getting help in choosing components and building airframes, but lab resources are usually not best served in teaching RC flying or building aircraft. The best teacher in this situation is experience, and if you want to gain mastery over these concepts, you will have to purchase your own parts. Although it can seem overwhelming to make the investment to purchase your own parts, my experience is that it's generally much more fulfilling and educational to have built and flown your own airplane or multirotor with your own parts. Making the financial investment makes that experience all that much more impactful.</p> <p>Given that, there are still a lot of opportunities for you to participate in building and working with hardware, even if you don't maintain the entire aircraft, so it's really important to understand how all of the parts function, which is why we have these tutorials.</p>"},{"location":"hw_guides/lipo_batts/#history","title":"History","text":""},{"location":"hw_guides/lipo_batts/#did-you-know-that-the-magicc-lab-used-to-be-in-the-clyde-building","title":"Did you know that the MAGICC lab used to be in the Clyde Building?","text":"<p>Well, it was! However, several years ago a fire started at the battery charging station and as a result, the lab was banished to the basement of B-34 (a more dispensable building). After good behavior, the lab was moved to the Fletcher Building.</p>"},{"location":"hw_guides/lipo_batts/#moral-of-the-story","title":"Moral of the Story:","text":"<p>is that if we want to ever have good air conditioning and heating again we need to be careful when charging batteries.</p>"},{"location":"hw_guides/lipo_batts/#guidelines","title":"Guidelines","text":"<p>Below are a few guidelines. If you have any questions, ask someone in the lab who knows and then update this wiki.</p>"},{"location":"hw_guides/lipo_batts/#connectors","title":"Connectors","text":"<p>Any 'hot' or 'source' line should always have a female connector. This ~~protects~~ makes it more difficult for the user to inadvertantly touch the 'hot'/'source' leads and get shocked. This is why wall outlets are female. Unless someone has something skinny and metal, deliberately aiming for the small hole, they won't get shocked. The male plug of an extension cord is only exposed when it is disconnected from a power outlet, and hence cannot shock you when you grab the exposed wires. Once you plug it in, there are no external wires to inadvertently grab.</p> <p>So, make sure the battery gets a female connector. Likewise, the bullet connectors coming out of the ESC should also be female, because as soon as the ESC is plugged into the battery, the ESC bullets can be 'hot'. Additionally, make sure these female bullet connectors are entirely covered by heat shrink, but not so much that it inhibits the full connection with the male bullets attached to the motor.</p> <p>Attention! Never cut the postive and negative wires of the battery at the same time (e.g. when replacing a connector, whether it is the main battery lead or the cell voltage-tester-lead).</p> <p>Most connectors are labeled with a positive and negative sign on the appropriate sides, to avoid reverse polarization at the soldering stage. Be aware of which side of the connector to solder the black wire to (negative), and the red wire (positive). If you realize you did it wrong by accident, start over. Do not purposefully solder a matching female connector to an ESC the wrong way, thinking you'll always remember that that battery and ESC must always go together. Fires Will Happen. De-solder it and start over.</p> <ul> <li>Some connector types (Anderson Powerpoles) are 'genderless.' This means that both sides of the connector are identical, or in other words, neither side has an exposed plug wire. Both are inside a housing, difficult to get accidentally electrically shocked if 'hot.' The MAGICC lab does not use these types of connectors (that I know of), so just get used to being careful and deliberate when soldering connectors. Even with 'genderless' connectors, they are still polarized, so make sure the red and black wires are soldered to the correct sides of the connector</li> </ul>"},{"location":"hw_guides/lipo_batts/#li-po-lithium-polymer-batteries","title":"Li-Po (Lithium-Polymer) Batteries:","text":"<ul> <li>3S - 3 cells in series</li> <li>4S - 4 cells in series</li> <li>2P - 2 cells in parallel</li> </ul>"},{"location":"hw_guides/lipo_batts/#voltage-v","title":"Voltage (V):","text":"<ul> <li>Batteries have nominal charge of 3.7V/cell</li> <li>WITH NO LOAD, BATTERY SHOULD NOT BE DISCHARGED BELOW THIS!</li> <li> <p>IF IT IS, RECHARGE BATTERIES IMMEDIATELY.</p> <ul> <li>e.g.<ul> <li>3S is 11.1V nominally</li> <li>4S is 14.8V nominally</li> </ul> </li> </ul> </li> <li> <p>Batteries when fully charged are 4.2V/cell</p> <ul> <li>e.g.<ul> <li>3S is 12.6V fully charged</li> <li>4S is 16.8V fully charged</li> </ul> </li> </ul> </li> <li> <p>Cells should be stored between 3.75 and 3.85 V</p> <ul> <li>Storage meaning anything longer than a day</li> </ul> </li> <li> <p>At any time, if the voltage in one cell is more than 0.5V different than any   other, the entire battery should be discarded. This condition is called cell   balance. All cells need to be balanced regularly, and checked that they have   not entered a state of imbalance. If you try to charge an imbalanced battery,   you run a very high risk of explosion.</p> </li> </ul>"},{"location":"hw_guides/lipo_batts/#charging","title":"Charging:","text":"<p>More info in the Battery Charger User Guide.</p> <p>Attention: IF YOU DO NOT KNOW HOW TO USE THE CHARGER, ASK FOR HELP</p> <p>Attention: REQUIRED READING: More charger-specific info in the Battery Charger User Guide.</p> <p>Be absolutely certain the charge mode of the charger matches the type of cell you are charging. Telling the charger it is connected to a Ni-MH battery, and actually connecting a Li-Po battery WILL cause irreparable damage to the equipment AND BUILDING.</p> <ul> <li>Capacity is measured in milli-amp hours (mAh)</li> <li>The 'C' rating is just a multiple of battery capacity<ul> <li>e.g.<ul> <li>A '25C' max discharge rate on a 5,000mAh battery means the battery is rated for a max discharge rate of 125A</li> <li>A '1C' max charge rate on a 5,000mAh battery means the battery is rated to safely charge at 5A</li> </ul> </li> </ul> </li> <li>Some battery specifications may advertise up to 5C or 10C charge rates, but did you read the MORAL OF THE STORY above? High charge rates can be dangerous, and can cause expensive-to-fix damage -- more than you can afford to cover -- hope you either have good insurance or alternate career plans...</li> <li>In the MAGICC lab we only charge batteries at '1C' max, even though the batteries may have a higher advertised rating on its spec sheet<ul> <li>If you have the time, charge at '0.5C' (or lower) as it will be easier on the battery, and help prolong the life of the cell</li> <li>High charge rates (and high discharge rates, for that matter) degrade cell quality more quickly, which causes otherwise unnecessary battery purchases with sacred funds provided to the lab</li> <li>The degradation level of the cells can most easily be seen by the 'puffiness' of the cells<ul> <li>e.g.<ul> <li>A 5,000mAh battery is charged at 5A maximum</li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"hw_guides/rospberry_pi_zero/","title":"Installing ROS Kinetic on a Raspberry Pi Zero W","text":"<p>The Raspberry Pi Zero W is a lightweight, inexpensive computer capable of running Linux. It also has bluetooth and WiFi, making it a good option for using on small UAV platforms, especially when you need to communicate with the ROSFlight board remotely for tuning gains, saving data, etc. However, it is only able to run Raspbian distros, meaning it can be kind of a pain to get ROS to run on it. This guide will explain how to install ROS Kinetic on the Raspberry Pi Zero W. To my knowledge, it isn't possible to install Melodic on the Zero, and if it is possible, there isn't much documentation for it, so we're stuck with Kinetic for now.</p>"},{"location":"hw_guides/rospberry_pi_zero/#setting-up-the-os","title":"Setting Up The OS","text":"<p>The easiest way to install the OS is to flash your SD card with a predownloaded image. Raspbian Lite images can be found here. It is (highly) recommended that you install a version of Jessie instead of Buster. Buster will have issues with finding boost and you will have to install it manually, which is a huge pain. Download the <code>.zip</code> file. Before you can flash the image, you need to know the name of the SD card partition. Without the SD card inserted, run <code>lsblk</code>. Then insert the card and run <code>lsblk</code> again to see the name of the SD card partition (the one that wasn't there before). It should be something like <code>/dev/mmcblk0</code> or <code>/dev/sdX</code>. Then, to flash the image, run the command</p> <pre><code>unzip -p /PATH/TO/IMAGE.zip | sudo dd of=/dev/sdX bs=4M conv=fsync\n</code></pre> <p>replacing <code>/PATH/TO/IMAGE.zip</code> with the path to the downloaded zip file and  <code>/dev/sdX</code> with the name of SD card partition. After a few minutes, the OS will be ready to run.</p> <p>If anything breaks, more detailed instructions are found on the Raspberry Pi website.</p>"},{"location":"hw_guides/rospberry_pi_zero/#setting-up-ssh","title":"Setting Up SSH","text":"<p>Unless you feel like finding a monitor, USB hub, micro HDMI cable, mouse, and keyboard, you'll need to set up SSH to be able to do anything with the Zero. This is super easy to do. You just need to add an empty text file called <code>ssh</code> to the root directory of the partition. This can be done with <code>touch ssh</code> when in the proper directory. Additionally, to get the Zero to connect to Wifi, create a text file called <code>wpa_supplicant.conf</code> in the same directory and paste these contents into it:</p> <p><pre><code>ctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev\nupdate_config=1\ncountry=US\n\nnetwork={\n    ssid=\"Your SSID\"\n    psk=\"YourWPAPassword\"\n    key_mgmt=WPA-PSK\n}\n</code></pre> inserting the proper SSID and password of the network you want to connect to.</p> <p>Now, eject the SD card, insert it into the Zero's SD slot, and boot the Raspberry Pi. It should connect to the internet automatically (assuming the network is available). To ssh into it, from your own machine connected to the same network run</p> <pre><code>$ ping raspberrypi.local\n</code></pre> <p>to find the IP address of the Pi, then run</p> <pre><code>$ ssh pi@&lt;IP_ADDRESS&gt;\n</code></pre> <p>to connect. The default password is <code>raspberry</code>.</p>"},{"location":"hw_guides/rospberry_pi_zero/#installing-ros-kinetic","title":"Installing ROS Kinetic","text":"<p>Now for the fun part. The ROS wiki has a really good tutorial demonstrating how to install ROS Kinetic on a Raspberry Pi running Raspbian. You can follow these instructions with a few caveats.</p>"},{"location":"hw_guides/rospberry_pi_zero/#1","title":"1.","text":"<p>For ROS to build successfully, you need to have the <code>yaml-cpp</code> package installed. This is easily accomplished with</p> <pre><code>$ sudo apt install libyaml-cpp-dev\n</code></pre>"},{"location":"hw_guides/rospberry_pi_zero/#2","title":"2.","text":"<p>Make sure you run the commands associated with the correct version of Raspbian (if you heeded my previous warning, that would be Jessie).</p>"},{"location":"hw_guides/rospberry_pi_zero/#3","title":"3.","text":"<p>In Section 2.1, the key they have shown is out of date. So instead of running</p> <pre><code>$ sudo apt-key adv --keyserver hkp://ha.pool.sks-keyservers.net:80 --recv-key 421C365BD9FF1F717815A3895523BAEEB01FA116\n</code></pre> <p>run</p> <pre><code>$ sudo apt-key adv --keyserver 'hkp://keyserver.ubuntu.com:80' --recv-key C1CF6E31E6BADE8868B172B4F42ED6FBAB17C654\n</code></pre>"},{"location":"hw_guides/rospberry_pi_zero/#4","title":"4.","text":"<p>You will only need the ROS-Comm package (not the desktop package) on the Pi. However, there are a whole bunch of packages that ROSFlight requires that you'll want to install with ROS-Comm. These packages include <code>std_msgs</code>, <code>std_srvs</code>, <code>geometry_msgs</code>, <code>eigen_stl_containers</code>, <code>sensor_msgs</code>, <code>tf</code>, and <code>nav_msgs</code>. Additionally, compilation of the package <code>collada_urdf</code> will fail. You could use the workaround they mention, but it takes forever and <code>collada_urdf</code> isn't necessary for ROSFlight, so you can just ignore it. So rather than running the command</p> <pre><code>$ rosinstall_generator ros_comm --rosdistro kinetic --deps --wet-only --tar &gt; kinetic-ros_comm-wet.rosinstall\n$ wstool init src kinetic-ros_comm-wet.rosinstall\n</code></pre> <p>you'll run something like</p> <pre><code>$ rosinstall_generator ros_comm std_msgs std_srvs geometry_msgs eigen_stl_containers sensor_msgs tf nav_msgs --rosdistro kinetic --deps --wet-only --exclude collada_parser collada_urdf --tar &gt; kinetic-ros_comm-wet.rosinstall\n$ wstool init src kinetic-ros_comm-wet.rosinstall\n</code></pre> <p>including whatever other ROS packages you think you'll need.</p> <p>If you find out you need other packages in the future, you can follow the instructions in Section 4.2 to install new packages. Note that you'll have to rebuild ROS each time, so figure out all the packages you want and install them at the same time so you don't have to keep rebuilding.</p>"},{"location":"hw_guides/rospberry_pi_zero/#5","title":"5.","text":"<p>When you build the workspace in Section 3.3, you're going to need to add swap space. Open <code>/etc/dphys_swapfile</code> and change the line <code>CONF_SWAPSIZE=100</code> to <code>CONF_SWAPSIZE=1024</code>. I think this is generally not recommended unless you're using a separate drive, but it didn't break when I did it, so you can find and mount a separate drive or you can be lazy like me and it'll probably be fine.</p> <p>Assuming that built correctly, you should be good to go! You can now build your catkin workspaces. If you find out you need additional ROS packages, just follow the steps in Section 4.2 on the ROSberry Pi tutorial page.</p>"},{"location":"hw_guides/ubiquiti/","title":"Ubiquiti","text":"<p>========================== The Ubiquiti Rocket can be thought of as a powerful wifi broadcaster that provides a very strong long-range connection to a Bullet.</p>"},{"location":"hw_guides/ubiquiti/#rocket","title":"Rocket","text":"<p>The MAGICC Lab has a Rocket sitting on the wall behind the printer.</p> <p></p>"},{"location":"hw_guides/ubiquiti/#bullet","title":"Bullet","text":"<p>Bullets can be ordered here</p> <p></p> <p>In the lab, we typically strip down the bullet in order to reduce its size.</p>"},{"location":"hw_guides/ubiquiti/#stripping-down-the-bullet","title":"Stripping Down the Bullet","text":"<ol> <li> <p>Use the hacksaw to saw off the metal cylinder extending from the plastic tube.</p> </li> <li> <p>Take the plastic tubing off.</p> </li> <li> <p>Detach the metal cylinder from the bullet. Be careful not to rip any of the five pads off the bullet while doing so.</p> </li> <li> <p>Desolder the connection points for the metal cylinder.</p> </li> <li> <p>Get a Coax Connector and solder it to all five pads. The connectors are located in the back of the lab.</p> <p> </p> </li> <li> <p>Insert the bullet into a heatshrink envelope.</p> </li> <li> <p>Use the heat gun to shrink the plastic until it fits tightly.</p> </li> <li> <p>Cut the plastic around the heatsink, ethernet port, and end of the Coax Connector.</p> </li> <li> <p>Attach an antenna like the Lumenier AXII.</p> </li> </ol>"},{"location":"hw_guides/ubiquiti/#bullet-configuration","title":"Bullet Configuration","text":"<ol> <li> <p>Download Google Chrome</p> </li> <li> <p>Download the Ubiquiti Device Discovery Tool</p> </li> <li> <p>Ensure the rocket in the Lab is operating.</p> </li> <li> <p>Plug the bullet into an ethernet cable that provides power, as shown below. Wait for two lights to come on.</p> <p></p> </li> <li> <p>Launch the Ubiquiti Device Discovery Tool. Select clear, then scan. You should see both the rocket and bullet in the list.</p> <p></p> </li> <li> <p>Click the link for the host of the bullet. This will open a page in your browser. The browser will warn you that the connection is not private. Select advanced and click proceed to enter the bullet's setup page.</p> </li> <li> <p>Log in to the bullet. The username and password are both ubnt. Dismiss any firmware update prompts.</p> </li> <li> <p>The lab updates the firmware for all of the bullets once/year. Check to see which firmware the other bullets are using, and then download that same firmware from here.</p> </li> <li> <p>Click the gear icon on the left to access the settings pane. In the top right sector, select upload firmware. Upload the firmware downloaded in the previous step.</p> <p></p> </li> <li> <p>Update the username of the bullet to ubnt. Password should be Magiccwifi123</p> </li> <li> <p>Update the name of the bullet to b##_MCU_character of your choice.</p> </li> <li> <p>Now repeat steps 4-8 with another bullet that has already been setup. (We will call this one bullet2) The username for bullet2 is ubnt. The password to bullet2 is Magiccwifi123.</p> </li> <li> <p>On bullet2, click the gear icon on the left to access the settings page. Scroll to the bottom and select backup configuration to download the configuration to your computer. Alternatively, access the config files for each bullet on the private MAGICC wiki.</p> <p></p> </li> <li> <p>Follow the previous step to download the configuration file for bullet1 as well.</p> </li> <li> <p>Open Atom. Install the sort-lines package by following directions here.</p> </li> <li> <p>Install the split-diff package in Atom via the settings window and install. You can find more information on the package here.</p> </li> <li> <p>Open bullet1.cfg in Atom. Select the entire text. In the view drop-down menu, select Toggle Command Palette. Then type sort::list in order to sort bullet1.cfg alphabetically.</p> </li> <li> <p>Open bullet2.cfg side-by-side with bullet1.cfg. Toggle the command palette again and run split-diff command.</p> </li> <li> <p>The things that should be different between the two .cfg files are names, IP addresses, Hardware Addresses, and the passwords. You can ignore anything with a # in front of it, as those lines are commented out.</p> </li> <li> <p>All other configurations in bullet1.cfg should match bullet2.cfg. NEVER modify bullet2.cfg.</p> </li> <li> <p>Once everything is up-to-date on the new bullet1.cfg file, upload the configuration to the bullet on its webpage. The bullet will then need to restart with the proper configuration. Once it does so, the bullet will have all its lights blinking.</p> </li> <li> <p>Update the MAGICC Hardware Inventory on the private wiki page under Inventory and Standard HW to include the new bullet, its MAC address, the project it falls under, and the date acquired.</p> </li> <li> <p>Upload the bullet1.cfg configuration file to the Ubiquiti_configs repo under the folder bullet_configs. Edit the file ownership.txt to include your new bullet.</p> </li> </ol>"},{"location":"hw_guides/ubiquiti/#using-a-bulletrocket-combination","title":"Using a Bullet/Rocket Combination","text":"<p>Avoid turning on any additional rockets within the lab. Doing so may adversely affect the lab's primary bullet near the MOCAP room.</p>"},{"location":"hw_guides/ublox_f9p/","title":"RTK GPS: F9P Modules","text":"<p>This article will outline all the necessary steps in order to set up a simple base/rover RTK system using two ZED-F9P modules. It focuses on hardware. For UBLOX_read software documentation, click here.</p> <p>Real Time Kinematics (RTK) is a GNSS technique used to obtain a centimeter-level accurate position of one module (called a rover) relative to a correction provider (often another module called a base).</p>"},{"location":"hw_guides/ublox_f9p/#required-hardware","title":"Required Hardware","text":"<ol> <li>Two computers with at least one USB 2.0 port each</li> <li>A high-bandwidth, low-latency connection between the two computers. See Ubiquiti page</li> <li>Two USB-C to USB 2.0 cables</li> <li>Two UBLOX ZED-F9P modules</li> <li>Two GNSS antennas with male SMA connector ends (we recommend UBLOX patch antennas)</li> <li>Two Female SMA to U.FL Interface Cables</li> <li>Two 3-D printed protective cases (.stl files found here)</li> <li>Two ground plates (preferably circular)</li> </ol>"},{"location":"hw_guides/ublox_f9p/#assembly","title":"Assembly","text":"<ol> <li>Gently push the female SMA/U.FL connector onto the port labeled Active L1/L2 Antenna on the ZED-F9P module until it snaps into place</li> </ol> <p> ![](assets/femalesma.jpg) </p> <ol> <li>Screw the male SMA end of the GNSS antenna into the end of the female SMA/U.FL connector</li> </ol> <p> ![](assets/connectantenna.jpg) </p> <ol> <li> <p>Attach the GNSS antenna to the center of the ground plate</p> </li> <li> <p>Plug the USB-C cable into the F9P module and plug the other end into Computer #1</p> </li> </ol> <p> ![](assets/connectcomp.jpg) </p> <ol> <li>Repeat steps 1-4 for the second antenna, F9P module, Female SMA/U.FL connector, USB-C to USB 2.0 cable, and Computer #2</li> </ol>"},{"location":"hw_guides/ublox_f9p/#software-installation","title":"Software Installation","text":"<p>The MAGICC Lab has developed its own software for interacting with the UBLOX F9P module.</p> <p>On each computer, perform the following steps given ROS is installed.</p> <ol> <li>Make a catkin workspace if you don't already have one (<code>mkdir catkin_ws</code>)</li> <li><code>cd catkin_ws &amp;&amp; mkdir src</code></li> <li><code>cd src &amp;&amp; git clone https://github.com/byu-magicc/UBLOX_read.git</code></li> <li><code>cd UBLOX_read</code></li> <li><code>git submodule update --init --recursive</code></li> <li><code>cd ../.. &amp;&amp; catkin_make</code></li> <li><code>source devel/setup.sh</code></li> </ol>"},{"location":"hw_guides/ublox_f9p/#networking","title":"Networking","text":"<p>Because of the time-sensitive nature of the data streamed from the base to the rover, it is important that you have a very low-latency connection. Stationary base may allow using WiFi, but the best option is a Rocket-Bullet connection.</p> <p>In order to ensure the computers can communicate, perform the following steps:</p> <ol> <li>Computer #1: Open a terminal and enter <code>hostname -I</code> in order to find its IP address</li> <li>Computer #1: Enter <code>netcat -l 1640</code></li> <li>Computer #2: Open a terminal and enter <code>netcat {IP address of Computer #1} 1640</code></li> <li>Enter <code>Hello</code> on Computer #2 and <code>World</code> on Computer #1</li> <li>If you can see  <code>Hello</code> <code>World</code>   in both terminals, then the connection is configured correctly. Otherwise, troubleshoot. You may need to disable firewalls</li> </ol> <p>In order to see information from each F9P module on either computer, set <code>ROS_MASTER_URI</code> on one computer to the IP address of the other computer. Do this as follows: <code>export ROS_MASTER_URI={IP address of the other computer}</code> Do not perform the same step for the other computer.</p> <p>Start a roscore on one computer. You must be able to see the node /rosout by entering <code>rosnode list</code> in the other computer's terminal. Shut the roscore down by typing Ctrl-C.</p> <p>Attention: Do not modify the launch files below. Only use them as templates for creating your own in a separate package.</p> <p>On the base computer, 1. <code>cp catkin_ws/src/UBLOX_read/launch/base.launch catkin_ws/src/&lt;your own rospackage&gt;/launch/basefile.launch</code> 2. Using your favorite text editor, open <code>basefile.launch</code> 3. Modify the line <code>&lt;arg name=\"base_host\" default=\"192.168.0.115\"/&gt;</code> base computer IP address 4. Modify the line <code>name=\"rover_host\" default=\"192.168.0.143\"/&gt;</code> rover computer IP address 5. Save and close</p> <p>On the rover computer, open 1. <code>cp catkin_ws/src/UBLOX_read/launch/rover.launch catkin_ws/src/&lt;your own rospackage&gt;/launch/roverfile.launch</code> 2. Using your favorite text editor, open <code>roverfile.launch</code> 2. Modify the line <code>&lt;arg name=\"base_host\" default=\"192.168.0.115\"/&gt;</code> base computer IP address 3. Modify the line <code>name=\"rover_host\" default=\"192.168.0.143\"/&gt;</code> rover computer IP address 4. Save and close</p>"},{"location":"hw_guides/ublox_f9p/#moving-or-stationary-base","title":"Moving or Stationary Base","text":"<p>The base F9P module supports two different configurations as follows:</p> <ol> <li>Stationary base assumes that the base is does not move. This results in easier, faster, and more accurate RTK calculations for the rover. (~ 10 Hz)</li> <li>Moving base does not assume that the base moves. This configuration has slower and generally less accurate RTK calculations. (~ 4 Hz)</li> </ol> <p>The param <code>base_type</code> controls this configuration setting. The param value can be set to either <code>stationary</code> or <code>moving</code>. This is found in all launch files.</p> <p>Check <code>catkin_ws/src/UBLOX_read/params/ublox.yaml</code> for the default param value.</p>"},{"location":"hw_guides/ublox_f9p/#startup","title":"Startup","text":"<ol> <li>On one computer, enter the command <code>roslaunch &lt;your own rospackage&gt; basefile.launch</code></li> <li>On the other computer, enter <code>roslaunch &lt;your own rospackage&gt; roverfile.launch</code></li> </ol>"},{"location":"hw_guides/ublox_f9p/#debugging","title":"Debugging","text":"<ul> <li><code>[async_comm][ERROR]: open: device or resource busy</code>: Launched a file before the USB connection to the module was fully operational.     Solution: Ctrl-C, wait 10 seconds, relaunch</li> <li><code>[async_comm][ERROR]: open: No such file or directory</code>: The serial port specified in the launch file has nothing connected to it     Solution: Ctrl-C     In a terminal, enter <code>ls /dev -a | grep ttyACM</code> to find which USB ports are currently in use. One of those will be the F9P serial port.     In the launch file, edit the param <code>serial_port</code> to match</li> <li><code>[async_comm][ERROR]: invalid argument</code>: Check <code>base_host</code> and <code>rover_port</code></li> <li><code>[async_comm][ERROR]: bind: Address already in use</code>: Check <code>base_port</code> and <code>rover_port</code></li> <li>The number and position of satellites at any given time significantly influences the accuracy of RTK-GNSS. If data is messy, wait an hour and try again. You may get a more favorable constellation</li> <li>As a last resort, consider turning off some GNSS constellations by setting them to 0 in <code>params/ublox.yaml</code>. Turn off GLONAS first (it requires more computational effort than the others)</li> <li>The base sends data to the rover via a UDP connection, which by nature may send packets out of order. Occasionally, you may see terminal output such as:  <code>Returning false because checksums did not match! Message cka: 0, calculated cka: 150 Message ckb: 90, calculated ckb: 158</code> or <code>Failed to parse message, f9pID: 1, ParseState: 8, CLASS_ID: 1, MSG_ID: 1</code> Do not be concerned if this happens occassionally as hundreds of data packets are sent over the network. However, if hundreds of these error messages print, then something may wrong with the connection.</li> </ul> <p><code>f9pID</code>: The f9P computer the message came from. 0 is the local computer. 1 is from its relative base.</p> <p><code>ParseState</code>: Stage the parser was at in the UBX Protocol</p> <code>ParseState</code> Meaning 0 START 1 GOT_START_FRAME 2 GOT_CLASS 3 GOT_MSG_ID 4 GOT_LENGTH1 5 GOT_LENGTH2 6 GOT_PAYLOAD 7 GOT_CK_A 8 GOT_CK_B <p><code>CLASS_ID</code>: UBX message class</p> <p><code>MSG_ID</code>: UBX message ID within class</p>"},{"location":"hw_guides/ublox_f9p/#best-practices","title":"Best Practices","text":"<ol> <li>Open sky with minimal surrounding obstructions</li> <li>Place antennas in the same orientation as each other (this is more important with shorter baselines)</li> </ol>"},{"location":"hw_guides/ublox_f9p/#base-and-rover-from-one-computer","title":"Base and Rover From One Computer","text":"<p>To run ZED-F9P modules from one computer:  1. Plug both modules into the computer  2. <code>cp catkin_ws/src/UBLOX_read/launch/OneComp.launch catkin_ws/src/&lt;your own rospackage&gt;/launch/OneComp.launch</code> 2. <code>roslaunch &lt;your own rospackage&gt; OneComp.launch</code></p>"},{"location":"hw_guides/ublox_f9p/#ros-topics","title":"ROS Topics","text":"<p>Helpful ROS Topics include 1. /rover/RelPos: Position of rover relative to base in NED frame 2. /rover/RelPosFlags: Flags that determine the validity of RTK calculations 3. /rover/PosVelTime: Rover global position/velocity in LLA format 4. /base/PosVelTime: Base global position/velocity in LLA format 5. /rover/PosVelEcef: Rover global position/velocity in ECEF frame</p> <p>See UBLOX_read Documentation for more information about the content of these messages. Ex: <code>rostopic echo /rover/RelPos</code></p>"},{"location":"hw_guides/ublox_f9p/#firmware-update","title":"Firmware Update","text":"<p>UBLOX periodically releases firmware updates for the ZED-F9P module. To tell if the module is running the latest verion, <code>roslaunch ublox debug.launch</code> The output will annouce if an update is needed.</p> <p>If an update is needed, follow these steps on a Windows Machine with U-Center installed (like the flight-simulator computer in the lab): 1. Navigate to the official UBLOX ZED-F9P Page 2. Scroll down to click the tab Documentation and Resources. 3. Scroll down to the section Firmware Update 4. Download the latest firmware version 5. Follow the instructions for updating firmware from the U-Center User Guide. As of May 2020, the instructions are located in Section 8.1. Alternatively, watch this video. Uncheck \"Enter safeboot before update\"</p>"},{"location":"hw_guides/ublox_f9p/#ublox-documentation-and-citations","title":"UBLOX Documentation and Citations","text":"<ul> <li>Interface Description contains information about various messages from the module.</li> <li>Integration Manual</li> <li>Moving Base Application Note</li> <li>Data Sheet</li> <li>UBLOX F9P Site contains more useful documents</li> </ul>"},{"location":"hw_guides/ublox_f9p/#credits","title":"Credits","text":"<p>A special thanks goes to  Nathan Toombs: ZED-F9P Protective Case Design</p>"},{"location":"misc/caedm_integration/","title":"CAEDM Integration","text":"<p>Mount your CAEDM J:\\ drive in Linux</p> <pre><code>mkdir ~/jdrive\nsudo apt install cifs-utils\nsudo mount -t cifs //fs-caedm.et.byu.edu/&lt;caedm_username&gt; ~/jdrive -o user=&lt;caedm_username&gt;,rw,uid=$USER,gid=$USER\n</code></pre> <p>Mount CAEDM group directory in Linux</p> <p>```bash mkdir ~/my_group</p>"},{"location":"misc/caedm_integration/#replace-caedm_username-below","title":"Replace caedm_username below","text":"<p>sudo mount -t cifs //fs-caedm.et.byu.edu//groups/my_group ~/my_group -o user=,rw,uid=USER,gid=USER  ```  Connect to CAEDM VPN from off campus <p>Use the guide provided by CAEDM at this link.</p>"},{"location":"misc/debugging_ros_nodes/","title":"Debugging ROS Nodes","text":"<p>Debugging ROS Stuff You can use GDB to connect to currently running (or not yet running) nodes. You can also use Qt Creator or SublimeGDB (Both just use GDB under the hood).</p>"},{"location":"misc/env_setup/","title":"Environment Setup","text":""},{"location":"misc/env_setup/#automated-environment-setup","title":"Automated Environment Setup","text":"<p>We have set up a number of scripts to assist you in setting up your computer, after you have installed ROS. Here is a link to the scripts folder Scripts and use the following credentials</p> <p><pre><code>username= \"relative_nav\"\npassword= \"hex\"\n</code></pre> Then, bring up a terminal (Ctrl+Alt+T) and type the following commands. The file will always be a little different, so fill in the blank (or just press tab to auto-complete) when it says  <p><pre><code>cd ~\nsudo apt update\nmkdir scripts\ncd Downloads\nls\nmv scripts.git&lt;rest of file name&gt;.zip ../scripts\ncd ../scripts\nunzip scripts.git&lt;rest of file name&gt;\ncd installation\n./toplevel\n</code></pre> When running this script, you should answer with the following</p> <ul> <li>N, you are not a cave computer</li> <li>Y, you want to copy the bashrc file</li> <li>your ROS_MASTER_URI is local (no quotes)</li> <li>your magicc username is firstname_lastname (your actual first name and last name)</li> </ul> <p>This script installs git, vim, a whole bunch of environment customizations, ROS, all the ROS packages needed to run the relative nav stack, Google Chrome, Sublime, QtCreator, Spotify, and the Numix Custom theme. It can take more than hour, depending mainly on your internet connection, because it downloads several gigabytes of data over the course of installation.</p> <p>Then to apply the changes you just made to your environment, <pre><code>cd ~\nsource ~/.bashrc\n</code></pre> You'll know if it worked if your terminal prompt is colored green</p>"},{"location":"misc/env_setup/#environment-variables","title":"Environment Variables","text":"<p>One of the things that can often go wrong in getting programs to work properly is the \"environment variables.\" These variables are sort of like global variables in scope of the entire operating system, that tell it where to find different libraries, how commands in the terminal get interpreted, the name of your system, and so on. Windows and Mac both actually have environment variables as well, but it's not often that you have to manage them.</p> <p>Let's look at our environment variables, just for fun. Open up a terminal and type</p> <p><pre><code>printenv\n</code></pre> A big long list of variables will show up. This list includes everything from where to find the python library, to what type of Linux you are running. It's sometimes unmanageable to go through the whole list, so let's use grep to filter through the list to see what we want. For example, let's use these commands to see what Linux thinks our active ROS workspace is.</p> <p><pre><code>printenv | grep ROS\n</code></pre> So, this command prints the whole list of variables and pushes it straight into grep, which returns only lines that have the phrase \"ROS\" in them. What you end up with is a list of variables that have to do with ROS. Look at your ROSLISP_PACKAGE_DIRECTORIES variable. It should include your active workspace. If the ros shortcuts \"roscd\" and \"roslaunch\" aren't working, this is sometimes the culprit.</p> <p>To change environment variables (which shouldn't be done on a regular basis, except for perhaps ROS_MASTER_URI and ROS_IP), type</p> <p><pre><code>export &lt;VARIABLE&gt;=&lt;new_value&gt;\n</code></pre> So, an example would be as follows: <pre><code>export ROS_MASTER_URI=http://localhost:11311\n</code></pre> It should be noted that you can create environment variables this way as well. These variables are loaded when the terminal is started, so if you want the variable to be a part of every session, you would you have to put it in the .bashrc script, which brings us to the next section!</p>"},{"location":"misc/env_setup/#the-bashrc-file","title":"The .bashrc file","text":"<p>Every time you open a terminal window, it runs a special script called your \"bashrc\" This script often calls other scripts such as the rosrc file we use in the lab</p> <p>Let's look at our bashrc <pre><code>vim ~/.bashrc\n</code></pre></p> <p>It's sort of confusing to read the file, but there are a few key words you should know. <pre><code>alias &lt;command&gt;='&lt;replacement command&gt;'\n</code></pre> This allows you to shorten commands. For example, I have the following line in my .bashrc <pre><code>alias grep='grep --color=auto'\n</code></pre> This means every time I use the grep command, I don't need to add the --color=auto argument. The terminal will automatically replace \"grep\" with \"grep --color=auto\" when it processes the command.</p> <p>Another keyword you should probably know is <pre><code>source &lt;external script file.sh&gt;\n</code></pre> Source runs the content in some external script. For example, the line you added to the bashrc when you installed ROS was exactly this type of command. It's that particular script that runs and sets up your ROS environment variables.</p> <p>It's important to note that the .bashrc file is loaded when a new terminal window is opened. That means that if you make changes to the bashrc, then you either need to open a new terminal to see the changes, or type <pre><code>source ~/.bashrc\n</code></pre> to see the changes in your current terminal.</p> <p>The full version of the bashrc we start with in the MAGICC Lab can be found here: Link. Don't be afraid if you don't understand everything that is going on.</p>"},{"location":"misc/env_setup/#colors-in-the-terminal","title":"Colors in the terminal","text":"<p>Also, if you want to change your command prompt to something other than the default, look into changing line 117 on the linked file. The PS1 variable defines the prompt color. The actual colors are defined by the code in brackets. For example</p> <pre><code>\\[\\033[01;32m\\] -&gt; Means that whatever follows is bold green\n\\[\\033[01;34m\\] -&gt; is bold blue and\n\\[\\033[00;33m\\] -&gt; is normal yellow\n</code></pre> <p>The \"01;\" defines bold or not, and the \"3*m\" defines the actual color. So, if we look at line 117</p> <pre><code>117. export PS1='\\[\\033[01;32m\\]\\u\\[\\033[01;34m\\] \\w\\[\\033[00;33m\\]$(__git_ps1)\\[\\033[01;32m\\] \\$\\[\\033[00m\\] '\n</code></pre> <p>Let's work through it. <pre><code>export PS1=                  -&gt; means we are setting the PS1 variable.\n'\\[\\033[01;32m\\]\\u           -&gt; sets the username in the bash prompt to be bold green\n \\[\\033[01;34m\\]\\w           -&gt; sets the current path to be bold blue\n \\[\\033[00;33m\\]$(__git_ps1) -&gt; means that the git status variable (set when inside a git directory) is yellow\n [\\033[01;32m\\]\\$            -&gt; means that the dollar sign (or # when acting as root) is green\n \\[\\033[00m\\]'               -&gt; means the text you type will be the default text color.\n ```\n Here are the color definitions for reference.\n ```bash\n [00;30m] = normal black         [01;30m] = bold black\n[00;31m] = normal red           [01;31m] = bold red\n[00;32m] = normal green         [01;32m] = bold green\n[00;33m] = normal yellow        [01;33m] = bold yellow\n[00;34m] = normal blue          [01;34m] = bold blue\n[00;35m] = normal purple        [01;35m] = bold purple\n[00;36m] = normal cyan          [01;36m] = bold cyan\n[00;37m] = normal white         [01;37m] = bold white\n</code></pre></p>"},{"location":"misc/env_setup/#other-environment-files","title":"Other Environment Files","text":"<p>There are other files we use in the MAGICC lab that function similarly to the .bashrc. These files all live in the home directory, right next to the bashrc and are also run every time the terminal window is opened.</p>"},{"location":"misc/env_setup/#rosrc","title":".rosrc","text":"<p>We noticed that we were often changing ROS variables, such as the workspace, ROS_IP and ROS_MASTER_URI. As a result, we created our own file, called .rosrc, and added a line to the .bashrc that just sources the .rosrc file. This helped to separate the ROS environment from the rest of the operating system environment.</p> <p>The .rosrc file looks as follows: <pre><code>1. source set_ros_master local\n2. export ROSLAUNCH_SSH_UNKNOWN=1\n3.\n4. # ROS_WORKSPACE\n5. source /opt/ros/indigo/setup.bash\n6. #source ~/rel_nav_ws/devel/setup.bash\n</code></pre> The first line runs the \"set_ros_master\" script contained in /usr/local/bin. This automatically sets the ROS_MASTER_URI and ROS_HOSTNAME variables. It will also show the state of these variables when it runs if told to do so in the startup script.</p> <p>The second line is necessary for remote launching of ROS nodes. Not something you need to worry about now.</p> <p>Lines 4-6 define the workspace. By default, the toplevel ROS workspace sourced. Whenever you make a new workspace, you need to come in and \"source\" it so ROS can find the packages you've put in it. For example, if I were to make a new workspace called \"obstacle\" I would have an additional line in my .rosrc that looked like this.</p> <p><pre><code>6. source ~/obstacle/devel/setup.bash\n</code></pre> After making the change, I have to either</p> <p><pre><code>source ~/.bashrc\n</code></pre> or if you're using the relative_nav bashrc <pre><code>sbashrc\n</code></pre> is an alias for the same thing.</p>"},{"location":"misc/env_setup/#rosalias","title":".rosalias","text":"<p>This is a file that I sometimes have on my systems where I have programmed several aliases specific to ROS. I usually reference it from my .rosrc file. Here is a copy of my ~/.rosalias file <pre><code>1. alias fixCMake=\"rm CMakeLists.txt &amp;&amp; cp /opt/ros/indigo/share/catkin/cmake/toplevel.cmake CMakeLists.txt\"\n2.\n3. alias printROS=\"printenv | grep ROS\"\n</code></pre> The first line is a handy command to fix a common problem when first using qtcreator in a ROS workspace.</p> <p>The second prints out all the ROS-related environment variables</p>"},{"location":"misc/env_setup/#vimrc","title":".vimrc","text":"<p>One last file is the .vimrc file. Whenever vim opens, it first goes through the .vimrc file, and loads a couple of defaults, such as syntax highlighting for files, tab and space defaults, etc...</p> <p>Here is a copy of my ~/.vimrc file <pre><code>\"Convenient tab settings\nset tabstop=4\nset shiftwidth=2\nset softtabstop=2\nset expandtab\n\n\"Sets proper syntax highlighting for .launch, .rosrc, and .rosalias files\nau BufRead,BufNewFile *.launch set filetype=xml\nau BufRead,BufNewFile *.rosrc set filetype=sh\nau BufRead,BufNewFile *.rosalias set filetype=sh\n</code></pre> Vim also loads macros from the ~/.vim/plugin folder. David wrote a macro that automatically comments and uncomments code by pressing Ctrl+C and Ctrl+X respectively. If you're interested, you can look at that plugin.</p>"},{"location":"misc/qt_creator/","title":"Qt Creator","text":"<p>We generally use Qt Creator (officially pronounced \"cute\" but that sounds stupid, so most of us call it it \"Q-T\" creator instead) to do our C++ ROS development in the MAGICC lab. Technically, there are ways to use Eclipse as well, and a lot of times, you end up using vim or sublime (plain text editors) to make quick modifications, but Qt does a good job of linking between documents, and helping you code efficiently.</p> <p>Using Qt creator is super easy, given that you know a few things about setting it up.</p> <p>First, install Qt creator</p> <pre><code>sudo apt install -y qtcreator\n</code></pre>"},{"location":"misc/qt_creator/#setting-up-the-environment","title":"Setting Up the Environment","text":"<p>The installation of Qt Creator will automatically create an icon for you to use in the launcher, however if you don't make a modification to that shortcut, then it will not load the ROS environment if you use the icon in the unity bar to launch the program.</p> <p>To fix this, you have two options:</p> <ol> <li>always start qtcreator from the command line</li> <li>replace the contents of the /usr/share/applications/qtcreator.desktop with the following (You'll need to sudo)</li> </ol> <p><pre><code>[Desktop Entry]\nExec=bash -i -c qtcreator %F\nIcon=qtcreator\nType=Application\nTerminal=false\nName=Qt Creator\nGenericName=Integrated Development Environment\nMimeType=text/x-c++src;text/x-c++hdr;text/x-xsrc;application/x-designer;application/vnd.nokia.qt.qmakeprofile;application/vnd.nokia.xml.qt.resource;\nCategories=Qt;Development;IDE;\nInitialPreference=9\n</code></pre> This will load the environment variables when you start qt creator, and you won't need to always start it from the command line</p>"},{"location":"misc/qt_creator/#loading-your-project","title":"Loading your project","text":"<p>To load your project, simply open Qt Creator, then click \"Load Project\" and open the CMakeLists.txt file in your /src folder. This will often return an error about Qt Creator not having privileges to edit some toplevel.cmake file.</p> <p>To check this out, cd into your /src folder and type <pre><code>ls -l\n</code></pre> <p>You'll notice that there will be a \"symlink\" between CMakeLists.txt and /opt/ros/indigo/share/catkin/cmake/toplevel.cmake. What this means is that CMakeLists.txt is not a real file, it's just a link to that toplevel.cmake file, which requires sudo privileges to edit. We don't actually want to modify that file anyway, so all we'll do is delete the symlink and then make a new copy of that toplevel file in our folder right here. <pre><code>rm CMakeLists.txt\ncp /opt/ros/indigo/share/catkin/cmake/toplevel.cmake CMakeLists.txt\n</code></pre> by the way, I made this an alias in my .rosalias file <pre><code>alias fixCMake=\"rm CMakeLists.txt &amp;&amp; cp /opt/ros/indigo/share/catkin/cmake/toplevel.cmake CMakeLists.txt\"\n</code></pre> After you've fixed that, Qt Creator should have no problem loading the project.</p>"},{"location":"misc/qt_creator/#set-the-build-folder","title":"Set the Build Folder","text":"<p>After you have opened CMakelists.txt and cleared the write permissions error, you'll see something like the following:</p> <p></p> <p>You need to delete the part highlighted above. This makes the QtCreator build tool actually run the same process that a catkin_make would do.</p> <p>After this, Qt will build the project, and you'll be able to edit the code! Simply press Ctrl+B or F5 to run a catkin_make.</p>"},{"location":"misc/qt_creator/#running-ros-nodes-within-qt-creator","title":"Running ROS nodes within Qt Creator","text":"<p>QtCreator can be used to actually run the ros node without using the terminal. This can be accomplished by changing a few of the run settings within the project. Go to the Projects Tab on the left side of the screen. Then near the top, toggle from \"build\" to \"run\"</p> <p></p> <p>Under the Run, portion, click \"Add\", then \"Custom Executable\" from the drop-down menu.</p> <p></p> <p>Then, navigate to /devel/lib// . This is the compiled executable created by catkin_make. With this selected, now when you press the play button at the bottom of Qtcreator, it will run the ros node. Be sure you have a roscore running in the background, and that all messages you need are being published. <p>To change which node runs when you press play, just go change the custom executable you selected in the previous step.</p>"},{"location":"misc/qt_creator/#debugging-executables-nodes-compiled-with-cmake-in-qt-creator","title":"Debugging Executables (Nodes) Compiled with CMake in Qt Creator","text":"<p>QtCreator has a pretty nice little debugger. It allows you to set watches on variables, set breakpoints, etc.. It is pretty easy to set up for your CMake projects too. When debugging, your node will go much slower than in run mode, so there are some issues with messages being lost in memory during debugging, because messages aren't persistent. If you're aware of this, however, it can be pretty nice for debugging ROS nodes.</p> <p>All you have to do is add the CMake argument -DCMAKE_BUILD_TYPE=Debug to the Project build step.</p> <p></p> <p>Then, just click the play button with a bug on it to debug your code. It will take quite a bit longer to compile in debug mode, especially if you have a lot of nodes in your project, but it can be a life saver for finding bugs.</p>"},{"location":"misc/ros_command_cheat_sheet/","title":"ROS Command Cheat Sheet","text":""},{"location":"misc/ros_command_cheat_sheet/#roslocate","title":"roslocate","text":"<p>Displays Package Information</p> <pre><code>roslocate info [PACKAGE]\n</code></pre>"},{"location":"misc/ros_command_cheat_sheet/#roscreate-pkg","title":"roscreate-pkg","text":"<p>Create a new package</p> <pre><code>roscreate-pkg [package_name] [depend1] [depend2] [depend3]\n</code></pre>"},{"location":"misc/ros_command_cheat_sheet/#rospack","title":"rospack","text":"<p>Reindex packages</p> <pre><code>rospack profile\n</code></pre> <p>Find Packages</p> <pre><code>rospack find [PACKAGE]\n</code></pre> <p>List all nested dependencies</p> <pre><code>rospack depends(1) [PACKAGE]\n</code></pre>"},{"location":"misc/ros_command_cheat_sheet/#rosnode","title":"rosnode","text":"<p>List current ROS nodes</p> <pre><code>rosnode list\n</code></pre> <p>Detailed information about specific node</p> <pre><code>rosnode info [NODE]\n</code></pre>"},{"location":"misc/ros_command_cheat_sheet/#roscore","title":"roscore","text":"<p>Daemon running msg handling/etc</p>"},{"location":"misc/ros_command_cheat_sheet/#rosrun","title":"rosrun","text":"<p>Run a ros node</p> <pre><code>rosrun [PACKAGE] [NODE]\n</code></pre>"},{"location":"misc/ros_command_cheat_sheet/#rostopic","title":"rostopic","text":"<p>List the types of messages being published</p> <pre><code>rostopic list\n</code></pre> <p>for contents of message</p> <pre><code>rostopic echo [MESSAGE TOPIC]\n</code></pre> <p>Publish messages</p> <pre><code>rostopic pub [TOPIC] [MSG_TYPE] -- [ARGS]\n</code></pre>"},{"location":"misc/ros_command_cheat_sheet/#roslaunch","title":"roslaunch","text":"<p>Launch from a launch file</p> <pre><code>roslaunch [PACKAGE] [launch-file]\n</code></pre>"},{"location":"misc/setting_up_ssh/","title":"Setting Up ssh","text":""},{"location":"misc/setting_up_ssh/#what-is-ssh","title":"What is ssh?","text":"<p><code>ssh</code> (secure shell) is a program we use to work on remote computers. It allows you to log in to a remote computer, and open up a terminal window from that remote computer and display it on your screen. We can use this to work on the companion computer of a multirotor because it is not connected to a keyboard or monitor. With shell access, we can run commands (e.g. roslaunch), change code, copy a rosbag, move files, etc...</p> <p>Terminology: \"ssh server\": The (usually remote) computer that will be logged into; the machine whose ip address is <code>&lt;ip.ad.dr.ess&gt;</code> \"ssh client\": The computer you are using; the one on which you type <code>ssh &lt;username&gt;@&lt;ip.ad.dr.ess&gt;</code></p> <p>In all examples below, a multirotor named \"shredder\" is connected to the lab network and its IP address is <code>192.168.1.237</code>.</p> <p>Pre-requisites: The server's IP address needs to be routable from your client machine. E.g. If you are at home, and your IP address is <code>192.168.1.28</code>, and you want to <code>ssh</code> into shredder, the command <code>$ ssh shredder@192.168.1.237</code> will fail. This is because your home 192.168.1/24 subnet is different from the lab's 192.168.1/24 subnet. Your local machine needs to have the ssh-client, and the remote machine you will be accessing needs to have the ssh-server daemon running. To install both the server and client (perfectly acceptable to have both on both machines), type:</p> <pre><code>sudo apt install ssh\n</code></pre> <p>Ubuntu automatically enables the ssh-server daemon upon installation.</p> <p>For some history, and extended information beyond what is provided here, read the Arch Wiki article, as well as lots of posts on lots of websites. Just know that some sites are not peer reviewed by knowledgeable and experienced individuals, nor updated often (if ever). The Arch Wiki generally has both of these traits.</p>"},{"location":"misc/setting_up_ssh/#basic-overview","title":"basic overview","text":"<p><code>ssh</code> is actually really simple. It essentially consists of logging into a computer with a known username and password. For example, if I were connected to the lab network and typed</p> <pre><code> ssh shredder@192.168.1.237\n</code></pre> <p>I would be connecting to the computer whose IP address is 192.168.1.237 and logging in as the user \"shredder\". After providing shredder's password as requested on the command line, I would have a shredder terminal session on my computer. I could run commands, and move, edit and delete files, just as if I were typing on a keyboard directly attached to shredder.</p> <p>Try \"ssh-ing\" into your multirotor. Fill in the correct user and IP address where indicated. Type</p> <pre><code>ssh &lt;username&gt;@&lt;your.multirotor.ip.address&gt;\n</code></pre> <p>After you connect, it will ask you for your password--type it in, and see if you get in. If you have problems, talk to someone else about getting access. Otherwise, you are in your home folder on your vehicle! I realize that's not terribly exciting, but it's a start. To leave, simply hit <code>CTRL-D</code> on your keyboard, or type</p> <pre><code>$ exit\n</code></pre> <p>This places your terminal session back to controlling your local machine.</p>"},{"location":"misc/setting_up_ssh/#a-note-on-ports","title":"a note on ports","text":"<p>ssh by default will use port 22, but the magicc server is set up on port 290, so we have to manually change it. The \"-p 290\" command tells ssh to use port 290 on the server.</p>"},{"location":"misc/setting_up_ssh/#creating-a-custom-hostname","title":"Creating a Custom Hostname","text":"<p>What if I didn't want to type the full command,</p> <pre><code>$ ssh username@hostname\n</code></pre> <p>every time I wanted to log in? Well, ssh allows you to make custom aliases (e.g. nicknames) for different hosts. Here's how you could make a custom alias for shredder. (This assumes that you already have access.)</p> <p>First, navigate to your <code>~/.ssh/</code> directory. If it doesn't exist, then make it. Create a new \"config file by typing</p> <pre><code>$ gedit ~/.ssh/config\n</code></pre> <p>and create config stanzas by adding the following lines</p> <pre><code>ServerAliveInterval 90\n# IdentitiesOnly yes\n\nHost shred\n    Hostname 192.168.1.237\n    User shredder\n</code></pre> <p>Now, if you type</p> <pre><code>$ ssh shred\n</code></pre> <p><code>ssh</code> will replace \"shred\" with <code>shredder@192.168.1.237</code>. It can save a lot of typing over time.</p>"},{"location":"misc/setting_up_ssh/#shared-keys","title":"Shared Keys","text":"<p>But what if I didn't want to type my password every time I log in? For example, when you download a git repository from the magicc server, you would have to type your password every time you wanted to download an individual ros package. (That would mean you'd have to type your password ~30 times if you downloaded the full Relative_Nav stack). Luckily, <code>ssh</code> allows you to use a \"shared key\" between two computers by creating a private-public keypair. This allows a client to access a host without typing the password every time, because the client is recognized as a trusted source.</p> <p>Let's try this by creating a shared key between your computer and the magiccvs server. Start by navigating to that same <code>~/.ssh/</code> folder on your local machine, and typing</p> <pre><code>$ ssh-keygen\n</code></pre> <p>It will first ask you where to save the generated key. The default location is fine, so just press enter.</p> <p>It will then ask you for a \"passphrase\" which you can leave empty and just press enter a few times. Kudos if you assign a password to your private key. (We believe in security but not that much. :P) This will create a private key file, a public key file, and a fingerprint printed to screen as a box of random characters.</p> <p>Warning</p> <p>Safeguard your private key. If your machine, or your private key, get compromised, immediately decommision the public key that has been deployed to ssh servers, github, etc. Generate a new keypair after ensuring no persistent threat is present. Deploy your new public key to the services to which you need access.</p> <p>You usually do not need to worry about the fingerprint. If you care, there are some good superuser and stack exchange posts about it.</p> <p>Now, we want to copy that key over to shredder. The default settings that allow ssh login by username and password allow you to copy your public key to the remote machine using your password. To do this, simply type</p> <pre><code>ssh-copy-id shred\n</code></pre> <p>That copies the public key you just generated over to the vehicle, using the mapping you created in the previous section. You'll need to type your password for the magiccvs server to accept the new file. But after that, you'll no longer need to type your password to log into the magicc server from your computer. The <code>ssh</code> server will verify your identity using public-private key verification. You should go ahead and test it out!</p> <pre><code>ssh shred\n</code></pre>"},{"location":"misc/setting_up_ssh/#_1","title":"Setting Up ssh","text":"<p>Certain lab resources do not use the default settings, opting to disable password authentication. This is generally considered safer. In this case, you need to copy the contents of your <code>~/.ssh/id_rsa.pub</code> public key that was created with the <code>ssh-keygen</code> command. Paste that public key onto a new line in the <code>~/.ssh/authorized_keys</code> file on your <code>ssh</code> server.</p> <p>In this case, you would connect \"shredder\" to a monitor and keyboard, and copy the public key via e.g. a usb drive. Create the <code>authorized_keys</code> file if it does not already exist.</p> <p>You will also need to alter the appropriate stanza in your <code>~/.ssh/config</code>. First, uncomment <code>IdentitiesOnly yes</code> at the top of the file (as seen above in !#creating-a-custom-hostname). Next, add <code>IdentityFile ~/.ssh/private_key</code> inside the appropriate stanza.</p> <p>Your whole file should look something like this:</p> <p><code>~/.ssh/config</code></p> <pre><code>ServerAliveInterval 90\nIdentitiesOnly yes\n\nHost shred\n    Hostname 192.168.1.237\n    User shredder\n    IdentityFile ~/.ssh/your_private_key\n</code></pre>"},{"location":"misc/setting_up_ssh/#more-on-creating-a-key","title":"More on creating a key","text":"<p>There are several different types of keys that you can use. The default is an <code>rsa</code> key. You can look up its history if you are interested. What you need to know is that a 2048-bit rsa key used to be default. Now, modern computers can brute-force a 2048-bit rsa key in \"reasonable time\". It is recommended to use at least a 3072-bit rsa key (this is the current default). A 4096-bit key is currently considered more than sufficient. The larger the key, the longer it will take to authenticate, but on modern computers, it is generally negligible. An <code>ed25519</code> key type is considered about as strong as a 3072-bit rsa key. I personally prefer these because the public key is much shorter than one generated with <code>rsa</code>, and hence is feasibly typed should the necessity arise.</p> <p>You can create an ed25519 key with:</p> <pre><code>$ cd ~/.ssh\n$ ssh-keygen -t ed25519 -C \"remoteHost_usernameOnRemoteHost_localClientHostName_localUsername\" -f remoteHost_usernameOnRemoteHost_localClientHostName_localUsername\n</code></pre> <p>You'll notice this creates two files in your <code>~/.ssh/</code></p> <pre><code>$ cd ~/.ssh\n$ ls\n\nremoteHost_usernameOnRemoteHost_localClientHostName remoteHost_usernameOnRemoteHost_localClientHostName_localUsername.pub\n</code></pre> <p>Inside the pubkey, at the end, you will see the contents of the string you typed after the <code>-C</code>. <code>-C</code> is for \"comment\". You are free to type anything in this string. It is simply a method to help humans keep track of the contents/uses of that keypair. <code>-f</code> is the filename. I generally try to make the comment and the filename match, though this is not a requirement. If you paste the public key into your github <code>ssh</code> keys settings section, the comment is conveniently set to the title of that key. This is an example of how a comment can help you later. If you have multiple keys in your github account, and you need to decommission one of them, it will be easy to know, by its title, which needs to be removed.</p> <p>I recommend creating a new key for each <code>ssh</code> server you wish to connect to. Key management in this manner facilitates decommissioning a key because if a single key gets accidentally published somewhere, you can decommission on that server only (or service, e.g. github) and not have to worry about the other servers or services that you connect to with <code>ssh</code>. If you only use one key for everything, if that private key becomes compromised, you have to decommission and re-deploy to every. single. host/site/service. Thus, it is helpful to have meaningful comments and file names.</p>"},{"location":"misc/setting_up_ssh/#caveats","title":"Caveats","text":"<p>Note that you will have to use the nickname you set in the <code>Host</code> field if three conditions are met:</p> <ol> <li>You use <code>IdentitiesOnly</code> and <code>IdentityFile</code> in your stanza,</li> <li>You use a non-default filename (e.g. you set <code>-f some_non_default_key_name</code>) when generating the key, and</li> <li>That custom filename is in the config stanza</li> </ol> <p><code>ssh</code> will not know it needs to use that specific, custom keyname when attempting to authorize a connection. By using the nickname on the <code>Host</code> line that opens the stanza, you are informing <code>ssh</code> of the non-standard key name to use.</p>"},{"location":"misc/setting_up_ssh/#git","title":"git","text":"<p>This complicates certain things, e.g. cloning submodules with <code>git submodule update --init --recursive</code>. When you first clone a repo, you can use your nickname, if your stanza is configured for e.g. GitHub. Let's say for example you have ssh-ed into shredder, and have created a keypair and pasted the public key into GitHub to pull down changes you make on your main dev machine. Further, your GitHub username is <code>coolcoder</code>. A stanza in <code>/home/shredder/.ssh/config</code> could look like this:</p> <pre><code>Host ghub.coolcoder\n    HostName github.com\n    User git\n    IdentityFile ~/.ssh/github_coolcoder_shredder\n</code></pre> <p>Create the keypair with:</p> <pre><code>$ cd ~/.ssh\n$ ssh-keygen -t ed25519 -C \"github_coolcoder_shredder\" -f github_coolcoder_shredder\n</code></pre> <p>Copy the contents of <code>github_coolcoder_shredder.pub</code> into your GitHub account.</p> <p>To clone a repo and retrieve the submodule content, you would e.g.:</p> <pre><code>$ cd ~/repos\n$ git clone ghub.coolcoder:coolcoder/superawesome_research.git\n$ cd superawesome_research\n$ git submodule update --init --recursive\n</code></pre> <p>However, the last command would fail because your <code>.gitmodules</code> file should look something like this:</p> <pre><code>[submodule \"superawesome_utils\"]\n    path = superawesome_utils\n    url = git@github.com:coolcoder/superawesome_utils.git\n</code></pre> <p><code>ssh</code> would fail to authenticate you properly with GitHub because it did not use your GitHub keypair.</p> <p>To resolve this, you should alter the <code>.git/config</code> file in your local repo directory. There should be a line that looks like this:</p> <pre><code>[submodule \"superawesome_utils\"]\n        active = true\n        url = git@github.com:coolcoder/superawesome_utils.git\n</code></pre> <p>Note</p> <p>This section will only be visible after calling <code>submodule update</code>. So the workflow is to run it once, expecting it to fail, so that it writes this section to the local <code>.git/config</code>. Then, you can open that file in your favorite editor and make this following change:</p> <p>Change the url line to e.g. the following:</p> <pre><code>[submodule \"superawesome_utils\"]\n        active = true\n        url = ghub.coolcoder:coolcoder/superawesome_utils.git\n</code></pre> <p>and run a second time:</p> <pre><code>$ git submodule update --init --recursive\n</code></pre> <p>Now, ssh will know that when attempting to fetch the submodule content, it needs to verify identity with GitHub using your GitHub keypair, just as it does for your main repo. You probably do not want to change the <code>.gitmodule</code> file to use your ssh nickname because:</p> <ol> <li>If you clone it on a different machine you own, you may be using a different nickname, or keyfile name, or both</li> <li>If someone else is working on your code with you, they will have their own authentication method, e.g. perhaps they (inferiorly) prefer username/password authentication.</li> </ol> <p>So, leave the traditional clone url in the <code>.gitmodule</code> file in your repo.</p>"},{"location":"misc/syncing_time/","title":"Syncing Time","text":""},{"location":"misc/syncing_time/#motivation","title":"motivation","text":"<p>If you have more than one computer collecting data for your thesis or dissertation, you likely want that data correlated in some manner. If the time stamps for the data from machine a do not match those from machine b, you will likely not be able to combine the data. Don't rely on software up your stack to sync time. The hardware clock is the base. Use a proper mechanism to sync the hardware clocks of multiple machines. Use <code>chrony</code>.</p> <p>Let's define some terms:</p> <pre><code># e.g. a base station, or, *the time server*\namy=\"machine a\"\n# e.g. a rover, or, *the time client*\nbob=\"machine b\"\n\namy.ip=\"192.168.0.2\"\nbob.ip=\"192.168.0.3\"\n</code></pre> <p>Note!   - use a public NTP server that is geographically close to you---you will get better results   - If you have a gps antenna and module connected to your computer, you can use chrony to sync to GPS stratum 0   - you can check stratum of a particular server at https://servertest.online/ntp</p>"},{"location":"misc/syncing_time/#prerequisites","title":"Prerequisites","text":"<p>First install chrony on both <code>$amy</code> and <code>$bob</code>, then open <code>/etc/chrony/chrony.conf</code> for editing:</p> <pre><code>$ sudo apt install chrony\n</code></pre> <p>Configure your router(s) to always give the same IP address to each of <code>$amy</code> and <code>$bob</code>. This is usually in the \"advanced\" settings of your router. E.g. it will pair the MAC address of <code>$amy</code> to an IP address you specify, usually in a table of some sort.</p> <p>Note! <code>$amy</code>'s wireless card and ethernet port have unique MAC addresses.   If you plan to use one, or the other, or switch back and forth, make sure you configure a static IP for both.   You will need to extrapolate the <code>chrony.conf</code> server section on the client to allow it to search for both server IPs dynamically.   Similarly, if <code>$bob</code> has multiple methods of connecting, e.g. wireless and wired,   you will need to configure <code>$amy</code>'s <code>chrony.conf</code> to allow both client IPs to sync.</p>"},{"location":"misc/syncing_time/#terminology","title":"Terminology","text":"<ul> <li>stratum: how many \"hops\" your server is away from an atomic clock</li> <li>examples of \"stratum 0\": the time source, e.g. GPS time (attoseconds), atomic clock (attoseconds), LTE time (nanoseconds)</li> <li>examples of \"stratum 1\": the server that connects to the stratum 0 hardware --- time.google.com, some of time.apple.com</li> <li>leap smearing: leap seconds are smeared, rather than discontinuous jump</li> <li>It is not recommended to mix ntp upstream servers in your config that use smearing<ul> <li>that means the members of the following set should be used exclusive of the others:</li> <li>{the google pool | the facebook pool | a pool of servers that do not smear time }</li> </ul> </li> </ul>"},{"location":"misc/syncing_time/#settings-for-both-server-and-client","title":"Settings for both server and client","text":"<p>Both machines need to be configured to attempt to connect to an internet source when available. The <code>server</code> directive near the top of <code>chrony.conf</code> specifies \"upstream\" hosts that you want to request time from. A reasonable base is Google's public NTP pool, which are advertised as \"stratum 0.\"</p> <pre><code>server time1.google.com iburst trust prefer\nserver time2.google.com iburst trust prefer\nserver time3.google.com iburst trust prefer\nserver time4.google.com iburst trust prefer\n</code></pre> <p>You may want to modify/enable a few other directives on both server(s) and client(s). Read the man page and understand any and all directives before changing the defaults.</p> <pre><code>maxupdateskew 50\n\nmakestep 1.0 3\n\nhwtimestamp *\n\nrtconutc\n\nrtcsync\n</code></pre>"},{"location":"misc/syncing_time/#setting-up-the-server","title":"Setting up the Server","text":"<p>Configure the ip addresses that are allowed to talk to the server. Edit <code>/etc/chrony/chrony.conf</code>. About half-way down the file, replace lines that start with \"allow\":</p> <pre><code>allow 169.254/16\nallow 192.168.1\nallow ${subnet.of.bobs.ip}\nallow ${bob.ip}\n\nmanual\n\nlocal stratum 3 orphan\n</code></pre> <p>In this example, the first two lines are the subnets---CIDR notation is allowed. This allows any computer on those subnets to talk to the server. You can also set it to allow a specific IP address.</p> <p>The <code>manual</code> directive tells chrony that we want to be able to manually update the time. This is usually only necessary if the time servers in your network do not have a button-cell battery keeping their clocks alive when disconnected from power, e.g. odroid, raspberry pi, etc. That means when you power on the machines, and none of them can access the internet, they will all have a system clock starting at linux epoch time, or January 1, 1970. Chrony has a mechanism to store the last known sync time to disk, but it will be incorrect by as many days and hours lapsed un-powered, and powered with no internet connection. The take-away is if you will ever use <code>$amy</code> and <code>$bob</code> away from an internet connection, and if they both do not have a button-cell battery, you may decide that you want this directive. If <code>$bob</code> and <code>$amy</code> both sync to your laptop <code>$chad</code> in the field, the laptop will retain the correct data and hour away from the internet for quite a long time. And in the field, the only thing that matters is that your data is time-synced to each other. It won't matter that 3:03pm in the data was actually 3:02pm according to time.nist.gov.</p> <p>I do not include the <code>manual</code> directive, as I only use laptops as servers, and it simplifies a lot of setup when you get to the field for a flight test.</p> <p>Finally, the <code>orphan</code> directive is required if you have multiple machines, e.g. <code>$alice</code> and <code>$chad</code> serving time away from the internet. Pretty much, you may as well have it. You can (and should) read more specifics about it in the man page.</p> <p>Then restart chrony</p> <pre><code>$ sudo systemctl restart chrony.service\n</code></pre>"},{"location":"misc/syncing_time/#setting-up-the-client","title":"Setting up the Client","text":"<p>Then edit <code>/etc/chrony/chrony.conf</code> and replace the 4 server lines with the following (or add to them):</p> <pre><code>server ${amy.ip} iburst trust xleave minpoll 1 maxpoll 2\nserver ${chad.ip} iburst trust xleave minpoll 1 maxpoll 2\n</code></pre> <p>Finally, restart chrony</p> <pre><code>$ sudo systemctl restart chrony.service\n</code></pre>"},{"location":"misc/syncing_time/#checking-if-time-is-synchronized","title":"Checking if Time is Synchronized","text":"<p>To check if time is synced up, just use the following command on the client, e.g. <code>${bob}</code> (all of these commands will work on <code>${amy}</code> and <code>${chad}</code>, if you want to verify what they are registering)</p> <p><pre><code>$ sudo chronyc\n</code></pre> this puts you on the <code>chronyc</code> (chrony client) command line</p> <p>Note!  Chrony \"client\" is the user-facing chrony program used to send commands to <code>chronyd</code>, the daemon. It doesn't have anything to do with the \"ntp client\", e.g. <code>${amy}</code>. <code>chronyd</code>, the chrony daemon, is what is running in the background, and is managed by <code>systemd</code>.</p> <pre><code>chronyc&gt; tracking\n</code></pre> <p>The \"reference ID\" field should be the IP of the server. The calculated time offset is also calculated and shown with this command.</p> <p>Chrony works by speeding up or slowing down the clock to sync it with the server, so it might not be all the way up to date when you check it. To make it jump all at once, type</p> <pre><code>chronyc&gt; makestep\n</code></pre> <p>which should automatically sync the clock.</p> <p>Some other commands you may want:</p> <pre><code>chronyc&gt; help\nchronyc&gt; sources -v\nchronyc&gt; sourcestats -v\nchronyc&gt; activity\nchronyc&gt; ntpdata\nchronyc&gt; refresh\nchronyc&gt; clients\nchronyc&gt; serverstats\nchronyc&gt; rtcdata\nchronyc&gt; trimrtc\n</code></pre>"},{"location":"misc/using_git/","title":"Using Git","text":""},{"location":"misc/using_git/#what-is-git","title":"What is Git","text":"<p>We use a git repository to host our code, and manage the different versions. Ultimately, git is a great tool for software development with a lot of functionality to track changes, branch or merge different files, and the ability to quickly clone files from a server to a local computer to work on.</p>"},{"location":"misc/using_git/#installation","title":"Installation","text":"<p>It's just as easy as all the other programs so far. Simply type</p> <pre><code>sudo apt install git\n</code></pre>"},{"location":"misc/using_git/#complete-the-tutorial","title":"Complete the Tutorial","text":"<p>Before you do anything else, you should probably complete the github tutorial. It takes about 15 minutes, but 15 minutes now is totally worth saving hours over messing up the git repo later.</p>"},{"location":"misc/using_git/#continue","title":"Continue","text":"<p>Obviously, there's a lot more to learn about git, but there are actually a lot of great resources online that you should look at first. It would be redundant to put all that information here. Git itself has really good documentation that would teach you everything you could ever want to know about using git, and whatever isn't there, or isn't clear, is probably on some question on stackoverflow.com</p>"},{"location":"misc/using_vim/","title":"Using Vim","text":"<p>One thing you'll find yourself doing a lot is editing text files. It is sometimes really handy to be able to edit these files from within the terminal. Vim is an awesome program that you can use to quickly edit text files without leaving the terminal window. It has a great deal of support and some awesome key shortcuts that make editing easy. It does, however, have a pretty steep learning curve. This is to hopefully get you started and at least familiar with the program. If you want more information, you'll have to go to external resources, such as this one.</p>"},{"location":"misc/using_vim/#installing-vim","title":"Installing Vim","text":"<p>Installing Vim is just as easy as any other program on Linux</p> <pre><code>sudo apt install vim\n</code></pre> <p>and that's it!</p>"},{"location":"misc/using_vim/#editing-files","title":"Editing Files","text":"<p>To edit files, all you have to do is type</p> <pre><code>vim &lt;textfile&gt;\n</code></pre> <p>If \"textfile\" doesn't exist, then vim will create a new blank file and open it for you, otherwise it will open the existing file.</p> <p>When you first open vim, it's in \"navigation mode.\" In this mode, you can't actually just type stuff like you would normally expect, but you can use the arrow keys to navigate around the document, you can cut and paste, search and replace, and other useful things. If you don't realize that you're not in insert mode, then trying to type will probably result in really random behavior. To enter \"insert\" mode, type</p> <pre><code>i\n</code></pre> <p>In insert mode, you can now add text, delete text, and edit as you would normally expect. To leave insert mode, just press the Esc button.</p> <p>To leave the file, there are two mains ways to exit.</p> <p>First, to write your changes to file and exit,</p> <pre><code>:x\n</code></pre> <p>Second, to quit without saving changes</p> <pre><code>:q!\n</code></pre> <p>And that's all! Again, this is just barely scratching the surface of what vim can do. I would recommend looking through some of the keyboard shortcuts, and watching or reading some tutorials online. Knowing these shortcuts can really speed up your work, much faster than using a standard graphics-based editor like gedit or notepad++.</p>"},{"location":"misc/vpn_setup/","title":"VPN Setup","text":"<p>A VPN (Virtual Private Network) allows several devices that are on different networks to be placed on a common subnet. Routing can be configured such that only specific data is sent to the VPN while normal requests are sent to the open internet. However, that functionality is out of the scope here. We will provide a method that routes all network requests to the vpn.</p> <p>Note</p> <p>There are much simpler solutions available to solve the original problem that served as motivation for this article. You can read about that motivation in the Legacy: Intro paragraph. If you still want a VPN, WireGuard can now be used to create a simple, secure, and fast VPN. A few details are included here.</p> <p>TODO: describe how to set up wireguard vpn with hub and spokes</p>"},{"location":"misc/vpn_setup/#legacy","title":"Legacy","text":""},{"location":"misc/vpn_setup/#intro","title":"Intro","text":"<p>The VPN (Virtual Private Network) Allows us to tie several networks together under the same \"subnet,\" allowing all of the ROS computers to think they are on the same network, and function properly. This was a problem when we needed to add an odroid to the hex to process incoming USB data in real time and wireless connections were not fast enough so we tied the odroid to shredder with an ethernet cable and made a network between them. The only problem was that it was impossible to have the laptop, casey, or splinter be a part of that ROS network, and visualize or send commands. To solve that, we created a VPN with shredder as the host. Shredder assigns IPs on an arbitrary subnet that is accessible by any computer who is attached to shredder in any way. Therefore the odroid, and casey can both talk to each other as if they were next to each other in the network.</p> <p>We use a PPTP (Point-to-point tunneling protocol) VPN with virtually no security hosted by shredder. This will show you how to set it up.</p> <p>Most of this tutorial comes from Digital Ocean</p>"},{"location":"misc/vpn_setup/#establishing-shredder-as-the-host","title":"Establishing Shredder as the Host","text":"<p>Use an hdmi cable to connect shredder to a monitor. Click on the network connections manager. Click \"edit connection.\" click \"add.\" Make sure that the highlighted selection is \"ethernet.\" Click create. Change the \"connection name\" as desired. Click \"ipv4 settings.\" Change the \"method\" to \"shared to other computers.\" Click save and you're done. Shredder will now act as host for other computers to connect on the network.</p>"},{"location":"misc/vpn_setup/#setting-up-the-vpn-hosts","title":"Setting Up the VPN Hosts","text":"<p>The VPN host is going to act as the relay between networks. All the computers needs to be able to resolve it's IP address, so in our case, we made shredder the host, since it was a part of both networks. All of the following commands require root access, so just save yourself some typing and open a root command prompt.</p> <pre><code>sudo bash\n</code></pre>"},{"location":"misc/vpn_setup/#setting-up-pptpd","title":"Setting up pptpd","text":"<p>First, install the pptp server on shredder</p> <pre><code>apt install pptpd\n</code></pre> <p>Next, we need to go in and tell shredder which IP addresses to assign to clients and what to assign itself on the network. Use vim to edit \"/etc/pptpd.conf\". Find, uncomment and edit the following lines to look as follows:</p> <pre><code>localip 192.168.2.2\nremoteip 192.168.2.3-20\n</code></pre> <p>or something like that. This sets the hosts's IP to be 192.168.2.2, and opens up the next 28 addresses to be used by clients attached to the network.</p> <p>Next, we need to set up the authentication on the network. Each client will have a username and password and a static IP assigned to it, found in /etc/ppp/chap-secrets. Shredder's looks like the following:</p> <p></p> <p>Now we need to add some DNS servers, so that computers hooked to the VPN can have internet access. Historically, we've just used Google's DNS servers.</p> <p>Edit /etc/ppp/pptpd-options, find the lines starting with \"ms-dns\" uncomment these lines and add the following lines:</p> <pre><code>ms-dns 8.8.8.8\nms-dns 8.8.4.4\n</code></pre> <p>Now just start up the pptp service and the VPN is up and running!</p> <pre><code>service pptpd restart\n</code></pre>"},{"location":"misc/vpn_setup/#setting-up-the-iptables-rules","title":"Setting up the IPtables Rules","text":"<p>Now the hard part, we need to set up the port forwarding. First allow IPv4 and IPv6 address forwarding by editing <code>/etc/sysctl.conf</code> and uncomment the following two lines</p> <pre><code>net.ipv4.ip_forward = 1\n</code></pre> <p>and in the next section</p> <pre><code>net.ipv6.conf.all.forwarding=1\n</code></pre> <p>Next, we will set some NAT rules (Network Address Translation - the sole purpose of our VPN). In the command prompt, type the following rules. These rules assume that the host is accessing the network(s) on eth0 and wlan0, and the VPN will be on ppp0 Check ipconfig to make sure that the adapters are right. Sometimes, the adapters are on other devices, just swap them out in the following commands for whichever connections you want.</p> <pre><code>iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE &amp;&amp; iptables-save\niptables -t nat -A POSTROUTING -o wlan0 -j MASQUERADE &amp;&amp; iptables-save\niptables --table nat --append POSTROUTING --out-interface ppp0 -j MASQUERADE\niptables -I INPUT -s 10.0.0.0/8 -i ppp0 -j ACCEPT\niptables --append FORWARD --in-interface eth0 -j ACCEPT\niptables --append FORWARD --in-interface wlan0 -j ACCEPT\n</code></pre> <p>To be completely honest, I'm not 100% sure what these commands do. If someone else decided to dive through and figure out what all these things are, then that would be great. All I know is that iptables is the firewall in linux, and these commands make the computer act as a router on the various network connections.</p>"},{"location":"misc/vpn_setup/#special-consideration-for-a-cloud-server","title":"Special Consideration for a Cloud Server","text":"<p>If you are using a cloud server, such as the AWS or Google Compute Engine, in order to connect to the VPN, you'll need to change the security on the cloud server to allow TCP traffic on the appropriate ports. (Students have in the past just opened up TCP on all ports from anywhere. This is not secure. Do NOT do this.)</p>"},{"location":"misc/vpn_setup/#special-considerations-for-the-odroid","title":"Special Considerations for the Odroid","text":"<p>The host in our setup needed an ethernet connection to the odroid on board. This required an additional step in which we created a bridge to the odroid. To do this, all you have to do is open the network manager on the host (From the GUI), and edit the wired connection. Under the IPv4 Settings, change it from \"Automatic\" to \"Shared to Other Computers.\" This creates a network between the two computers. Pull up ipconfig and make a note of the host's IP address on this wired network, because this will be the gateway for the odroid.</p>"},{"location":"misc/vpn_setup/#connecting-a-client","title":"Connecting a Client","text":"<p>We will now be connecting a client (odroid) to the host that we just set up. Connect the odroid to a monitor with an hdmi cable.</p> <p>First, if you are running lubuntu (odroid), pptp does not come default, install it with</p> <pre><code>sudo apt install network-manager-pptp\n</code></pre> <p>It comes default with the standard ubuntu install. Open the network manager and add a connection. Scroll down and select PPTP, then create</p> <p></p> <p>In the following dialog, name the connection something other than \"VPN Connection 1\" add the hosts IP as the gateway, and the username and password (from the chap-secrets file) of the client that is connecting to the host. Click \"Advanced\" and check the box \"Use Point-to-Point encryption MPPE\"</p> <p>[Image:VPN_1] [Image:VPN_2]</p> <p>Click \"OK\" then \"Save\" and close the network manager.</p> <p>To Connect to the VPN, simply click the network icon in the upper right, hover over VPN Connections, and select the newly created VPN. It should think for a minute, then display \"VPN Connection Successful\".</p> <p>If you type</p> <pre><code>ifconfig\n</code></pre> <p>into the command prompt, you should now see an additional pppX connection with a new IP address.</p>"},{"location":"misc/vpn_setup/#auto-connecting-to-the-vpn","title":"Auto connecting to the VPN","text":"<p>To automatically connect to the VPN, such as when using the Odroid, there are a few steps.</p>"},{"location":"misc/vpn_setup/#disable-the-keyring","title":"Disable the keyring","text":"<p>First, you have disable the \"Default Keyring\" (that annoying pop-up that asks for your password every time you log in). You have to install and open the password manager found in regular Ubuntu</p> <pre><code>sudo apt install seahorse\nseahorse\n</code></pre> <p>In the leftmost column under Passwords, right click the \"Default\" folder, and select \"change password\" Type the keyring password, then leave the new password fields blank. It will give you some message about it being unsafe, just ignore it and reboot the Odroid.</p>"},{"location":"misc/vpn_setup/#automatically-connect-to-the-ethernet","title":"Automatically Connect to the Ethernet","text":"<p>Although you have already disabled the keyring, you still have to get around it for user permission issues. To do this, edit the VPN connection file /etc/NetworkManager/system-connections/shredder and change the field</p> <pre><code>password-flags=0\n</code></pre> <p>and then add at the bottom the two lines</p> <pre><code>[vpn-secrets]\npassword=&lt;password&gt;\n</code></pre> <p>you also need to tell the ethernet connection to automatically connect to the VPN. Go to Network connections manager. Make sure the ethernet connection is highlighted and click \"edit.\" Then click the \"general\" tab. Check the box that says \"automatically connect to VPN when using this connection.\"</p> <p>Then reboot the odroid. It should automatically connect to the VPN, the Ethernet and the WiFi without any intervention</p>"},{"location":"ros2_tutorials/adv_launch_file/","title":"Additional Launch File Syntax","text":""},{"location":"ros2_tutorials/adv_launch_file/#topic-remapping-in-launch-files","title":"Topic Remapping in Launch Files","text":"<p>When we first learned about launch files we had to do some topic remapping in order to get mimic to work properly. The code is repeated here:</p> <p>(Python) <pre><code>from launch import LaunchDescription\nfrom launch_ros.actions import Node\n\ndef generate_launch_description():\n    return LaunchDescription([\n        Node(\n            package='turtlesim',\n            namespace='turtlesim1',\n            executable='turtlesim_node',\n            name='sim'\n        ),\n        Node(\n            package='turtlesim',\n            namespace='turtlesim2',\n            executable='turtlesim_node',\n            name='sim'\n        ),\n        Node(\n            package='turtlesim',\n            executable='mimic',\n            name='mimic',\n            remappings=[\n                ('/input/pose', '/turtlesim1/turtle1/pose'),\n                ('/output/cmd_vel', '/turtlesim2/turtle1/cmd_vel'),\n            ]\n        )\n    ])\n</code></pre></p> <p>(XML) <pre><code>&lt;launch&gt;\n  &lt;node pkg=\"turtlesim\" exec=\"turtlesim_node\" name=\"sim\" namespace=\"turtlesim1\"/&gt;\n  &lt;node pkg=\"turtlesim\" exec=\"turtlesim_node\" name=\"sim\" namespace=\"turtlesim2\"/&gt;\n  &lt;node pkg=\"turtlesim\" exec=\"mimic\" name=\"mimic\"&gt;\n    &lt;remap from=\"/input/pose\" to=\"/turtlesim1/turtle1/pose\"/&gt;\n    &lt;remap from=\"/output/cmd_vel\" to=\"/turtlesim2/turtle1/cmd_vel\"/&gt;\n  &lt;/node&gt;\n&lt;/launch&gt;\n</code></pre></p> <p>The syntax above can be used whenever topic remapping is required within launch files. Notice that the syntax above places the remapping inside the node <code>mimic</code>:</p> <p>(Python) <pre><code>    Node(\n        package='turtlesim',\n        executable='mimic',\n        name='mimic',\n        remappings=[\n            ('/input/pose', '/turtlesim1/turtle1/pose'),\n            ('/output/cmd_vel', '/turtlesim2/turtle1/cmd_vel'),\n        ]\n    )\n</code></pre></p> <p>(XML) <pre><code>  &lt;node pkg=\"turtlesim\" exec=\"mimic\" name=\"mimic\"&gt;\n    &lt;remap from=\"/input/pose\" to=\"/turtlesim1/turtle1/pose\"/&gt;\n    &lt;remap from=\"/output/cmd_vel\" to=\"/turtlesim2/turtle1/cmd_vel\"/&gt;\n</code></pre></p> <p>The syntax below is also used often but don't be confused because in this case the remapping is done outside of the node argument. When using this syntax, the remapping must be called before the node it acts on, or else it won't take effect. This is true for remapping topics and node names.</p> <p>(Python) <pre><code>    SetRemap(src='/input/pose', dst='/turtlesim1/turtle1/pose'),\n    SetRemap(src='/output/cmd_vel', dst='/turtlesim2/turtle1/cmd_vel'),\n    Node(\n        package='turtlesim',\n        executable='mimic',\n        name='mimic'\n    )\n</code></pre></p> <p>(XML) <pre><code>    &lt;remap from=\"/george/turtle1/cmd_vel\" to=\"/turtle1/cmd_vel\"/&gt;\n\n    &lt;group ns=\"george\"&gt;\n    &lt;node pkg=\"turtlesim\" name=\"sim\" type=\"turtlesim_node\"/&gt;\n    &lt;/group&gt;\n</code></pre></p>"},{"location":"ros2_tutorials/adv_launch_file/#loading-parameters-in-launch-files","title":"Loading Parameters in Launch Files","text":"<p>See \"2 Parameters\" in \"Managing large projects\".</p>"},{"location":"ros2_tutorials/adv_launch_file/#yaml-files-example","title":"YAML Files Example","text":"<p>Previously using <code>ros2 param dump</code> we created a YAML file which stored parameter values for us.  We can also create this file manually.  We just need to create a file with the .yaml extension which holds all our parameter information.  An example is the following which is contained within ps2.yaml:</p> <pre><code>joy_commander: {\n x_axis: 3,\n y_axis: 2,\n yaw_axis: 0,\n\n alt_axis: 5,\n\n x_sign: 1,\n y_sign: -1,\n yaw_sign: -1,\n\n mode_but: 0,\n llpp_but: 1,\n }\n</code></pre> <p>This set of parameters defines buttons on a joystick controller for use with the joy_commander node.  Since these parameters change with the type of controller used (Xbox 360 vs. PS2) it makes sense to group them within a .yaml file.</p> <p>In order to load a .yaml file within a launch file the following syntax is used:</p> <pre><code> &lt;param from=\"$(find rosparam)/example.yaml\"/&gt;\n</code></pre> <p>For additional information about launch file formats, consult the documentation Using Python, XML, and YAML for ROS 2 Launch Files and Migrating launch files from ROS 1 to ROS 2.</p>"},{"location":"ros2_tutorials/c%2B%2B_node_class/","title":"Nodes Based on Classes (C++)","text":""},{"location":"ros2_tutorials/c%2B%2B_node_class/#classes","title":"Classes","text":"<p>If you have taken CS 142, you'll remember C++ classes. If you haven't or you have and you're totally lost, then you should probably brush up on your C++.  This is a pretty good tutorial that should help you get up to speed on C++ programming.</p> <p>In short, we use classes because they are convenient.  They may not seem so convenient at first, but being able to split up your code into different files makes it a lot easier, and classes make it easy to store variables in between function calls, and limit the scope of functions.  You could just program every node in one giant main cpp file, but that eventually becomes unreasonable.</p> <p>In the MAGICC lab, we generally organize our nodes as follows:</p> <p></p> <p>We have the <code>CMakelists.txt</code> file that you're used to seeing, the <code>package.xml</code>, but then we make an include folder with the <code>.hpp</code> file inside, the <code>.cpp</code> file that implements the class functions, and then the main file, which is more of a ROS2 daemon than anything (spins up the node, and connects it to ROS2).  Almost all of the actual work is done in the class <code>.cpp</code> file.</p>"},{"location":"ros2_tutorials/c%2B%2B_node_class/#example-moving-sensor-package","title":"Example: Moving Sensor Package","text":"<p>The picture above has the general outline of what is in each node, but here's an example node which listens to the turtlesim pose message and publishes a boolean flag of whether or not it is moving. The \"moving_sensor\" package is in the <code>ros2-tutorials</code> git repo. \"Bool.msg\" in \"bool_interfaces/msg\" is a message type I created which is simply \"bool data\". If you're interested in creating custom msg and srv files, see here.</p> <p>The file structure appears as follows:</p> <pre><code>moving_sensor\n\u251c\u2500\u2500 CMakeLists.txt\n\u251c\u2500\u2500 package.xml\n\u251c\u2500\u2500 include\n\u2502   \u251c\u2500\u2500 moving_sensor\n\u2502   \u2502   \u2514\u2500\u2500 moving_sensor.hpp\n\u251c\u2500\u2500 src\n\u2502   \u251c\u2500\u2500 moving_sensor.cpp\n\u2502   \u2514\u2500\u2500 moving_sensor_node.cpp\n</code></pre>"},{"location":"ros2_tutorials/c%2B%2B_node_class/#cmakeliststxt","title":"CMakeLists.txt","text":"<p>Let's look at the <code>CMakeLists.txt</code> of this package.  I've highlighted what each line does in this file below</p> <pre><code>cmake_minimum_required(VERSION 3.8)\nproject(moving_sensor)  # &lt;-- this is the project name, should match in the package.xml\n\nif(CMAKE_COMPILER_IS_GNUCXX OR CMAKE_CXX_COMPILER_ID MATCHES \"Clang\")\n  add_compile_options(-Wall -Wextra -Wpedantic)\nendif()\n\nfind_package(ament_cmake REQUIRED)        # This goes out and finds the packages required for our moving sensor.\nfind_package(turtlesim REQUIRED)          # We need turtlesim because we are listening to turtlesim/msg/Pose messages.\nfind_package(bool_interfaces REQUIRED)    # We need bool_interfaces because we are publishing a bool_interfaces/msg/Bool.\nfind_package(rclcpp REQUIRED)             # Often, we need Eigen, tf, and other packages that we use in the node.\n\n\ninclude_directories(include) # This line makes sure the compiler looks in the include folder for our headers\ninclude_directories(\n  ${ament_INCLUDE_DIRS}      # This line adds in the headers already added by ament.\n)\n\n## Declare a cpp executable\nadd_executable(moving_sensor_node src/moving_sensor_node.cpp src/moving_sensor.cpp)\n# These lines create the executable (node).  You can make more than\n# one node per package, each node should have only one main() function.\n# We explicitly tell it which .cpp files to compile into that node\n\n## Add ament target dependencies of the executable/library\nament_target_dependencies(moving_sensor_node rclcpp turtlesim bool_interfaces)\n# This ensures that the turtlesim and bool_interfaces packages, including their messages, are properly set up before your node is built.\n\ninstall(TARGETS\n  moving_sensor_node\n  DESTINATION lib/${PROJECT_NAME})\n\nament_package()\n</code></pre>"},{"location":"ros2_tutorials/c%2B%2B_node_class/#packagexml","title":"package.xml","text":"<p>Let's look now at the <code>package.xml</code>.  This file is by far the easiest of the bunch it's pretty much self-explanatory</p> <pre><code>&lt;?xml version=\"1.0\"?&gt;\n\n&lt;package format=\"3\"&gt;\n  &lt;name&gt;moving_sensor&lt;/name&gt;\n  &lt;version&gt;0.0.0&lt;/version&gt;\n  &lt;description&gt;The moving_sensor package&lt;/description&gt;\n\n  &lt;maintainer email=\"hebeshen@byu.edu\"&gt;hebeshen&lt;/maintainer&gt;\n\n  &lt;license&gt;Apache-2.0&lt;/license&gt;\n\n  &lt;buildtool_depend&gt;ament_cmake&lt;/buildtool_depend&gt;\n  &lt;depend&gt;turtlesim&lt;/depend&gt;\n  &lt;depend&gt;bool_interfaces&lt;/depend&gt;\n  &lt;depend&gt;rclcpp&lt;/depend&gt;\n\n  &lt;export&gt;\n    &lt;build_type&gt;ament_cmake&lt;/build_type&gt;\n  &lt;/export&gt;\n\n&lt;/package&gt;\n</code></pre>"},{"location":"ros2_tutorials/c%2B%2B_node_class/#moving_sensorhpp","title":"moving_sensor.hpp","text":"<pre><code>#ifndef MOVING_SENSOR_HPP\n#define MOVING_SENSOR_HPP\n\n#include \"rclcpp/rclcpp.hpp\"\n#include \"turtlesim/msg/pose.hpp\"\n#include \"bool_interfaces/msg/bool.hpp\"\n\nnamespace moving_sensor\n{\n\nclass MovingSensor : public rclcpp::Node\n{\npublic:\n  MovingSensor();\n\nprivate:\n  //***************** PUBLISHERS AND SUBSCRIBERS ***************//\n  rclcpp::Subscription&lt;turtlesim::msg::Pose&gt;::SharedPtr pose_subscriber_;\n  // will end up getting hooked up to the callback for the Pose message\n\n  rclcpp::Publisher&lt;bool_interfaces::msg::Bool&gt;::SharedPtr bool_publisher_;\n  // will publish the flag to ROS2\n\n  //***************** PARAMETERS ***************//\n  double threshold_;\n  // a parameter we get from the ROS2 server, in this case the value below which\n  // we consider the turtle as not moving.  This is basically a class variable\n  // at this point,\n\n  //***************** STATE VARIABLES ***************//\n  // in this node, we don't have any variables.  Often though, we need to remember\n  // things between loops, so we could create variables here to hold those values\n\n  //***************** CALLBACKS ***************//\n  void poseCallback(const turtlesim::msg::Pose::SharedPtr msg);\n  // this function will get called every time ROS2 \"spins\"\n  // and there is a Pose message in the queue.  More on this\n  // later\n\n  //***************** FUNCTIONS ***************//\n  // Also, in this node, we don't have any \"helper\" functions.  These are useful\n  // if you need to break up the work in the node into different functions\n};\n\n} // namespace moving_sensor\n\n#endif // MOVING_SENSOR_HPP\n</code></pre>"},{"location":"ros2_tutorials/c%2B%2B_node_class/#moving_sensorcpp","title":"moving_sensor.cpp","text":"<pre><code>#include \"moving_sensor/moving_sensor.hpp\"\n\nnamespace moving_sensor\n{\n\nMovingSensor::MovingSensor() : Node(\"moving_sensor_node\")\n{\n  //***************** RETRIEVE PARAMS ***************//\n  this-&gt;declare_parameter&lt;double&gt;(\"threshold\", 0.0001);\n  this-&gt;get_parameter(\"threshold\", threshold_);\n  // This will pull the \"threshold\" parameter from the 2 server, and store it in the threshold_ variable.\n  // If no value is specified on the ROS2 param server, then the default value of 0.0001 will be applied.\n\n  //***************** NODE HANDLES ***************//\n  pose_subscriber_ = this-&gt;create_subscription&lt;turtlesim::msg::Pose&gt;(\n    \"turtle1/pose\", 1, std::bind(&amp;MovingSensor::poseCallback, this, std::placeholders::_1)\n  );\n  // This connects the poseCallback function with the reception of a Pose message on the \"turtle1/pose\" topic\n  // ROS2 will essentially call the poseCallback function every time it receives a message on that topic.\n  // the \"1\" indicates the length of the queue to hold messages before tossing them.  In this case, our callback\n  // function is so fast that 1 is sufficient.\n\n  bool_publisher_ = this-&gt;create_publisher&lt;bool_interfaces::msg::Bool&gt;(\"is_moving\", 1);\n  // This connects a std_msgs::Bool message on the \"is_moving\" topic.  The 1 also indicates the length of the queue\n  // before tossing messages.  Publishers are generally so fast that 1 almost always works.\n}\n\nvoid MovingSensor::poseCallback(const turtlesim::msg::Pose::SharedPtr msg)\n// This function runs every time we get a turtlesim::Pose message on the \"turtle1/pose\" topic.\n// We generally use the const &lt;message&gt;ConstPtr &amp;msg syntax to prevent our node from accidentally\n// changing the message, in the case that another node is also listening to it.\n{\n  bool_interfaces::msg::Bool out_flag;  // create a new message to store the result of our check in\n  out_flag.data = msg-&gt;linear_velocity &gt; threshold_;\n  // figure out if our velocity is more than the threshold and save the result in our new message\n\n  // publish the message to ROS2\n  bool_publisher_-&gt;publish(out_flag);\n}\n\n} // namespace moving_sensor\n</code></pre>"},{"location":"ros2_tutorials/c%2B%2B_node_class/#moving_sensor_nodecpp","title":"moving_sensor_node.cpp","text":"<pre><code>#include \"moving_sensor/moving_sensor.hpp\"\n\nint main(int argc, char **argv)\n{\n  rclcpp::init(argc, argv);\n  rclcpp::spin(std::make_shared&lt;moving_sensor::MovingSensor&gt;());\n  // instatiate our class object and check for new messages and call the callback if we get one\n\n  rclcpp::shutdown();\n  return 0;\n}\n</code></pre>"},{"location":"ros2_tutorials/creating_nodes/","title":"Creating Nodes","text":"<p>Now you know most everything you need to know about launch files, it's time to learn how to create your own nodes. However, before we start, it's important for you to know how to set up a C++/Python environment since that is the language we use most often.</p>"},{"location":"ros2_tutorials/creating_nodes/#setting-up-ide","title":"Setting up IDE","text":"<p>When working with large c++ projects, simple text editors like vim or sublime really don't cut it.  Instead, we have IDE (Integrated Development Environment).  </p>"},{"location":"ros2_tutorials/creating_nodes/#setting-up-clion","title":"Setting up CLion","text":"<p>CLion is free for students who apply for a JetBrains student license. You can download it from the Ubuntu app center or from its official website. </p>"},{"location":"ros2_tutorials/creating_nodes/#setting-up-vscode","title":"Setting up VSCode","text":"<p>VSCode (Visual Studio Code) is completely free. You can download it from the Ubuntu app center or from its official website.</p>"},{"location":"ros2_tutorials/creating_nodes/#_1","title":"Lesson 10: Creating Nodes","text":"<p>Two websites that might help:</p> <p>Clion ROS2 setup tutorial</p> <p>ROS 2 and VSCode</p>"},{"location":"ros2_tutorials/creating_nodes/#creating-your-own-nodes","title":"Creating Your Own Nodes","text":"<p>These links will take you to the official ROS2 tutorials which are pretty good at covering this subject.</p>"},{"location":"ros2_tutorials/creating_nodes/#creating-nodes-in-c","title":"Creating Nodes in C++:","text":"<p>ROS2: Writing a Simple Publisher and Subscriber (C++)</p>"},{"location":"ros2_tutorials/creating_nodes/#creating-nodes-in-python","title":"Creating Nodes in Python:","text":"<p>ROS2: Writing a Simple Publisher and Subscriber (Python)</p>"},{"location":"ros2_tutorials/filesystem/","title":"The ROS Filesystem","text":""},{"location":"ros2_tutorials/filesystem/#package","title":"Package","text":"<p>Now that you have gotten a little experience with ROS2, you're ready to start working within the file system.</p> <p>Packages are the software organization unit of ROS2 code. Each package can contain libraries, executables, scripts, or other artifacts. For example, the <code>turtlesim</code> and <code>teleop_turtle</code> nodes are both contained in the <code>turtlesim</code> package.</p>"},{"location":"ros2_tutorials/filesystem/#filesystem-tool-ros2-pkg","title":"Filesystem Tool: ros2 pkg","text":"<p><code>ros2 pkg</code> allows you to get information about packages. </p>"},{"location":"ros2_tutorials/filesystem/#ros2-pkg-prefix","title":"ros2 pkg prefix","text":"<p><code>ros2 pkg prefix</code> returns the prefix path to the package.</p> <p>Usage: <pre><code> ros2 pkg prefix [package_name]\n</code></pre></p> <p>Example: <pre><code> ros2 pkg prefix rclcpp\n</code></pre></p> <p>Would return (might be different if you have a different installation path): <pre><code> /opt/ros/jazzy\n</code></pre></p> <p><code>ros2 pkg prefix</code> only gives you the prefix path instead of the absolute path. To actually \"cd\" (Change Directory) to a certain package, try: <pre><code> cd $(ros2 pkg prefix [package_name])\n cd share/[package_name]\n</code></pre></p>"},{"location":"ros2_tutorials/filesystem/#ros2-pkg-list","title":"ros2 pkg list","text":"<p><code>ros2 pkg list</code> outputs a list of available packages.</p>"},{"location":"ros2_tutorials/filesystem/#ros2-pkg-executables","title":"ros2 pkg executables","text":"<p><code>ros2 pkg executables</code> outputs a list of package specific executables.</p> <p>Example: <pre><code>ros2 pkg executables turtlesim\n</code></pre> <pre><code>turtlesim draw_square\nturtlesim mimic\nturtlesim turtle_teleop_key\nturtlesim turtlesim_node\n</code></pre></p>"},{"location":"ros2_tutorials/filesystem/#ros2-pkg-create","title":"ros2 pkg create","text":"<p><code>ros2 pkg create</code> is used to create a new package. You'll learn more about this command in Lesson 5.</p>"},{"location":"ros2_tutorials/filesystem/#more-filesystem-concepts","title":"More Filesystem Concepts","text":""},{"location":"ros2_tutorials/filesystem/#colcon","title":"colcon","text":"<p>In ROS1, the build tool we often use is \"catkin_make\". In ROS2, we use colcon which is an iteration on catkin_make, catkin_make_isolated, catkin_tools, and ament_tools.</p> <p>Please install colcon with: <pre><code> sudo apt install python3-colcon-common-extensions\n</code></pre></p> <p>More information about colcon</p>"},{"location":"ros2_tutorials/filesystem/#workspace-package","title":"Workspace &amp; Package","text":"<p>Normally we would put our packages in one place, and a workspace is the directory where you can store your packages.</p> <p></p> <p>A single workspace can have as many packages as you need. Every package has its own folder, and can be of different build types (ament_python, ament_cmake, cmake).</p> <p>In order to complete the following tutorial in Lesson 5 we need a package in which to place our launch file in. Go ahead and complete these two tutorials from the official ROS tutorials.</p> <p>Creating a workspace</p> <p>Creating a package</p>"},{"location":"ros2_tutorials/filesystem/#review","title":"Review","text":"<ul> <li>ROS2 packages: an organizational unit for ROS2 code</li> <li><code>ros2 pkg</code>: a filesystem tool to interface with packages<ul> <li><code>ros2 pkg prefix</code>: output the prefix path of a package</li> <li><code>ros2 pkg list</code>: outputs a list of available packages</li> <li><code>ros2 pkg executables</code>: outputs a list of package specific executables</li> <li><code>ros2 pkg create</code>: create a new package</li> </ul> </li> </ul>"},{"location":"ros2_tutorials/intro/","title":"Introduction to ROS2","text":""},{"location":"ros2_tutorials/intro/#ros","title":"ROS","text":""},{"location":"ros2_tutorials/intro/#why-ros","title":"Why ROS?","text":"<p>According to the ROS website, \"ROS (Robot Operating System) is an open source software development kit for robotics applications. ROS offers a standard software platform to developers across industries that will carry them from research and prototyping all the way through to deployment and production.\" Specifically, ROS simplifies the plumbing required to connect together the components of a robotic system, it provides tools for simulating and inspecting the behavior of the system, and it provides a common platform that enables the sharing of technologies and ideas. </p>"},{"location":"ros2_tutorials/intro/#why-ros2","title":"Why ROS2?","text":"<p>\u201cSince ROS was started in 2007, a lot has changed in the robotics and ROS community. The goal of the ROS 2 project is to adapt to these changes, leveraging what is great about ROS 1 and improving what isn\u2019t.\u201d </p> <p>Pros of ROS2: - decentralized (no master node)  - uses DDS-based middleware for communication - compatible with Linux, Windows, Mac, and microcontroller RTOSs - supports Python 3 - introduces new concepts, such as node life cycles - offer standardized framework for multi-robot cooperation</p> <p>ROS2 offers better robustness, flexibility, and safety.  </p> <p>Picture Link</p>"},{"location":"ros2_tutorials/intro/#plumbing","title":"Plumbing","text":"<p>One of the challenges of developing a robotic system is developing the \"plumbing\" to connect data from all of the different subsystems together. Consider, for example, the requirements for a robot that, using an altimeter, Xbox Kinect, and IMU, can safely drive through a room making a map as it goes. A graph of the components of this system is depicted below, the arrows indicate the flow of data from one component to another.  </p> <p>Starting from scratch, much of the development time (and frustration) on a system like this would be spent figuring out how to get data from one subsystem to another. If you aren't careful, the result could be very brittle, requiring extensive rework if a component is changed, or if system requirements change. To solve these issues you could spend hours creating a modular system for message passing, or you could use ROS2. ROS2 was developed to solve problems such as this. It enables high modularity by creating standalone nodes that can be easily reused and that have well-defined data interfaces. These interfaces are known as topics. Below is a figure depicting the example system from above as a set of ROS2 nodes (blue boxes), communicating with each other through messages known as topics (green arrows).  </p> <p>Every message \"input\" on a node is referred to as a subscriber, and every message \"output\" is known as a publisher. There can be multiple publishers and subscribers to a topic.  </p> <p>Picture Link</p>"},{"location":"ros2_tutorials/intro/#tools","title":"Tools","text":"<p>ROS2 provides many helpful tools for debugging and inspecting the behavior of a system. This is a brief overview of some of the most useful.</p>"},{"location":"ros2_tutorials/intro/#rqt_graph","title":"rqt_graph","text":"<p>rqt_graph gives a graphical representation of the currently active nodes and topics, allowing you to see what nodes are subscribing to and to make sure that everything is connected the way you intended. </p>"},{"location":"ros2_tutorials/intro/#rqt_plot","title":"rqt_plot","text":"<p>rqt_plot will subscribe to topics and plot their data over time. </p>"},{"location":"ros2_tutorials/intro/#ros2-bag","title":"ros2 bag","text":"<p>The ros2 bag command allows you to record all of the data that is being published, and save it into a file known as a ros2 bag. This file can then be replayed as if the system were currently running, or examined using rqt_bag.  </p>"},{"location":"ros2_tutorials/intro/#rqt_bag","title":"rqt_bag","text":"<p>rqt_bag reads a ros2 bag and provides a nice gui for interacting with it. It shows a graph of when messages were published, and it can plot data from specific messages. </p>"},{"location":"ros2_tutorials/intro/#tf-tf2","title":"tf (tf2)","text":"<p>tf (tf2 for ROS2) keeps track of coordinate frames and transformations, doing the kinematics for you. </p>"},{"location":"ros2_tutorials/intro/#rviz","title":"RViz","text":"<p>RViz provides a visualization environment for visualizing coordinate frames, point clouds, paths, goals, models, etc. </p>"},{"location":"ros2_tutorials/intro/#plotjuggler","title":"PlotJuggler","text":"<p>PlotJuggler is a \"Fast, intuitive and extensible time series visualization tool\". It \"works seamlessly with both ROS and ROS2\" on rosbag loading, topic subscribing, and message re-publishing and visualization in RViz.</p> <p></p> <p>Website Link</p> <p>This overview was based on a powerpoint by Paul Nyholm and David Wheeler.</p>"},{"location":"ros2_tutorials/intro/#ros2-versions","title":"ROS2 Versions","text":"<p>A new version of ROS2 is released every year on May 23<sup>rd</sup>. Releases on even-numbered years are LTS releases that will be supported for 5 years; releases on odd-numbered years are normal releases that will be supported for only 1.5 years. </p> <p>Updating ROS2 distributions can be pretty time-consuming, so to avoid frequent updates, we generally use only the LTS versions of ROS2. The LTS version released in 2024 was Jazzy Jalisco. As of this writing, we are using Jazzy. </p> <p></p> <p>Ubuntu LST releases are published every two years, and there are Ubuntu interim releases every six months. Ubuntu 24.04 LTS (April 2024) Noble Numbat is the current LTS version that we use. </p> <p>Different versions of ROS2 are designed to be compatible with specific versions of Ubuntu, so please check your Ubuntu version before downloading ROS2. Also, ROS2 doesn't always support other releases besides the LTS. To be safe, just stick with the LTS versions.</p>"},{"location":"ros2_tutorials/intro/#linux-mint-elementary-os-and-other-distros","title":"Linux Mint, Elementary OS, and other distros","text":"<p>There are several variants of Linux, all of which have their own pros and cons. Theoretically, since many of these distros are based on Debian (which is what Ubuntu is based on), and many of them are based directly on Ubuntu, they will be compatible with ROS2. If you're just getting started, you may want to avoid these distros for developing ROS2. You could encounter issues since not all Linux distros are created equal.</p>"},{"location":"ros2_tutorials/intro/#installing-linux-and-ros","title":"Installing Linux and ROS","text":"<p>Here are the links for installing Ubuntu and ROS2:</p> <ul> <li>Installing Ubuntu</li> <li>Installing ROS2 Jazzy</li> </ul>"},{"location":"ros2_tutorials/launch_files/","title":"Launch Files","text":"<p>Hopefully by this point you've realized that starting every node individually is not always the best option.  Doing so not only takes time, but it also results in a plethora of command terminals.  <code>ros2 launch</code> is a tool in ROS2 that allows you to start multiple nodes (which are defined in a launch file) with only one command.</p>"},{"location":"ros2_tutorials/launch_files/#prerequisites","title":"Prerequisites","text":"<p>In order to complete this tutorial we need a package to place our launch file. You should complete these two official tutorials first:</p> <p>Creating a workspace</p> <p>Creating a package</p> <p>If you're interested in learning more about the build tool, see \"A universal build tool\".</p>"},{"location":"ros2_tutorials/launch_files/#using-ros2-launch","title":"Using ros2 launch","text":"<p><code>ros2 launch</code> starts nodes as defined in a launch file.</p> <p>Usage: <pre><code> ros2 launch [package_name] [launchfile_name]\n</code></pre></p> <p>Example: <pre><code> ros2 launch turtlesim multisim.launch.py\n</code></pre> Notice that you've launched two <code>turtlesim</code> nodes with only one command. This command will run the following launch file: <pre><code># turtlesim/launch/multisim.launch.py\n\nfrom launch import LaunchDescription\nimport launch_ros.actions\n\ndef generate_launch_description():\n    return LaunchDescription([\n        launch_ros.actions.Node(\n            namespace= \"turtlesim1\", package='turtlesim', executable='turtlesim_node', output='screen'),\n        launch_ros.actions.Node(\n            namespace= \"turtlesim2\", package='turtlesim', executable='turtlesim_node', output='screen'),\n    ])\n</code></pre></p> <p>And then, in a new terminal, try:  <pre><code> ros2 topic pub  /turtlesim1/turtle1/cmd_vel geometry_msgs/msg/Twist \"{linear: {x: 2.0, y: 0.0, z: 0.0}, angular: {x: 0.0, y: 0.0, z: 1.8}}\"\n</code></pre></p> <p>And in a third terminal, try: <pre><code> ros2 topic pub  /turtlesim2/turtle1/cmd_vel geometry_msgs/msg/Twist \"{linear: {x: 2.0, y: 0.0, z: 0.0}, angular: {x: 0.0, y: 0.0, z: -1.8}}\"\n</code></pre></p> <p></p>"},{"location":"ros2_tutorials/launch_files/#creating-a-launch-file","title":"Creating a Launch File","text":"<p>First, go to <code>my_package</code> we created and built earlier. <pre><code> cd ~/ros2_ws/src/my_package\n</code></pre> <pre><code>Then let's make a launch directory:\n``` bash\n mkdir launch\n cd launch\n</code></pre></p> <p>NOTE: The directory to store launch files doesn't necessarily have to be named as \"launch\". In fact, you don't even need to store them in a directory. <code>ros2 launch</code> command automatically looks into the passed package and detects available launch files. However, it is good practice to do so.</p>"},{"location":"ros2_tutorials/launch_files/#the-launch-file","title":"The Launch File","text":"<p>Now let's create a launch file called \"turtlesim_mimic_launch.py\" (or \"turtlesim_mimic_launch.xml\"). After navigating to the launch directory (<code>cd launch</code>), you could create the file by entering <code>touch turtlesim_mimic_launch.py</code> (The 'touch' command is used to create a file). Then copy&amp;paste the following content into your file:</p> <p>(Python Version) <pre><code>from launch import LaunchDescription\nfrom launch_ros.actions import Node\n\ndef generate_launch_description():\n    return LaunchDescription([\n        Node(\n            package='turtlesim',\n            namespace='turtlesim1',\n            executable='turtlesim_node',\n            name='sim'\n        ),\n        Node(\n            package='turtlesim',\n            namespace='turtlesim2',\n            executable='turtlesim_node',\n            name='sim'\n        ),\n        Node(\n            package='turtlesim',\n            executable='mimic',\n            name='mimic',\n            remappings=[\n                ('/input/pose', '/turtlesim1/turtle1/pose'),\n                ('/output/cmd_vel', '/turtlesim2/turtle1/cmd_vel'),\n            ]\n        )\n    ])\n</code></pre></p> <p>(XML Version) <pre><code>&lt;launch&gt;\n  &lt;node pkg=\"turtlesim\" exec=\"turtlesim_node\" name=\"sim\" namespace=\"turtlesim1\"/&gt;\n  &lt;node pkg=\"turtlesim\" exec=\"turtlesim_node\" name=\"sim\" namespace=\"turtlesim2\"/&gt;```\n### Python Launch File\n\nThe **import** statements pull in necessary Python launch modules:\n``` python\nfrom launch import LaunchDescription\nfrom launch_ros.actions import Node\n</code></pre></p> <p>Here we start the launch description: <pre><code>def generate_launch_description():\n   return LaunchDescription([......])\n</code></pre></p> <p>Here we start two nodes with a namespace tag of <code>turtlesim1</code> and <code>turtlesim2</code> with a <code>turtlesim_node</code> named <code>sim</code>. Therefore, the first two actions are running two <code>turtlesim</code> node: <pre><code>Node(\n    package='turtlesim',\n    namespace='turtlesim1',\n    executable='turtlesim_node',\n    name='sim'\n),\nNode(\n    package='turtlesim',\n    namespace='turtlesim2',\n    executable='turtlesim_node',\n    name='sim'\n),\n</code></pre></p> <p>Here we start the mimic node with the topics input and output renamed to turtlesim1 and turtlesim2. This remap will make turtlesim2 mimic turtlesim1: <pre><code>Node(\n    package='turtlesim',\n    executable='mimic',\n    name='mimic',\n    remappings=[\n      ('/input/pose', '/turtlesim1/turtle1/pose'),\n      ('/output/cmd_vel', '/turtlesim2/turtle1/cmd_vel'),\n    ]\n)\n</code></pre></p>"},{"location":"ros2_tutorials/launch_files/#xml-launch-file","title":"XML Launch File","text":"<p>The first two actions are running two <code>turtlesim</code> nodes: <pre><code>&lt;node pkg=\"turtlesim\" exec=\"turtlesim_node\" name=\"sim\" namespace=\"turtlesim1\"/&gt;\n&lt;node pkg=\"turtlesim\" exec=\"turtlesim_node\" name=\"sim\" namespace=\"turtlesim2\"/&gt;\n</code></pre></p> <p>The next action is to remap and launch the mimic node: <pre><code>&lt;node pkg=\"turtlesim\" exec=\"mimic\" name=\"mimic\"&gt;\n  &lt;remap from=\"/input/pose\" to=\"/turtlesim1/turtle1/pose\"/&gt;\n  &lt;remap from=\"/output/cmd_vel\" to=\"/turtlesim2/turtle1/cmd_vel\"/&gt;\n&lt;/node&gt;\n</code></pre></p>"},{"location":"ros2_tutorials/launch_files/#launching","title":"Launching","text":"<p>Now let's go to the launch directory and <code>ros2 launch</code> the launch file you created: <pre><code> ros2 launch turtlesim_mimic_launch.py\n</code></pre> or <pre><code> ros2 launch turtlesim_mimic_launch.xml\n</code></pre></p> <p>With one command from the command line, we were able to start multiple nodes! This is obviously a cleaner and easier approach to start multiple nodes than starting them individually.</p> <p>Then, in a new terminal, enter: <pre><code> ros2 topic pub -r 1 /turtlesim1/turtle1/cmd_vel geometry_msgs/msg/Twist \"{linear: {x: 2.0, y: 0.0, z: 0.0}, angular: {x: 0.0, y: 0.0, z: -1.8}}\"\n</code></pre></p> <p>You'll see the two turtlesims start to move in the same way even though the publish command is only being sent to <code>turtlesim1</code>. </p> <p>NOTE: Don't worry too much about understanding the <code>ros2 topic pub</code> command yet. We will return to it in the next lesson. Basically, this usage of the command continuously publishes commands to <code>turtlesim</code> which tells the turtle to travel in a circle.</p> <p>We can also use <code>rqt</code> to better understand what our launch file did. Run: <pre><code> rqt\n</code></pre> </p>"},{"location":"ros2_tutorials/multiple_machines/","title":"ROS2 on Multiple Machines","text":"<p>Sometimes we want to run ROS2 on multiple computers when working with multiple robots, enabling more scalable, reliable, and capable robotic systems. In this tutorial, we're using a GIGABYTE BRIX (Mini-PC Barebone) as our example of the second machine, but the steps to run ROS2 on multiple machines should be the same.</p>"},{"location":"ros2_tutorials/multiple_machines/#prerequisite","title":"Prerequisite","text":"<ul> <li>You need to install ROS2 on the machines.</li> <li>You may need a router and some ethernet cables.</li> </ul>"},{"location":"ros2_tutorials/multiple_machines/#network-configuration","title":"Network configuration","text":"<p>At first, you need to make sure all your machines are under the same network. To do so, connect all the machines to one router. </p>"},{"location":"ros2_tutorials/multiple_machines/#connect-through-a-router","title":"Connect through a Router","text":"<p>This is the router we're using in the MAGICC lab: D-Link AC3200 ULTRA WIFI ROUTER (You may use a different router). </p> <p>For more information about connecting the router to one of your machines, See page 10-12 in the Dlink user manual.</p> <p></p> <p></p> <p>Wait for the router to boot up and both the Power LED and the Internet LED to turn white, turn on the machine and go to http://dlinkrouter.local/. You don't need to configure the router. Instead, you can directly log in with the admin password labeled on the router. You would see a webpage similar to this:</p> <p> </p> <p>And then, connect all the other machines to the Gigabit LAN ports of the router through ethernet cables. The \"Connected Clients\" on the right-upper of the website should show the number of machines connected.</p>"},{"location":"ros2_tutorials/multiple_machines/#running-ros2","title":"Running ROS2","text":""},{"location":"ros2_tutorials/multiple_machines/#addresses-of-the-hosts","title":"Addresses of the Hosts","text":"<p>Machine 1: Run: <pre><code>hostname -I\n</code></pre></p> <p>It should return the addresses of the host (192.168.0.XXX by default): <pre><code>192.168.0.219 \n</code></pre></p> <p>Machine 2: Run: <pre><code>hostname -I\n</code></pre></p> <p>It should return the address of the second host: <pre><code>192.168.0.145 \n</code></pre></p> <p>To check if the network connection works well, try: <pre><code>ping [address_of_the_other_hosts]\n</code></pre></p> <p>Example:</p> <p>Machine 1: <pre><code>ping 192.168.0.145\n</code></pre> <pre><code>PING 192.168.0.145 (192.168.0.145) 56(84) bytes of data.\n64 bytes from 192.168.0.145: icmp_seq=1 ttl=64 time=0.431 ms\n64 bytes from 192.168.0.145: icmp_seq=2 ttl=64 time=0.322 ms\n64 bytes from 192.168.0.145: icmp_seq=3 ttl=64 time=0.287 ms\n</code></pre></p> <p>Machine 2: <pre><code>ping 192.168.0.219\n</code></pre> <pre><code>PING 192.168.0.219 (192.168.0.1219) 56(84) bytes of data.\n64 bytes from 192.168.0.219: icmp_seq=1 ttl=64 time=0.779 ms\n64 bytes from 192.168.0.219: icmp_seq=2 ttl=64 time=0.552 ms\n64 bytes from 192.168.0.219: icmp_seq=3 ttl=64 time=0.545 ms\n</code></pre></p>"},{"location":"ros2_tutorials/multiple_machines/#running-a-talker-and-a-listener","title":"Running a Talker and a Listener","text":"<p>Let's test ROS2 by running a talker on one machine and a listener on the other.</p> <p>Machine 1: <pre><code>ros2 run demo_nodes_cpp talker\n</code></pre> <pre><code>[INFO] [1722972652.321040926] [talker]: Publishing: 'Hello World: 1'\n[INFO] [1722972653.321038414] [talker]: Publishing: 'Hello World: 2'\n[INFO] [1722972654.321045644] [talker]: Publishing: 'Hello World: 3'\n[INFO] [1722972655.321057633] [talker]: Publishing: 'Hello World: 4'\n[INFO] [1722972656.321018001] [talker]: Publishing: 'Hello World: 5'\n</code></pre></p> <p>Machine 2: <pre><code>ros2 run demo_nodes_cpp listener\n</code></pre> <pre><code>[INFO] [1722970595.418757978] [listener]: I heard: [Hello World: 1]\n[INFO] [1722970596.418662019] [listener]: I heard: [Hello World: 2]\n[INFO] [1722970597.418683848] [listener]: I heard: [Hello World: 3]\n[INFO] [1722970598.418696562] [listener]: I heard: [Hello World: 4]\n[INFO] [1722970599.418693184] [listener]: I heard: [Hello World: 5]\n</code></pre></p> <p>Your listener on Machine 1 should be able to listen to the talker on Machine 2.</p>"},{"location":"ros2_tutorials/multiple_machines/#use-of-ros_domain_id","title":"Use of ROS_DOMAIN_ID","text":"<p>For more information about ROS_DOMAIN_ID, see \"3.1 The ROS_DOMAIN_ID variable\" of the offical tutorial \"Configuring environment\" and the documentation \"The ROS_DOMAIN_ID\".</p> <p>When you want to run different ROS2 applications, you can use ROS_DOMAIN_ID to isolate ROS2 environments in the same network. Only machines with the same ROS_DOMAIN_ID can communicate with each other.</p> <p>Usage: <pre><code>export ROS_DOMAIN_ID=[your_domain_id]\n</code></pre></p> <p>Example:</p> <p>Machine 1: <pre><code>export ROS_DOMAIN_ID=2\n</code></pre></p> <p>At this moment, if you run a talker on Machine 1 and a listener on Machine 2, the listener cannot receive the messages from the talker.</p> <p>Machine 2: <pre><code>export ROS_DOMAIN_ID=2\n</code></pre></p> <p>Now, the talker and the listener should be able to communicate with each other again.</p>"},{"location":"ros2_tutorials/node_info/","title":"Getting Info About Nodes","text":""},{"location":"ros2_tutorials/node_info/#ros2-topics","title":"ROS2 Topics","text":"<p>\u201cROS 2 breaks complex systems down into many modular nodes. Topics are a vital element of the ROS graph that act as a bus for nodes to exchange messages.\u201d In order to communicate, ROS2 nodes publish and/or subscribe to ROS2 topics. </p> <p></p> <p>Picture link</p> <p>Nodes can also send messages through services and actions. If you\u2019re interested, you could look at the official documentations:</p> <p>ROS2 Services </p> <p>ROS2 Actions</p>"},{"location":"ros2_tutorials/node_info/#setup","title":"Setup","text":""},{"location":"ros2_tutorials/node_info/#turtlesim","title":"turtlesim","text":"<p>In a new terminal, run: <pre><code> ros2 run turtlesim turtlesim_node\n</code></pre></p>"},{"location":"ros2_tutorials/node_info/#turtle-keyboard-teleoperation","title":"turtle keyboard teleoperation","text":"<p>We'll also need something to drive the turtle around with. Let's see what other nodes are in the turtlesim package. Open a new terminal and type: <pre><code> ros2 run turtlesim&lt;now press TAB twice&gt;\n</code></pre></p> <p>The following should appear: <pre><code> draw_square        mimic        turtlesim_node        turtle_teleop_key\n</code></pre></p> <p>These are the four nodes in the <code>turtlesim</code> package.  Each node is an individual executable, or program, but all are organized into a single package.  Let's try the executable <code>turtle_teleop_key</code>. Enter: <pre><code> ros2 run turtlesim turtle_teleop_key\n</code></pre></p> <pre><code>Reading from keyboard\n---------------------------\nUse arrow keys to move the turtle.\nUse g|b|v|c|d|e|r|t keys to rotate to absolute orientations. 'f' to cancel a rotation.\n'q' to quit.\n</code></pre> <p>Now you can use the arrow keys(\u2190\u2191\u2193\u2192) of your keyboard to drive the turtle around. Remember to select the terminal window of the turtle_teleop_key first to make sure that the keys you type are recorded. </p> <p>In this case, the <code>turtlesim</code> node and the <code>teleop_turtle</code> node are communicating with each other over the ROS2 topic <code>command_velocity</code>: The <code>teleop_key</code> publishes keystrokes to the ROS2 topic <code>/turtle1/cmd_vel</code>, and the <code>turtlesim</code> node subscribes to the same topic <code>/turtle1/cmd_vel</code> to receive the keystroke messages.  </p>"},{"location":"ros2_tutorials/node_info/#rqt_graph","title":"rqt_graph","text":"<p>Using the rqt_graph tool we visualize the node interactions.</p> <p>Unless you already have <code>rqt</code> installed, run: <pre><code> sudo apt update\n sudo apt install ~nros-jazzy-rqt*\n</code></pre></p> <p>In a new terminal, run: <pre><code> rqt\n</code></pre></p> <p>You will see a blank window but no worries. We need to select the rqt plugin we want to use. From the Plugins menu, select Introspection and then Node Graph. Now you should be able to see a graph of the relationship between topics and nodes. </p> <p></p> <p>If you place your mouse over /turtle1/cmd_vel, it will highlight the nodes (blue and green here) and topics (red here). As stated before, the <code>teleop_turtle</code> node and the <code>turtlesim</code> node are communicating on the topic named <code>/turtle1/cmd_vel</code>. </p>"},{"location":"ros2_tutorials/node_info/#ros2-node","title":"ros2 node","text":"<p><code>ros2 node</code> is a useful tool for finding information about nodes.</p>"},{"location":"ros2_tutorials/node_info/#ros2-node-list","title":"ros2 node list","text":"<p><code>ros2 node list</code> returns a list of all currently running nodes. This will become a more and more useful tool as you run more and more nodes.</p> <p>In a new terminal run: <pre><code> ros2 node list\n</code></pre></p> <p>Assuming you still have the <code>turtlesim</code> and <code>teleop_turtle</code> nodes running, you should see: <pre><code> /teleop_turtle\n /turtlesim\n</code></pre></p>"},{"location":"ros2_tutorials/node_info/#ros2-node-info","title":"ros2 node info","text":"<p><code>ros2 node info</code> returns information about a specified node. </p> <p>Example: <pre><code> ros2 node info /turtlesim\n</code></pre></p> <p>(Don't forget the forward slash \"<code>/</code>\" here.)</p> <p>You should see something similar to: <pre><code>/turtlesim\n  Subscribers:\n    /parameter_events: rcl_interfaces/msg/ParameterEvent\n    /turtle1/cmd_vel: geometry_msgs/msg/Twist\n  Publishers:\n    /parameter_events: rcl_interfaces/msg/ParameterEvent\n    /rosout: rcl_interfaces/msg/Log\n    /turtle1/color_sensor: turtlesim/msg/Color\n    /turtle1/pose: turtlesim/msg/Pose\n  Service Servers:\n    /clear: std_srvs/srv/Empty\n    /kill: turtlesim/srv/Kill\n    /reset: std_srvs/srv/Empty\n    /spawn: turtlesim/srv/Spawn\n    /turtle1/set_pen: turtlesim/srv/SetPen\n    /turtle1/teleport_absolute: turtlesim/srv/TeleportAbsolute\n    /turtle1/teleport_relative: turtlesim/srv/TeleportRelative\n    /turtlesim/describe_parameters: rcl_interfaces/srv/DescribeParameters```_atomically: rcl_interfaces/srv/SetParametersAtomically\n  Service Clients:\n\n  Action Servers:\n    /turtle1/rotate_absolute: turtlesim/action/RotateAbsolute\n  Action Clients:\n</code></pre></p> <p>Note that <code>ros2 node info</code> allows us to see publications, subscriptions as well as services and actions associated with a certain node.</p>"},{"location":"ros2_tutorials/node_info/#review","title":"Review","text":"<ul> <li>ROS2 topics: named buses over which nodes exchange messages</li> <li>rqt_graph: a tool for visualizing interactions among nodes</li> <li><code>ros2 node</code>: a tool to get information about a node<ul> <li><code>ros2 node info</code>: output information about a node</li> <li><code>ros2 node list</code>: output a list of available nodes</li> </ul> </li> </ul>"},{"location":"ros2_tutorials/others/","title":"Others","text":""},{"location":"ros2_tutorials/others/#ros2-bag","title":"ros2 bag","text":"<p><code>ros2 bag</code> is a command line tool that should already be included in your ROS2 setup. You can use it to record the data passed on topics and replay the data later on.</p> <p>Recording and playing back data</p>"},{"location":"ros2_tutorials/others/#from-ros1-to-ros2","title":"From ROS1 to ROS2","text":"<p>Migrating from ROS 1 to ROS 2</p>"},{"location":"ros2_tutorials/others/#ros2-cheat-sheet","title":"ROS2 Cheat Sheet","text":"<p>A collection of ROS2-related cheats sheet</p>"},{"location":"ros2_tutorials/others/#node-communication","title":"Node Communication","text":"<p>Each node can send and receive data from other nodes via topics, services, actions, or parameters.</p> <p>ROS2 Services</p> <p>Writing a simple service and client (C++)</p> <p>Writing a simple service and client (Python)</p> <p>ROS2 Parameters</p> <p>Using parameters in a class (C++)</p> <p>Using parameters in a class (Python)</p> <p>ROS2 Actions</p> <p>Writing an action server and client (C++)</p> <p>Writing an action server and client (Python)</p>"},{"location":"ros2_tutorials/others/#parameter-descriptor-slider","title":"Parameter Descriptor &amp; Slider","text":"<p>If you're interested in how to describe a parameter, control a parameter with a slider, set limits for a parameter, see \"rcl_interfaces\".</p>"},{"location":"ros2_tutorials/packages/","title":"Packages","text":""},{"location":"ros2_tutorials/packages/#packages_1","title":"Packages","text":"<p>When you create a node you need a package to put the node in. Multiple nodes can be put into one package. You already know this because you've typed the following commands: <pre><code> ros2 run [package_name] [node_name]\n ros2 run turtlesim turtlesim_node\n ros2 run turtlesim turtle_teleop_key\n</code></pre></p> <p>Both the <code>turtlesim</code> and <code>teleop_turtle</code> nodes are in the <code>turtlesim</code> package.</p> <p>The following command will create a package, and should be called when within the src folder of your workspace (/ros2_ws/src):</p> <pre><code> ros2 pkg create [package_name] --build-type [build_type]  --dependencies [dependecy 1] [dependency 2] [dependency...]\n</code></pre> <p>There are three build types: <code>cmake</code>, <code>ament_cmake</code>, and <code>ament_python</code>. If you don't assign one, <code>ament_cmake</code> will be chosen by default.</p> <p>There could be several depend arguments. They might be as follows: \"std_msgs\", \"rclpy\", or \"rclcpp\". </p> <p>Once you are done creating a package, you can build the package by this command : <pre><code> colcon build\n</code></pre></p> <p>When you call this command, make sure you are within the root folder of your workspace (/ros2_ws) instead of any other folders in the workspace, such as the src folder. Calling this command will build all the packages in the workspace, not just the ones most recently created.</p> <p>If you want to build only one package, try: <pre><code> colcon build --packages-select [package_name]\n</code></pre></p> <p>As previously mentioned, when you are writing your code, you will need to build the package before any saved changes can take effect. </p>"},{"location":"ros2_tutorials/packages/#c-packages","title":"C++ Packages","text":"<p>Example:  <pre><code> ros2 pkg create example_cpp --build-type ament_cmake --dependencies rclcpp\n</code></pre></p> <p>A package should have 4 essential items within: <code>CMakeLists.txt</code>, <code>package.xml</code>, an <code>include</code> folder, and a <code>src</code> folder. Without them, the package would just be a regular folder. <pre><code>CMakeLists.txt file that describes how to build the code within the package\n\ninclude/&lt;package_name&gt; directory containing the public headers for the package\n\npackage.xml file containing meta information about the package\n\nsrc directory containing the source code for the package\n</code></pre></p>"},{"location":"ros2_tutorials/packages/#cmakeliststxt","title":"CMakeLists.txt","text":"<p>Below is a simple example of a CmakeLists.txt. <pre><code>cmake_minimum_required(VERSION 3.8)\nproject(example_cpp)\n\nif(CMAKE_COMPILER_IS_GNUCXX OR CMAKE_CXX_COMPILER_ID MATCHES \"Clang\")\n  add_compile_options(-Wall -Wextra -Wpedantic)\nendif()\n\n# find dependencies\nfind_package(ament_cmake REQUIRED)\nfind_package(rclcpp REQUIRED)\n\nif(BUILD_TESTING)\n  find_package(ament_lint_auto REQUIRED)\n  # the following line skips the linter which checks for copyrights\n  # comment the line when a copyright and license is added to all source files\n  set(ament_cmake_copyright_FOUND TRUE)\n  # the following line skips cpplint (only works in a git repo)\n  # comment the line when this package is in a git repo and when\n  # a copyright and license is added to all source files\n  set(ament_cmake_cpplint_FOUND TRUE)\n  ament_lint_auto_find_test_dependencies()\nendif()\n\nament_package()\n</code></pre></p> <p>The CMakeLists.txt that was auto-created when you called <code>ros2 pkg create</code> is basically the same thing as the above with a lot more unnecessary code that has been commented out. The following line is the most important and what you will need to change in order for your node to function.</p> <pre><code>add_executable(example_node src/example_node.cpp src/example.cpp)\n</code></pre> <p>The above line adds the <code>example_node.cpp</code> and <code>example.cpp</code> files, which you will create and add to the executables, so that they can be run. Both of the <code>.cpp</code> files will be placed in the src folder.</p>"},{"location":"ros2_tutorials/packages/#src-folder","title":"src Folder","text":"<p>The source folder contains two <code>.cpp</code> files which hold the commands for the node. Nodes are often written using classes in c++. Conventionally, the <code>example_node.cpp</code> will hold the <code>int main()</code> function and the <code>example.cpp</code> will hold the class and function declarations. For creating a publisher and a subscriber, here is also where the publisher.cpp and subscriber.cpp should be.</p>"},{"location":"ros2_tutorials/packages/#include-folder","title":"include Folder","text":"<p>The include folder will contain the <code>.hpp</code> files.</p>"},{"location":"ros2_tutorials/packages/#packagexml-file","title":"package.xml file","text":"<p>The package.xml file containing meta information about the package</p>"},{"location":"ros2_tutorials/packages/#python-packages","title":"Python Packages","text":"<p>Example: <pre><code> ros2 pkg create example_py  --build-type ament_python --dependencies rclpy\n</code></pre></p>"},{"location":"ros2_tutorials/packages/#packagexml-file_1","title":"package.xml file","text":"<p>The package.xml file contains meta information about the package.</p>"},{"location":"ros2_tutorials/packages/#resource","title":"resource/ <p>resource/ is the marker file for the package","text":""},{"location":"ros2_tutorials/packages/#setupcfg","title":"setup.cfg <p>setup.cfg is required when a package has executables, so <code>ros2 run</code> can find them.</p>","text":""},{"location":"ros2_tutorials/packages/#setuppy","title":"setup.py <p>setup.py contains instructions for how to install the package.</p> <p>Example: <pre><code>from setuptools import find_packages, setup\n\npackage_name = 'example_py'\n\nsetup(\n    name=package_name,\n    version='0.0.0',\n    packages=find_packages(exclude=['test']),\n    data_files=[\n        ('share/ament_index/resource_index/packages',\n            ['resource/' + package_name]),\n        ('share/' + package_name, ['package.xml']),\n    ],\n    install_requires=['setuptools'],\n    zip_safe=True,\n    maintainer='maintainer_name',\n    maintainer_email='maintainer_email@todo.todo',\n    description='TODO: Package description',\n    license='TODO: License declaration',\n    tests_require=['pytest'],\n    entry_points={\n        'console_scripts': [\n        ],\n    },\n)\n</code></pre></p>","text":""},{"location":"ros2_tutorials/packages/#my_package-folder","title":"my_package Folder <p>package_name - a directory with the same name as your package, used by ROS 2 tools to find your package containing init.py.</p> <p>For creating a publisher and a subscriber, this folder is also where the publisher.cpp and subscriber.cpp should be.</p>","text":""},{"location":"ros2_tutorials/parameters/","title":"ROS2 Parameters","text":""},{"location":"ros2_tutorials/parameters/#joy","title":"Joy","text":""},{"location":"ros2_tutorials/parameters/#continually-publishing-messages-on-joy","title":"Continually Publishing Messages on Joy","text":"<p>Start by replicating the same scenario we had in the previous tutorial: </p> <p>Now try getting the turtle to go continually in any direction.  You'll notice that the turtle stops after a certain distance.</p> <p>Display the output of the <code>joy</code> node: <pre><code> ros2 topic echo joy\n</code></pre></p> <p>Now move the joystick, the output should be similar to the following: <pre><code> ---\n header:\n   seq: 3\n   stamp:\n     secs: 1439228031\n     nsecs: 139606633\n   frame_id: ''\n axes: [0.13516968488693237, 0.0, 0.0, 0.0, 0.0, 0.0]\n buttons: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n ---\n header:\n   seq: 4\n   stamp:\n     secs: 1439228031\n     nsecs: 248627279\n   frame_id: ''\n axes: [0.14702372252941132, 0.0, 0.0, 0.0, 0.0, 0.0]\n buttons: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n ---\n</code></pre></p> <p>Note that <code>joy</code> stops publishing when you stop moving the joystick.  The result is that holding the joystick fixed in any position will cause our turtle to stop moving. Suppose we wanted to keep publishing at these moments. Fortunately those who created the joy package built in that capability. Try: <pre><code> ros2 run joy joy_node _autorepeat_rate:=10\n</code></pre></p> <p><code>joy</code> should now be continually publishing messages at a rate of 10 Hz when no new messages are received.</p>"},{"location":"ros2_tutorials/parameters/#joy-parameters","title":"Joy Parameters","text":"<p>Take a look at the Joy Documentation.</p> <p></p> <p>By building these parameters into the code, joy can be customized to fit many different situations without requiring a change in the code each time.</p> <p>Parameters can be changed either by passing them in as we did with \"ros2 run joy joy_node _autorepeat_rate:=10\" on the parameter autorepeat_rate (note the underscore preceding the parameter) or by changing the parameters value on the ROS2 Parameter Server using <code>ros2 param</code>.</p> <p>## Using ros2 param</p> <p><code>ros2 param</code> allows you to store and manipulate data on the ROS2 Parameter Server. The Parameter Server can store integers, floats, boolean, dictionaries, and lists. <code>ros2 param</code> uses the YAML markup language for syntax. In simple cases, YAML looks very natural: 1 is an integer, 1.0 is a float, one is a string, true is a boolean, [1, 2, 3] is a list of integers, and {a: b, c: d} is a dictionary. <code>ros2 param</code> has many commands that can be used on parameters, as shown below: <pre><code>Commands:\n  delete    Delete parameter\n  describe  Show descriptive information about declared parameters\n  dump      Show all of the parameters of a node in a YAML file format\n  get       Get parameter\n  list      Output a list of available parameters\n  load      Load parameter file for a node\n  set       Set parameter\n</code></pre></p>"},{"location":"ros2_tutorials/parameters/#ros2-param-list","title":"ros2 param list","text":"<p>Let's look at what parameters are currently on the param server: <pre><code> ros2 param list\n</code></pre></p> <p>The <code>turtlesim</code> node has three parameters on the param server for background color.  You can also see that <code>joy</code>'s autorepeat_rate parameter is on the parameter server: <pre><code>/joy_node:\n  autorepeat_rate\n  ......\n</code></pre> <pre><code>/teleop_twist_joy_node:\n  ......\n</code></pre> <pre><code>/turtlesim:\n  background_b\n  background_g\n  background_r\n  ......\n</code></pre></p>"},{"location":"ros2_tutorials/parameters/#ros2-param-get","title":"ros2 param get","text":"<p>We can retrieve the current value of parameters on the parameter server by using <code>ros2 param get</code>:</p> <p>Usage: <pre><code> ros2 param get [node_name] [parameter_name]\n</code></pre></p> <p>Let's try this command with \"background_r\": <pre><code> ros2 param get /turtlesim background_r\n</code></pre> <pre><code>Integer value is: 69\n</code></pre></p>"},{"location":"ros2_tutorials/parameters/#ros2-param-set","title":"ros2 param set","text":"<p>Let's now use <code>ros2 param set</code>:</p> <p>Usage: <pre><code> ros2 param set [node_name] [parameter_name] [value]\n</code></pre></p> <p>Let's change the \"background_r\" parameter to a higher value: <pre><code> ros2 param set /turtlesim background_r 200\n</code></pre> <pre><code>Set parameter successful\n</code></pre></p> <p>The command should change the background color of the turtlesim. </p>"},{"location":"ros2_tutorials/parameters/#ros2-param-dump","title":"ros2 param dump","text":"<p>Setting parameters with the set command will NOT change parameters permanently. However, you can save your settings and reload them for the next time. If you wish to store all current parameter values in a file you can use <code>ros2 param dump</code>.</p> <p>Usage: <pre><code> ros2 param dump [node_name] &gt; [filename.yaml]\n</code></pre></p> <p>Example: <pre><code> ros2 param dump /turtlesim &gt; turtlesim.yaml\n</code></pre></p> <p>The \"turtlesim.yaml\" file gets saved in your current working directory. Open the file, and you'll see:  </p>"},{"location":"ros2_tutorials/parameters/#ros2-param-load","title":"ros2 param load","text":"<p>To load parameter values from a file simply use <code>ros2 param load</code>.</p> <p>Usage: <pre><code> ros2 param load [node_name] [filename.yaml]\n</code></pre></p> <p>Example: <pre><code> ros2 param load /turtlesim turtlesim.yaml\n</code></pre></p> <p>You can also load yaml files on node startup: <pre><code> ros2 run [package_name] [node_name] --ros-args --params-file [filename.yaml]\n</code></pre></p> <p>Example: <pre><code> ros2 run turtlesim turtlesim_node --ros-args --params-file turtlesim.yaml\n</code></pre></p> <p>The background of the turtlesim should turn purple again.</p>"},{"location":"ros2_tutorials/parameters/#review","title":"Review","text":"<ul> <li>ROS2 packages: a configuration value of a node</li> <li><code>ros2 param</code>: a tool to interface with parameters<ul> <li><code>ros2 param list</code>: output a list of available parameters</li> <li><code>ros2 param get</code>: get parameter    </li> <li><code>ros2 param set</code>: set parameter</li> <li><code>ros2 param dump</code>: show all of the parameters of a node in a YAML file format    </li> <li><code>ros2 param load</code>: load parameter file for a node</li> </ul> </li> </ul>"},{"location":"ros2_tutorials/python_node_class/","title":"Nodes Based On Classes (Python)","text":""},{"location":"ros2_tutorials/python_node_class/#using-python","title":"Using Python","text":"<p>Python is an awesome language for quickly prototyping.  C++ is way faster than python, but in my experience, I can throw together a python node in about half the time it would take for me to put a C++ node together.  Debugging python is also a lot easier and faster, if only because you don't have to compile between code changes and you have a terminal to try code during a breakpoint.  Often, I'll create a prototype in python, and once it's working, I'll convert it to C++ to get a massive speedup.  I find that this workflow is typically more efficient than trying to do my debugging in C++.</p> <p>You don't have to just use Python.  There are some awesome libraries that allow you to merge C++ and python into a single node.  This is a more advanced topic, and will probably be covered in later tutorials.  Obviously, you can have both python and C++ in the same package.</p>"},{"location":"ros2_tutorials/python_node_class/#ros2-package-organization","title":"ROS2 Package organization","text":"<p>Because python doesn't actually have to be compiled, you don't technically need a <code>CMakeLists.txt</code>.  You do need a <code>package.xml</code>, though, so <code>ros2 pkg</code> can recognize your package for what it is.  If you want to install your python node, then you will need to use the CMakeLists.txt, so that colcon can move your python files to the install directories.</p>"},{"location":"ros2_tutorials/python_node_class/#classes","title":"Classes","text":"<p>In short, we use classes because they are convenient. They may not seem so convenient at first, but being able to split up your code into different files makes it a lot easier, and classes make it easy to store variables in between function calls, and limit the scope of functions. You could just program every node in one giant main script, but that eventually becomes unreasonable.</p> <p>In the MAGICC lab, we generally organize our nodes as follows:</p> <p></p> <p>The  <code>__init__.py</code> file (which is empty) tells python that your node is a python module.  This is also the reason for putting our scripts in a subfolder of the src folder named the same as our package.  Python is pretty flexible, and you can actually put your files wherever you want, but the above structure is the officially recommended organization.</p>"},{"location":"ros2_tutorials/python_node_class/#example-moving-sensor-package","title":"Example: Moving Sensor Package","text":"<p>The file structure appears as follows:</p> <pre><code>moving_sensor\n\u251c\u2500\u2500 package.xml\n\u251c\u2500\u2500 setup.py\n\u251c\u2500\u2500 setup.cfg\n\u251c\u2500\u2500 resource\n\u2502   \u251c\u2500\u2500 moving_sensor\n\u251c\u2500\u2500 (test)\n\u251c\u2500\u2500 moving_sensor\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 moving_sensor.py\n</code></pre>"},{"location":"ros2_tutorials/python_node_class/#moving_sensorpy","title":"moving_sensor.py","text":"<pre><code>#!/usr/bin/env python3\n\nimport rclpy\nfrom rclpy.node import Node\nfrom turtlesim.msg import Pose\nfrom bool_interfaces.msg import Bool\n\nclass MovingSensor(Node):\n    def __init__(self):\n        super().__init__('moving_sensor')\n\n        self.pose_subscriber = self.create_subscription(\n            Pose,\n            'pose',\n            self.pose_callback,\n            1\n        )\n\n        self.is_moving_publisher = self.create_publisher(\n            Bool,\n            'is_moving',\n            1\n        )\n\n        self.declare_parameter('threshold', 0.0)\n        self.threshold = self.get_parameter('threshold').get_parameter_value().double_value\n\n    def pose_callback(self, msg):\n        out_msg = Bool()\n        if msg.linear_velocity &gt; self.threshold:\n            out_msg.data = True\n        else:\n            out_msg.data = False\n\n        self.is_moving_publisher.publish(out_msg)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = MovingSensor()\n\n    rclpy.spin(node)\n\n    node.destroy_node()\n    rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n</code></pre>"},{"location":"ros2_tutorials/rostopic/","title":"ROS2 Topics","text":""},{"location":"ros2_tutorials/rostopic/#prerequisites","title":"Prerequisites","text":"<p>Start <code>turtlesim</code>, <code>teleop_turtle</code>, and <code>rqt</code>.</p>"},{"location":"ros2_tutorials/rostopic/#introducing-ros2-topic","title":"Introducing ros2 topic","text":"<p>The <code>ros2 topic</code> tool allows you to get information about ROS2 topics.</p> <p>You can use the help option to get the available sub-commands for <code>ros2 topic</code> <pre><code> ros2 topic -h\n</code></pre></p> <pre><code>......\n\nCommands:\n  bw     Display bandwidth used by topic\n  delay  Display delay of topic from timestamp in header\n  echo   Output messages from a topic\n  find   Output a list of available topics of a given type\n  hz     Print the average publishing rate to screen\n  info   Print information about a topic\n  list   Output a list of available topics\n  pub    Publish a message to a topic\n  type   Print a topic's type\n\n......\n</code></pre> <p>Let's use some of these sub-commands to examine turtlesim.</p>"},{"location":"ros2_tutorials/rostopic/#ros2-topic-list","title":"ros2 topic list","text":"<p><code>ros2 topic list</code> returns a list of available topics currently subscribed to and published.</p> <p>Example: <pre><code> ros2 topic list\n</code></pre> <pre><code>/parameter_events\n/rosout\n/turtle1/cmd_vel\n/turtle1/color_sensor\n/turtle1/pose\n</code></pre></p> <p>Let's get into some topic list sub-command arguments. Run: <pre><code> ros2 topic list -h\n</code></pre> <pre><code>usage: ros2 topic list [-h] [--spin-time SPIN_TIME] [-s] [--no-daemon] [-t]\n                       [-c] [--include-hidden-topics] [-v]\n\nOutput a list of available topics\n\noptions:\n  -h, --help            show this help message and exit\n  --spin-time SPIN_TIME\n                        Spin time in seconds to wait for discovery (only\n                        applies when not using an already running daemon)\n  -s, --use-sim-time    Enable ROS simulation time\n  --no-daemon           Do not spawn nor use an already running daemon\n  -t, --show-types      Additionally show the topic type\n  -c, --count-topics    Only display the number of topics discovered\n  --include-hidden-topics\n                        Consider hidden topics as well\n  -v, --verbose         List full details about each topic\n</code></pre></p> <p>With the <code>-t</code> (show-types) option: <pre><code> ros2 topic list -t\n</code></pre></p> <p>This gives the same list but with the topic type appended in brackets: <pre><code>/parameter_events [rcl_interfaces/msg/ParameterEvent]\n/rosout [rcl_interfaces/msg/Log]\n/turtle1/cmd_vel [geometry_msgs/msg/Twist]\n/turtle1/color_sensor [turtlesim/msg/Color]\n/turtle1/pose [turtlesim/msg/Pose]\n</code></pre></p> <p>With the <code>-v</code> (verbose) option: <pre><code> ros2 topic list -v\n</code></pre></p> <p>This displays a verbose list of topics with message type and publisher/subscriber information. <pre><code>Published topics:\n * /parameter_events [rcl_interfaces/msg/ParameterEvent] 3 publishers\n * /rosout [rcl_interfaces/msg/Log] 3 publishers\n * /turtle1/cmd_vel [geometry_msgs/msg/Twist] 1 publisher\n * /turtle1/color_sensor [turtlesim/msg/Color] 1 publisher\n * /turtle1/pose [turtlesim/msg/Pose] 1 publisher\n\nSubscribed topics:\n * /parameter_events [rcl_interfaces/msg/ParameterEvent] 3 subscribers\n * /turtle1/cmd_vel [geometry_msgs/msg/Twist] 1 subscriber\n</code></pre></p> <p>Feel free to try some of the other options.</p>"},{"location":"ros2_tutorials/rostopic/#ros2-topic-type","title":"ros2 topic type","text":"<p>Communication on topics happens by sending ROS2 messages between nodes. For a publisher to talk to a subscriber, such as the publisher <code>teleop_turtle</code> and the subscriber <code>turtlesim</code>, the publisher and subscriber must send and receive the same type of the message. The type of the message on a topic can be determined by using <code>ros2 topic type</code> which returns the message type of any topic being published.</p> <p>Usage: <pre><code> ros2 topic type [topic_name]\n</code></pre></p> <p>Example: <pre><code> ros2 topic type /turtle1/cmd_vel\n</code></pre> You should get: <pre><code>geometry_msgs/msg/Twist\n</code></pre></p> <p>We can look at the details of a message using <code>ros2 interface show</code>: <pre><code> ros2 interface show geometry_msgs/msg/Twist\n</code></pre></p> <pre><code># This expresses velocity in free space broken into its linear and angular parts.\n\nVector3  linear\n    float64 x\n    float64 y\n    float64 z\nVector3  angular\n    float64 x\n    float64 y\n    float64 z\n</code></pre> <p>You may also choose to look up certain type of message of its details. From this documentation \"geometry_msgs/msg/Twist Message\", you can learn that this message contains two 3D vectors of translational and rotational velocity.</p>"},{"location":"ros2_tutorials/rostopic/#ros2-topic-echo","title":"ros2 topic echo","text":"<p><code>ros2 topic echo</code> shows the data published on a topic.</p> <p>Usage: <pre><code> ros2 topic echo [topic_name]\n</code></pre></p> <p>Let's look at the command velocity data published by the <code>teleop_turtle</code> node, which is published on the <code>/turtle1/cmd_vel</code> topic.  <pre><code> ros2 topic echo /turtle1/cmd_vel\n</code></pre></p> <p><pre><code>WARNING: topic [/turtle1/cmd_vel] does not appear to be published yet\nCould not determine the type for the passed topic\n</code></pre> You'll probably receive a warning because no data is currently being published on this topic. Let's make <code>teleop_turtle</code> publish data by pressing our arrow keys. If the turtle isn't moving, you might need to select the <code>teleop_turtle</code> terminal.</p> <p>You should now see the following when you press up and then left: <pre><code>linear:\nlinear:\n  x: 2.0\n  y: 0.0\n  z: 0.0\nangular:\n  x: 0.0\n  y: 0.0\n  z: 0.0\n---\nlinear:\n  x: 0.0\n  y: 0.0\n  z: 0.0\nangular:\n  x: 0.0\n  y: 0.0\n  z: -2.0\n---\n</code></pre></p> <p>Those are the 3D vectors we saw in the message information.  If you'll notice, when you turn, the angular.z changes, and when you move forward and backward, the linear.x changes.</p> <p>So, what if we wanted to control the turtle with something other than the <code>teleop_turtle</code> node?  All we would need to do is to publish geometry_msgs/msg/Twist on the <code>/turtle1/cmd_vel</code> topic.  The turtle will turn if we publish messages to the angular.z, and it will move when we publish messages to the linear.x.</p> <p>Now let's look at <code>rqt</code>. Press the refresh button in the upper-right corner and uncheck the \"Debug\" box.</p> <p></p> <p>The <code>/_ros2cli_26821</code> node is created by the echo command. As you can see, it is now subscribed to the <code>/turtle1/cmd_vel</code> topic.</p>"},{"location":"ros2_tutorials/rostopic/#ros2-topic-pub","title":"ros2 topic pub","text":"<p><code>ros2 topic pub</code> publishes data on to a topic currently advertiseda message to a topic.</p> <p>Usage: <pre><code> ros2 topic pub [topic_name] [msg_type] '&lt;args&gt;'\n</code></pre></p> <p>The '' argument is the actual data you\u2019ll pass to the topic.  <p>Example: <pre><code> ros2 topic pub --once /turtle1/cmd_vel geometry_msgs/msg/Twist \"{linear: {x: 4.0, y: 0.0, z: 0.0}, angular: {x: 0.0, y: 0.0, z: 2.0}}\"\n</code></pre></p> <p>The optional argument \"--once\" means \u201cpublish one message then exit\u201d. This whole command sends a single message to turtlesim telling it to move with a linear velocity of 4.0 and an angular velocity of 2.0.</p> <p></p> <p>The output in the terminal: <pre><code>publisher: beginning loop\npublishing #1: geometry_msgs.msg.Twist(linear=geometry_msgs.msg.Vector3(x=4.0, y=0.0, z=0.0), angular=geometry_msgs.msg.Vector3(x=0.0, y=0.0, z=2.0))\n</code></pre></p> <p>Another example is: <pre><code> ros2 topic pub --rate 1 /turtle1/cmd_vel geometry_msgs/msg/Twist \"{linear: {x: 2.0, y: 0.0, z: 0.0}, angular: {x: 0.0, y: 0.0, z: 1.8}}\"\n</code></pre></p> <p>Instead of the <code>--once</code> option, we use the <code>--rate 1</code> option here to keep publishing the command in a steady stream at 1 HZ. As you can see the turtle is running in a continuous circle.</p> <p></p> <p>This is a pretty complicated example, so let's look at each argument in detail. * This command will publish messages to a given topic:   <pre><code>ros2 topic pub\n</code></pre></p> <ul> <li> <p>This option causes rostopic to publish messages at a steady stream of 1 Hz:   <pre><code>--rate 1\n</code></pre></p> </li> <li> <p>This is the name of the topic to publish to:   <pre><code>/turtle1/cmd_vel\n</code></pre></p> </li> <li> <p>This is the message type to use when publishing the topic:   <pre><code>geometry_msgs/msg/Twist\n</code></pre></p> </li> <li> <p>As noted before, a \"geometry_msgs/msg/Twist\" message has two vectors, and each of the two vectors has three floating point elements:   <pre><code>{linear: {x: 2.0, y: 0.0, z: 0.0}, angular: {x: 0.0, y: 0.0, z: 1.8}}\n</code></pre></p> </li> </ul> <p><code>{x: 2.0, y: 0.0, z: 0.0}</code> is the linear value with <code>x=2.0</code>, <code>y=0.0</code>, and <code>z=0.0</code>, and <code>{x: 0.0, y: 0.0, z: 1.8}</code> is the angular value with <code>x=0.0</code>, <code>y=0.0</code>, and <code>z=1.8</code>.</p> <p></p>"},{"location":"ros2_tutorials/rostopic/#ros2-topic-hz","title":"ros2 topic hz","text":"<p><code>ros2 topic hz</code> reports the rate at which data is published.</p> <p>Usage: <pre><code> ros2 topic hz [topic_name]\n</code></pre></p> <p>Let's see how fast the <code>turtlesim</code> node is publishing on <code>/turtle1/pose</code>: <pre><code> ros2 topic hz /turtle1/pose\n</code></pre> <pre><code>average rate: 62.247\n    min: 0.010s max: 0.022s std dev: 0.00257s window: 64\naverage rate: 62.513\n    min: 0.010s max: 0.022s std dev: 0.00209s window: 127\naverage rate: 62.439\n    min: 0.010s max: 0.022s std dev: 0.00201s window: 190\n</code></pre></p>"},{"location":"ros2_tutorials/rostopic/#review","title":"Review","text":"<ul> <li><code>ros2 topic</code>: a ros2 tool to interface with topics<ul> <li><code>ros2 topic list</code>: output a list of available topics</li> <li><code>ros2 topic type</code>: print a topic's type</li> <li><code>ros2 topic echo</code>: output messages from a topic</li> <li><code>ros2 topic pub</code>: publish a message to a topic</li> <li><code>ros2 topic hz</code>: print the average publishing rate to screen</li> </ul> </li> </ul>"},{"location":"ros2_tutorials/starting_nodes/","title":"Starting Nodes","text":""},{"location":"ros2_tutorials/starting_nodes/#environment-configuration","title":"Environment Configuration","text":"<p>Every time you open a new shell, before using any ROS2 command, you must source the setup files first:</p> <pre><code> source /opt/ros/jazzy/setup.bash\n</code></pre> <p>If you don\u2019t want to do this every time you open a new shell, you need to add the source command to your shell startup script:</p> <pre><code> echo \"source /opt/ros/jazzy/setup.bash\" &gt;&gt; ~/.bashrc\u201d\n</code></pre>"},{"location":"ros2_tutorials/starting_nodes/#runing-nodes","title":"Runing Nodes","text":"<p>A node isn't really much more than an executable executable file from a package. <code>ros2 run</code> allows you to use the package name to directly run a node within a package (without having to know the package path).</p> <p>Usage: <pre><code> ros2 run [package_name] [executable_name]\n</code></pre></p>"},{"location":"ros2_tutorials/starting_nodes/#starting-turtlesim","title":"Starting Turtlesim","text":"<p>According to the ROS2 website, \"Turtlesim is a lightweight simulator for learning ROS 2. It illustrates what ROS 2 does at the most basic level to give you an idea of what you will do with a real robot or a robot simulation later on.\" </p> <p>We can now run the <code>turtlesim</code> node in the <code>turtlesim</code> package. In a new terminal, we start <code>turtlesim</code> with:</p> <pre><code> ros2 run turtlesim turtlesim_node\n</code></pre> <p>You will see the turtlesim window (your turtle could look different but that's okay):</p> <p></p>"},{"location":"ros2_tutorials/starting_nodes/#renaming-nodes","title":"Renaming Nodes","text":"<p>Sometimes, you might want to give nodes a new name. Through remapping, you can change default node properties, including node names. </p> <p>For example, we can rename the <code>turtlesim</code> node with: <pre><code> ros2 run turtlesim turtlesim_node --ros-args --remap __node:=[new_name]\n</code></pre></p>"},{"location":"ros2_tutorials/starting_nodes/#tab-completion","title":"Tab Completion","text":"<p>NOTE: If you're using Zsh instead of Bash, see here.</p> <p>It can get tedious to type out an entire package or excutable name. For example, <code>turtle_teleop_key</code> is a fairly long name. Luckily, some ROS2 tools support TAB completion.</p> <p>Start by typing:  <pre><code> ros2 run tu&lt;now push the TAB key&gt;\n</code></pre></p> <p>After pushing the <code>TAB</code> key, the command line should fill out the rest: <code>turtlesim</code>. This works because <code>turtlesim</code> is currently the only ROS2 package that starts with \"tu\".</p> <p>Now try typing: <pre><code> ros2 run turtlesim t&lt;now push the TAB key&gt;\n</code></pre></p> <p>In this case, we have two excutable names that start with \"turtle\". The <code>TAB</code> key won't fill out the exutable name for us but should fill out the command line as much as possible: <pre><code>ros2 run turtlesim turtle\n</code></pre></p> <p>Try typing <code>TAB</code> twice and all the possible names should be listed:  <pre><code> ros2 run turtlesim turtle&lt;now push the TAB key TWICE&gt;\n</code></pre></p> <p>This should display all the ROS2 excutables in the <code>turtlesim</code> package that begin with \"turtle\": <pre><code> turtlesim_node     turtle_teleop_key  \n</code></pre></p> <p>On the command line you should still have: <pre><code> ros2 run turtlesim turtle\n</code></pre></p> <p>After adding an \"_\" after the name \"turtle\", press <code>TAB</code> again: <pre><code> ros2 run turtlesim turtle_&lt;now push the TAB key&gt;\n</code></pre></p> <p>There is only one excutable that starts with \"turtle_\" so you should see: <pre><code> ros2 run turtlesim turtle_teleop_key\n</code></pre></p>"},{"location":"ros2_tutorials/starting_nodes/#review","title":"Review","text":"<ul> <li><code>ros2 run [package_name] [executable_name]</code>: run a node from a given package</li> </ul>"},{"location":"ros2_tutorials/topic_remapping/","title":"Topic Remapping","text":"<p>A node isn't really much more than an executable file from a package, and topic remapping isn't much more than simply changing the names of node properties. In our Lesson 2: Starting Nodes, we've learned how to reassign the name of a node. In this tutorial, we're going to remap topics with command-line interface.</p> <p>Usage: <pre><code> ros2 run [package_name] [node_name] --ros-args --remap [from]:=[to]\n</code></pre></p>"},{"location":"ros2_tutorials/topic_remapping/#example-1-connecting-joy-and-turtlesim","title":"Example-1: Connecting Joy and Turtlesim","text":"<p>NOTE: If you don't have a joystick, you could skip this example and jump to Example-2 and Example-3.</p>"},{"location":"ros2_tutorials/topic_remapping/#example-1-prerequisites","title":"Example-1 Prerequisites","text":"<p>For this tutorial we will usethe <code>joy</code> package. Acquire a joystick and ensure the <code>joy</code> and <code>teleop_twist_joy</code> package are installed: <pre><code> sudo apt-get install ros-jazzy-joy\n sudo apt-get install ros-jazzy-teleop-twist-joy\n</code></pre></p> <p>Read about the \"joy\" package: ROS2 Joy Package and ROS Driver for Generic Linux Joysticks.</p> <p><code>joy</code> outputs the messages of type <code>sensor_msgs/msg/Joy</code>. <code>turtlesim</code> requires the input messages of type <code>geometry_msgs/msg/Twist</code>. In order for <code>joy</code> to send messages to <code>turtlesim</code> we need to be able to convert messages of type <code>sensor_msgs/msg/Joy</code> to <code>geometry_msgs/msg/Twist</code>.</p> <p>Let's take a look more in depth at the differences between the two message types. Try: <pre><code> ros2 interface show sensor_msgs/msg/Joy\n</code></pre> <pre><code># Reports the state of a joystick's axes and buttons.\n\n# The timestamp is the time at which data is received from the joystick.\nstd_msgs/Header header\n    builtin_interfaces/Time stamp\n        int32 sec\n        uint32 nanosec\n    string frame_id\n\n# The axes measurements from a joystick.\nfloat32[] axes\n\n# The buttons measurements from a joystick.\nint32[] buttons\n ```\n\nAnd try:\n``` bash\n ros2 interface show geometry_msgs/msg/Twist\n</code></pre> <pre><code># This expresses velocity in free space broken into its linear and angular parts.\n\nVector3  linear\n    float64 x\n    float64 y\n    float64 z\nVector3  angular\n    float64 x\n    float64 y\n    float64 z\n</code></pre></p> <p>As you can see, the contents (as well as type) of these two messages are fundamentally different, hence we need a node that can convert one to the other.</p> <p>The node we will use to convert <code>sensor_msgs/msg/Joy</code> messages to <code>geometry_msgs/msg/Twist</code> messages is teleop_twist_joy.</p> <p>In different terminals we run: <pre><code> ros2 run turtlesim turtlesim_node\n</code></pre></p> <pre><code> ros2 run joy joy_node\n</code></pre> <pre><code> ros2 run teleop_twist_joy teleop_node\n</code></pre> <p>Now try using the joystick to move the turtle around.  You'll notice that it doesn't work. Let's investigate this problem using rqt: <pre><code> rqt\n</code></pre></p> <p>You should see something similar to this: </p> <p>As seen above, all three nodes are running, but <code>teleop_twist_joy_node</code> is not communicating with <code>turtlesim</code>.  Let's look at what topic <code>teleop_twist_joy_node</code> is publishing on and <code>turtlesim</code> is subscribing to.</p> <p>Let's start with <code>teleop_twist_joy_node</code>: <pre><code> ros2 node info /teleop_twist_joy_node\n</code></pre> <pre><code>/teleop_twist_joy_node\n  Subscribers:\n    /joy: sensor_msgs/msg/Joy\n    /parameter_events: rcl_interfaces/msg/ParameterEvent\n  Publishers:\n    /cmd_vel: geometry_msgs/msg/Twist\n    /parameter_events: rcl_interfaces/msg/ParameterEvent\n    /rosout: rcl_interfaces/msg/Log\n  Service Servers:\n    /teleop_twist_joy_node/describe_parameters: rcl_interfaces/srv/DescribeParameters\n    /teleop_twist_joy_node/get_parameter_types: rcl_interfaces/srv/GetParameterTypes\n    /teleop_twist_joy_node/get_parameters: rcl_interfaces/srv/GetParameters\n    /teleop_twist_joy_node/get_type_description: type_description_interfaces/srv/GetTypeDescription\n    /teleop_twist_joy_node/list_parameters: rcl_interfaces/srv/ListParameters\n    /teleop_twist_joy_node/set_parameters: rcl_interfaces/srv/SetParameters\n    /teleop_twist_joy_node/set_parameters_atomically: rcl_interfaces/srv/SetParametersAtomically\n  Service Clients:\n\n  Action Servers:\n\n  Action Clients:seperately\n</code></pre></p> <p>It appears <code>teleop_twist_joy_node</code> is publishing on the <code>/cmd_vel</code> topic. Let's see what <code>turtlesim</code> is subscribing to:</p> <p><pre><code> ros2 node info /turtlesim\n</code></pre> <pre><code>/turtlesim\n  Subscribers:\n    /parameter_events: rcl_interfaces/msg/ParameterEvent\n    /turtle1/cmd_vel: geometry_msgs/msg/Twist\n  Publishers:\n    /parameter_events: rcl_interfaces/msg/ParameterEvent\n    /rosout: rcl_interfaces/msg/Log\n    /turtle1/color_sensor: turtlesim/msg/Color\n    /turtle1/pose: turtlesim/msg/Pose\n  Service Servers:\n    /clear: std_srvs/srv/Empty\n    /kill: turtlesim/srv/Kill\n    /reset: std_srvs/srv/Empty\n    /spawn: turtlesim/srv/Spawn\n    /turtle1/set_pen: turtlesim/srv/SetPen\n    /turtle1/teleport_absolute: turtlesim/srv/TeleportAbsolute\n    /turtle1/teleport_relative: turtlesim/srv/TeleportRelative\n    /turtlesim/describe_parameters: rcl_interfaces/srv/DescribeParameters\n    /turtlesim/get_parameter_types: rcl_interfaces/srv/GetParameterTypes\n    /turtlesim/get_parameters: rcl_interfaces/srv/GetParameters\n    /turtlesim/get_type_description: type_description_interfaces/srv/GetTypeDescription\n    /turtlesim/list_parameters: rcl_interfaces/srv/ListParameters\n    /turtlesim/set_parameters: rcl_interfaces/srv/SetParameters\n    /turtlesim/set_parameters_atomically: rcl_interfaces/srv/SetParametersAtomically\n  Service Clients:\nseperatelysim/action/RotateAbsolute\n  Action Clients:\n</code></pre></p> <p>Look at the \"Subscriber\" list. <code>turtlesim</code> is subscribing to <code>/turtle1/cmd_vel</code> instead of <code>/cmd_vel</code>. Let's shut the <code>turtlesim</code> and fix this problem by remapping the input of turtlesim to be <code>/cmd_vel</code>. <pre><code> ros2 run turtlesim turtlesim_node --ros-args --remap turtle1/cmd_vel:=cmd_vel\n</code></pre></p> <p>Now refresh your rqt. It should now look like: </p> <p>If you hold down the activation button (for Xbox 360 controllers it's the A button) and move the joystick you should be able to control your turtle! </p>"},{"location":"ros2_tutorials/topic_remapping/#example-1-summary","title":"Example-1 Summary","text":"<p>The <code>joy</code> package is for interfacing generic joysticks to ROS2. We want to use a joystick to control the turtle in <code>turtlesim</code>. However, <code>joy</code> outputs messages of type <code>sensor_msgs/msg/Joy</code>, and <code>turtlesim</code> requires input messages of type <code>geometry_msgs/msg/Twist</code>.</p> <p>Therefore, we need a special node <code>teleop_twist_joy</code> which is used for converting <code>sensor_msgs/msg/Joy</code> messages to <code>geometry_msgs/msg/Twist</code>.</p> <p>The <code>teleop_twist_joy_node</code> is publishing to the topic <code>/cmd_vel</code>. However, <code>turtlesim</code>, by default, is subscribing to the topic <code>/turtle1/cmd_vel</code>. Therefore, we need to remap the input topic of turtlesim to be <code>/cmd_vel</code> instead of <code>/turtle1/cmd_vel</code>.</p>"},{"location":"ros2_tutorials/topic_remapping/#example-2-controling-two-turtles-separately","title":"Example-2: Controling Two Turtles Separately","text":"<p>Run two <code>turtlesim</code> nodes and rename one of them as \"turtlesim2\": <pre><code> ros2 run turtlesim turtlesim_node\n</code></pre></p> <p>In a new terminal: <pre><code> ros2 run turtlesim turtlesim_node --ros-args --remap __node:=turtlesim2\n</code></pre></p> <p>In new terminals, run two <code>teleop_turtle</code> nodes: <pre><code> ros2 run turtlesim turtle_teleop_key\n</code></pre></p> <p>No matter which <code>teleop_turtle</code> node you're using, the two turtles always move the same way.  </p> <p>In a new terminal, use the <code>rqt</code> tool and we'll see why: <pre><code> rqt\n</code></pre> </p> <p>At this moment, both two <code>turtlesim</code> nodes are subscribing to the topic <code>/turtle1/cmd_vel</code> published by the <code>teleop_turtle</code> nodes. If we want to control two turtles separately, using two different <code>teleop_turtle</code> nodes, we need to remap the topics. Close one <code>turtlesim</code> node and one <code>teleop_turtle</code> node. Instead, we run: <pre><code> ros2 run turtlesim turtlesim_node --ros-args --remap __node:=turtlesim2 -r turtle1/cmd_vel:=turtle2/cmd_vel\n</code></pre></p> <p>In another terminal, run: <pre><code> roson__node:=telelop_turtle_2 -r turtle1/cmd_vel:=turtle2/cmd_vel\n</code></pre></p> <p>The <code>turtlesim2</code> node is now subscribing to the topic <code>/turtle2/cmd_vel</code> and the <code>teleop_turtle_2</code> node is publishing to this topic. Now you should be able to control the two turtles to do different movement.  </p> <p>In a new terminal, use the <code>rqt</code> tool and we'll see that the two <code>turtlesim</code> nodes are communicating with the <code>teleop_turtle</code> nodes through two different topics: <code>/turtle1/cmd_vel</code> and <code>/turtle2/cmd_vel</code>. <pre><code> rqt\n</code></pre> </p>"},{"location":"ros2_tutorials/topic_remapping/#example-2-summary","title":"Example-2 Summary","text":"<p>We're trying to control two <code>turtlesim</code> nodes separately with two <code>teleop_turtle</code> nodes, so we need two separate topics <code>/turtle1/cmd_vel</code> and <code>/turtle2/cmd_vel</code> for the communication between two pairs of nodes. </p> <p>The first <code>turtlesim</code> node subscribes to the topic <code>/turtle1/cmd_vel</code>, and the first <code>teleop_turtle</code> node publishes to this topic. The <code>turtlesim2</code> node subscribes to the topic <code>/turtle2/cmd_vel</code>, and the <code>teleop_turtle_2</code> node publishes to the same topic. </p>"},{"location":"ros2_tutorials/topic_remapping/#example-3-controlling-two-separate-turtles-in-one-window","title":"Example-3: Controlling Two Separate Turtles in One Window","text":"<p>If you'd love to try another example, you could go to the \"5 Use rqt\" and \"6 Remapping\" parts of the ROS2 official documentation \"Using turtlesim, ros2, and rqt\" and give a try to the /spawn service in the Service Caller of the rqt tool and practice on this remapping command: <pre><code> ros2 run turtlesim turtle_teleop_key --ros-args --remap turtle1/cmd_vel:=turtle2/cmd_vel \n</code></pre></p>"},{"location":"ros2_tutorials/assignments/10_L10-12_draw_a_star/","title":"Assignment 10: Draw a Star","text":"<p>Now it's time to get some experience building your own ROS node in both C++ and Python.  This assignment is intended to be more challenging than previous ones, and will probably require using knowledge gained from additional tutorials, lab mates, and/or online resources.</p> <ol> <li>First create a node using C++ which makes the turtle in TurtleSim draw a star when run.</li> <li>Then try again using Python instead of C++.</li> </ol> <p></p> <p>NOTE: The star doesn't have to be perfect.</p> <p>Hint: A useful tool for C++ might be the <code>rclcpp::Rate</code> class.  A useful tool for python might be the <code>rclpy.Rate</code> class, <code>rclpy.time</code> class and/or the <code>rclpy.duration</code> class.</p>"},{"location":"ros2_tutorials/assignments/11_L10-12_fuel/","title":"Assignment 11: Display/Publish Fuel Remaining","text":"<p>Now create a subscriber node which subscribes to the <code>turtle1/pose</code> topic and uses the information provided over this topic to publish remaining fuel.  Test your node thoroughly.</p>"},{"location":"ros2_tutorials/assignments/11_L10-12_fuel/#example","title":"Example","text":"<pre><code>[ INFO] [1441729129.808192832]: Fuel Remaining: 878.002\n[ INFO] [1441729129.824126911]: Fuel Remaining: 877.502\n[ INFO] [1441729129.840222084]: Fuel Remaining: 877.002\n[ INFO] [1441729129.856043631]: Fuel Remaining: 876.502\n[ INFO] [1441729129.872168505]: Fuel Remaining: 876.002\n[ INFO] [1441729129.888102265]: Fuel Remaining: 875.502\n[ INFO] [1441729129.904134376]: Fuel Remaining: 875.002\n[ INFO] [1441729129.920143881]: Fuel Remaining: 874.502\n</code></pre>"},{"location":"ros2_tutorials/assignments/12_L10-12_out_of_fuel/","title":"Assignment 12: Stop Turtlesim When Fuel Runs Out","text":"<p>Now modify your fuel-tracking node and teleop_twist_joy in order to get the turtle in turtlesim to stop moving when fuel runs out.</p> <p>Once you have completed this assignment you will have completed the main part of the MAGICC Lab's ROS Tutorials.</p>"},{"location":"ros2_tutorials/assignments/1_L1-3_node_running/","title":"Assignment 1: Running Nodes: Listener and Talker","text":"<p>Try to run these two nodes in two different terminal, and see what will happen.  <pre><code>ros2 run demo_nodes_py listener\n</code></pre></p> <pre><code>ros2 run demo_nodes_cpp talker\n</code></pre> <p>Then, explain the rqt graph below: </p> <ul> <li>We are running what nodes from what packages? </li> <li>The two nodes are communicating with each other through which topic? </li> <li>Which node is receiving messages and which node is sending messages through the topic? Which node is a \"subscriber\"? Which node is a \"publisher\"?</li> </ul>"},{"location":"ros2_tutorials/assignments/2_L1-3_turtlesim/","title":"Assignment 2: Turtlesim Assignment","text":"<p>Replicate the following scenario using the tools which you have learned in the two previous tutorials:</p> <p> </p> <ul> <li> <p>Note 1: /COUGAR1 and /COUGAR2 are renamed <code>turtlesim_node</code> (Lesson 2 for Node Renaming). /teleop_turtle is from the <code>turtle_telelop_key</code> node.</p> </li> <li> <p>Note 2: Choose \"Nodes only\" / \"Nodes/Topics (active)\" mode for the rqt tool, and you will see  different graphs.</p> </li> </ul> <p> </p>"},{"location":"ros2_tutorials/assignments/3_L4-5_creating_launch_file/","title":"Assignment 3: Launch Files","text":"<p>Use a single ros launch file to replicate the same scenario you created in Assignment 1.</p>"},{"location":"ros2_tutorials/assignments/4_L4-5_explaining_launch_file/","title":"Assignment 4: Launch Files","text":"<p>Use your own words to explain the two launch files:</p> <p>Two Turtles:</p> <pre><code># turtlesim/launch/multisim.launch.py\n\nfrom launch import LaunchDescription\nimport launch_ros.actions\n\ndef generate_launch_description():\n    return LaunchDescription([\n        launch_ros.actions.Node(\n            namespace= \"turtlesim1\", package='turtlesim', executable='turtlesim_node', output='screen'),\n        launch_ros.actions.Node(\n            namespace= \"turtlesim2\", package='turtlesim', executable='turtlesim_node', output='screen'),\n    ])\n</code></pre> <p>**Two-Turtle Mimicing:**https://docs.ros.org/en/jazzy/Tutorials/Demos/Logging-and-logger-configuration.html#logging</p> <pre><code>from launch import LaunchDescription\nfrom launch_ros.actions import Node\n\ndef generate_launch_description():\n    return LaunchDescription([\n        Node(\n            package='turtlesim',\n            namespace='turtlesim1',\n            executable='turtlesim_node',\n            name='sim'\n        ),\n        Node(\n            package='turtlesim',\n            namespace='turtlesim2',\n            executable='turtlesim_node',\n            name='sim'\n        ),\n        Node(\n            package='turtlesim',\n            executable='mimic',\n            name='mimic',\n            remappings=[\n                ('/input/pose', '/turtlesim1/turtle1/pose'),\n                ('/output/cmd_vel', '/turtlesim2/turtle1/cmd_vel'),\n            ]\n        )\n    ])\n</code></pre>"},{"location":"ros2_tutorials/assignments/5_L6_nodes_topics_and_messages/","title":"Assignment 5 - Nodes, Topics and Messages","text":"<ul> <li>Define nodes, topics, and messages in your own words.</li> <li>Using the command terminal, find the message type <code>turtlesim</code> needs to receive in order to move.</li> </ul>"},{"location":"ros2_tutorials/assignments/6_L7-9_more_launch_file1/","title":"Assignment 6: More Launch File Practice 1","text":"<p>According to what you've learned in Lesson 5: Launch Files and Lesson 7: Topic Remapping, create a launch file for turtlesim mimicing that can - launch three <code>turtlesim_node</code> - make two of the three <code>turtlesim_node</code> mimic the other one</p> <p>This rqt node graph is what you might get: </p>"},{"location":"ros2_tutorials/assignments/7_L7-9_more_launch_file2/","title":"Assignment 7: More Launch File Practice 2","text":"<p>According to what you've learned in Lesson 5: Launch Files and Lesson 7: Topic Remapping,  create a launch file that can: - launch four <code>turtlesim_node</code> - make turtlesim3 mimic turtlesim1; turtlesim4 mimic turtlesim2.</p> <p>In a new terminal, run: <pre><code> ros2 topic pub -r 1 /turtlesim1/turtle1/cmd_vel geometry_msgs/msg/Twist \"{linear: {x: 2.0, y: 0.0, z: 0.0}, angular: {x: 0.0, y: 0.0, z: -1.8}}\"\n</code></pre></p> <p>In a new terminal, run: <pre><code> ros2 topic pub -r 1 /turtlesim2/turtle1/cmd_vel geometry_msgs/msg/Twist \"{linear: {x: -4.0, y: 0.0, z: 0.0}, angular: {x: 0.0, y: 0.0, z: -1.8}}\"\n</code></pre></p> <p></p> <p>Run the rqt tool: <pre><code>rqt\n</code></pre> </p>"},{"location":"ros2_tutorials/assignments/8_L7-9_launch_file_advanced/","title":"Assignment 8: Creating a Launch File with Parameters and Topic Remapping","text":"<p>Replicate the following scenario using a single launch file. In addition, adjust <code>joy</code> so that messages publish at a rate of 10Hz when no messages are received. Do so within your launch file.</p> <p></p>"},{"location":"ros2_tutorials/assignments/9_L7-L9_edit_node/","title":"Assignment 9: Editing Teleop Twist Joy Node","text":"<p>Edit <code>teleop_twist_joy.cpp</code> so that you no longer need to press the enable button to move the turtle with the joystick.  Test your solution.</p>"},{"location":"ros2_tutorials/assignments/9_L7-L9_edit_node/#tips","title":"Tips:","text":"<ul> <li>Very little needs to be changed within the node in order to remove the enable button.  This is more of an exercise on navigating the code.</li> <li>This webpage may be useful in understanding the code more fully: ROS2 Joy Package and ROS Driver for Generic Linux Joysticks.</li> <li>Although not necessary for this assignment, this webpage can help you to understand the logging statements: Logging</li> </ul>"},{"location":"ros2_tutorials/mocap/mocap_tutorial/","title":"Motion Capture Tutorial","text":""},{"location":"ros2_tutorials/mocap/mocap_tutorial/#prerequisite","title":"Prerequisite","text":"<ol> <li> <p>Setting markers for the object you want to track</p> </li> <li> <p>Connect to the Magicc network</p> <p>Turn Between the lab conference room and the flight room (146A and 146C), there's a Netgear box used for the mocap system. To turn it on, press the power button marked \"MoCap\" that is under the desk. Pressing the wrong button might cause serious problems! And don't forget to turn it off when you're finished.</p> </li> <li> <p>Open Motive (can be found on the Windows desktop). Make sure Motive is not blocked by the firewall!</p> </li> </ol>"},{"location":"ros2_tutorials/mocap/mocap_tutorial/#tracking-the-vehicleobject","title":"Tracking the vehicle/object","text":"<ol> <li> <p>In the menu, select \"View -&gt; Assets Pane\".</p> </li> <li> <p>On the left sidebar check the boxes, and you should see the markers on the perspective view. Choose the markers you want to track. </p> <p>In this case, \"DemonstrationCopter\" is being tracked (containing four markers). </p> </li> </ol>"},{"location":"ros2_tutorials/mocap/mocap_tutorial/#data-collecting-with-ros","title":"Data Collecting with ROS","text":"<ol> <li>Download the vrpn_client_ros package.</li> </ol> <p>In the <code>src</code> of your workspace, run: <pre><code> git clone https://gitlab.magiccvs.byu.edu/lab/vrpn_client_ros2.git\n</code></pre></p> <p>And in your workspace, build the package: <pre><code> colcon build\n</code></pre></p> <ol> <li>Run the <code>vrpn_client_ros</code> node. <pre><code> ros2 run vrpn_client_ros vrpn_client_node \n</code></pre></li> </ol> <pre><code>[INFO] [1726270601.321879825] [vrpn_client_node]: Connecting to VRPN server at localhost:3883\n[INFO] [1726270602.324711875] [vrpn_client_node]: Connection established\n</code></pre> <ol> <li>The tracked object's pose information is publishing to your device through ROS topics. <pre><code> ros2 topic list\n</code></pre> <pre><code>/DemonstrationCopter/pose\n/DemonstrationCopter/pose_enu\n/DemonstrationCopter/pose_ned\n/parameter_events\n/rosout\n</code></pre> The topic <code>DemonstrationCopter_enu</code> publishes the pose in the ENU frame (East, North, Up), and the topic <code>DemonstrationCopter_ned</code> publishes the pose in the NED frame (North, East, Down).</li> </ol> <p><pre><code> ros2 topic echo /DemonstrationCopter_ned\n</code></pre> <pre><code>header:\n  seq: 1810\n  stamp:\n    secs: 1720634981\n    nsecs: 653036405\n  frame_id: \"optitrack_ned\"\npose:\n  position:\n    x: 0.557237863541\n    y: 3.70402407646\n    z: -1.14867293835\n  orientation: \n    x: -0.0940773898464\n    y: -0.711429558216\n    z: 0.676397042416\n    w: 0.165845259493\n---\n</code></pre></p>"},{"location":"ros2_tutorials/mocap/mocap_tutorial/#data-collecting-with-the-motive-record-function","title":"Data Collecting with the Motive Record Function","text":"<ol> <li> <p>Make sure you're under the LIVE mode. Click on the red recording button. Click on it again to end the recording.     </p> </li> <li> <p>Click on \"EDIT\" to switch to the EDIT mode. Select \"File -&gt; Export Tracking Data\", and save the file in the CSV format.     </p> <p>Your file should look like this: </p> </li> </ol>"},{"location":"ros2_tutorials/mocap/mocap_tutorial/#when-you-are-finished-be-sure-to-unplug-the-mocap-system-box-from-power","title":"When you are finished, be sure to unplug the mocap system box from power.","text":""},{"location":"sw_guides/airsim_quickstart/","title":"Quickstart Airism Guide","text":""},{"location":"sw_guides/airsim_quickstart/#using-only-precompiled-binaries","title":"(Using Only Precompiled Binaries)","text":"<p>This guide details the quickest way to get up and running using Airsim and its python API on Linux.  Please see the official Airsim documentation for more depth on how to utilize Airsim.</p> <p>There are four installation steps: 1. Download and extract a precomplied environment available on the Airsim Github repo.  My favorite is the Neighborhood Environment. 2. Download and extract the latest Airsim source code available on the Airsim Github repo.  Right now, this version 1.4.0. 3. Navigate to the Airsim source code directory and run <code>./setup.sh</code> followed by <code>./build.sh</code>. 4. (Note: Do not do this last step if you use Jupyter Notebooks or iPython.  We are working on a fix for this, but for now there is a breaking dependency conflict with these packages.  This can be avoided by using vitual python environments, which is more complex than this guide goes.)  Run <code>pip install Airsim</code>.</p> <p>You are now ready to run an Airsim simulation!  Below is an example python script for using Airsim for waypoint navigation.</p> <pre><code>import airsim\n\nclient = airsim.MultirotorClient()\nclient.confirmConnection()\nclient.enableApiControl(True)\nclient.armDisarm(True)\n\nwhile True:\n    in_coords = list(map(int,input(\"\\nEnter destination waypoint in NED cooridnates \").strip().split()))[:3]\n    print(\"Flying to ({},{},{}) at 5 m/s\".format(in_coords[0],in_coords[1],in_coords[2]))\n    # client.moveToPositionAsync(in_coords[0], in_coords[1], in_coords[2], 5) # This will set the multirotor on a path and imediately return\n    client.moveToPositionAsync(in_coords[0], in_coords[1], in_coords[2], 5).join() # This will block until the multirotor has reached its destination\n    in_char = input(\"Continue flying?  y/n \")\n    if in_char == 'y':\n        continue\n    elif in_char == 'n':\n        break\n\nclient.armDisarm(False)\nclient.reset()\nclient.enableApiControl(False)\n</code></pre> <p>In one terminal window run the executable buried deep in the precompiled environment's file structure.  For example, the neighborhood executable can be found at <code>&lt;path_to_your_download_location&gt;/Neighborhood/AirSimNH/Binaries/Linux/AirSimNH</code>.  Select multirotor when prompted.  In a seperate terminal window run the provided python script to control the simulated multirotor.</p> <p>That's it!  Refer to the official documentation for more in depth guides on utiziling all of Airsim's capabilities.</p>"},{"location":"sw_guides/airsim_quickstart/#extra-examples","title":"Extra Examples","text":"<p>As an aside, here are two more example python scripts for working with Airsim.  The first enables camera output to be fed into opencv (be sure to change the camera name from <code>0</code> to the camera name you have listed in the Airsim settings found in <code>~/Documents/AirSim/settings.json</code>).  </p> <pre><code>import numpy as np\nimport airsim\nimport cv2\n\nclient = airsim.MultirotorClient()\nclient.confirmConnection()\n\ncv2.namedWindow('image', cv2.WINDOW_NORMAL)\ninkey = 'a'\n\nwhile inkey != 27:\n    in_image = client.simGetImages([airsim.ImageRequest(\"0\", airsim.ImageType.Scene, False, False)])[0]\n    img1d = np.fromstring(in_image.image_data_uint8, dtype=np.uint8) # get numpy array\n    image = img1d.reshape(in_image.height, in_image.width, 3) # reshape array to 3 channel image array H X W X 3\n    cv2.imshow('image', image)\n    inkey = cv2.waitKey(1)\n\ncv2.destroyAllWindows()\n</code></pre> <p>The second implements basic keyboard control for the multirotor using the <code>keyboard</code> package (<code>pip install keyboard</code>, be sure to run this script as <code>sudo</code>)</p> <pre><code>import numpy as np\nimport airsim\nimport keyboard\n\nclient = airsim.MultirotorClient()\nclient.confirmConnection()\nclient.enableApiControl(True)\nclient.armDisarm(True)\n\nclient.takeoffAsync().join()\n\nprint('Multirotor Initialized')\nprint('Fly with the following controls')\nprint('w: forward')\nprint('s: backward')\nprint('a: left')\nprint('d: right')\nprint('left arrow: yaw left')\nprint('right arrow: yaw right')\nprint('up arraw: up')\nprint('down arrow: down')\nprint('hold left shift to go faster')\nprint('press esc to cancel flight and land')\n\nrunning = True\ncontrol_freq = 60 # control update frequency in hertz\ncontrol_period = 1/control_freq\nbase_speed = 15 \nbase_rotation_rate = 75 \nvelocity = np.array([0.0, 0.0, 0.0])\nheading = 0.0\nyaw_rate = 0.0\n\nwhile running:\n    state = client.getMultirotorState()\n    velocity[0] = 0.0\n    velocity[1] = 0.0\n    velocity[2] = 0.0\n    yaw_rate = 0.0\n    q = state.kinematics_estimated.orientation.to_numpy_array()\n    heading = np.arctan2(2.0*(q[2]*q[3] + q[0]*q[1]), \n                         q[0]*q[0] - q[1]*q[1] - q[2]*q[2] + q[3]*q[3])\n\n    if keyboard.is_pressed('esc'):\n        running = False\n        continue\n    else:\n        if keyboard.is_pressed('left_arrow'):\n            yaw_rate = -base_rotation_rate\n            client.rotateByYawRateAsync(yaw_rate, control_period)\n            continue\n        elif keyboard.is_pressed('right_arrow'):\n            yaw_rate = base_rotation_rate \n            client.rotateByYawRateAsync(yaw_rate, control_period)\n            continue\n        if keyboard.is_pressed('w'):\n            velocity[0] += np.cos(heading)\n            velocity[1] += np.sin(heading)\n        if keyboard.is_pressed('s'):\n            velocity[0] -= np.cos(heading)\n            velocity[1] -= np.sin(heading)\n        if keyboard.is_pressed('a'):\n            velocity[0] += np.sin(heading)\n            velocity[1] -= np.cos(heading)\n        if keyboard.is_pressed('d'):\n            velocity[0] -= np.sin(heading)\n            velocity[1] += np.cos(heading)\n        if keyboard.is_pressed('up_arrow'):\n            velocity[2] -= 1\n        if keyboard.is_pressed('down_arrow'):\n            velocity[2] += 1\n\n        norm = np.sqrt(np.sum(velocity**2))\n        if norm != 0.0:\n            velocity /= norm \n        velocity *= base_speed\n        if keyboard.is_pressed('left_shift'):\n            velocity *= 2\n        velocity[0] = (velocity[0]+state.kinematics_estimated.linear_velocity.x_val)/2\n        velocity[1] = (velocity[1]+state.kinematics_estimated.linear_velocity.y_val)/2\n\n        client.moveByVelocityAsync(velocity[0], velocity[1], velocity[2], control_period)\n\nclient.armDisarm(False)\nclient.reset()\nclient.enableApiControl(False)\n</code></pre>"},{"location":"sw_guides/airsim_settings/","title":"Airsim Settings","text":"<p>Airsim settings are stored in a json file. The settings control many aspects of the simulation: - Number and type of vehicles - Sensors on each vehicle - Simulation speed - etc.</p> <p>The most common settings are shown here. For full documentation on AirSim settings, visit the AirSim documentation.</p>"},{"location":"sw_guides/airsim_settings/#launching-airsim-with-a-settings-file","title":"Launching airsim with a settings file","text":"<p>To launch AirSim with a settings json file, specify it with the <code>--settings</code> flag. For example:</p> <p><code>./CityBlocks.sh --settings ~/airsim_settings.json -windowed</code></p> <p>(Note that some AirSim flags use single dashes, such as <code>-windowed</code>, and some use double dashes, such as <code>--settings</code>.)</p> <p>If the provided settings file is invalid or missing, it AirSim will launch with default settings and ask whether you want a car simulation or multirotor simulation.</p>"},{"location":"sw_guides/airsim_settings/#common-settings","title":"Common Settings","text":"<p>These are settings that you are likely to use at the MAGICC lab. For full documentation on AirSim settings, visit the AirSim documentation. There is a separate page for non-camera sensors. This is a wiki, please expand this page as you find information.</p>"},{"location":"sw_guides/airsim_settings/#simulator-settings","title":"Simulator Settings","text":""},{"location":"sw_guides/airsim_settings/#settingsversion","title":"SettingsVersion","text":"<p>All settings file must have a \"SettingsVersion\" field. For now, use <code>1.2</code>.</p>"},{"location":"sw_guides/airsim_settings/#clockspeed","title":"ClockSpeed","text":"<p>This allows you to slow down or speed up the simulation. This is particularly helpful if your computer is struggling with a complex simulation. This can increase the effective framerates of simulated cameras.</p>"},{"location":"sw_guides/airsim_settings/#viewmode","title":"ViewMode","text":"<p>This sets how the main viewport camera moves around. There are a number of options listed in the AirSim documentation. <code>SpringArmChase</code> is a good default; it will follow the vehicle around. By setting ViewMode to \"NoDisplay\", the main display of AirSim is made blank. This is useful for saving computing resources once you have the simulation set up the way you need it.</p>"},{"location":"sw_guides/airsim_settings/#wind","title":"Wind","text":"<p>Sets the wind for the simulation.</p>"},{"location":"sw_guides/airsim_settings/#recording","title":"Recording","text":"<p>AirSim has some built-in recording tools, which record vehicle pose and images. They do not record sensors without modifying the source code and rebuilding, and so recording from ROS may be more practical.</p>"},{"location":"sw_guides/airsim_settings/#vehicle-settings","title":"Vehicle Settings","text":"<p>AirSim supports any number of vehicles, and they can be a mix of types. When there is only one vehicle it is used by default, and when there are multiple vehicles methods referencing them must specify the vehicle.</p>"},{"location":"sw_guides/airsim_settings/#vehicletype","title":"VehicleType","text":"<p>There are three options for multirotors: <code>SimpleFlight</code>, <code>PX4Multirotor</code>, and <code>ArduCopter</code>. <code>SimpleFlight</code> uses the built-in controller to fly the vehicle and has a number of different control options. The others work with their respective software.</p> <p>This can also be set to <code>ComputerVision</code>, which disables all vehicle mechanics. The location of the \"vehicle\" can be set through the software API.</p> <p>This can also be set to <code>PhysXCar</code> or <code>Ardurover</code>. These are cars, which are like drones that don't fly.</p>"},{"location":"sw_guides/airsim_settings/#cameras","title":"Cameras","text":"<p>See below.</p>"},{"location":"sw_guides/airsim_settings/#x-y-z-roll-pitch-yaw","title":"X, Y, Z, Roll, Pitch, Yaw","text":"<p>This sets the initial location and attitude of the vehicle. The origin is also set to this location. The coordinate frame is note rotated by roll, pitch, or yaw.</p>"},{"location":"sw_guides/airsim_settings/#camera-settings","title":"Camera Settings","text":"<p>Note that in AirSim cameras are configured separately from other sensors. Each vehicle can have as many cameras as you want. Many of the important settings are under <code>CaptureSettings</code>.</p>"},{"location":"sw_guides/airsim_settings/#capturesettingsimagetype","title":"CaptureSettings.ImageType","text":"<p>Airsim supports several types of cameras. Normal cameras are <code>0</code> or scene cameras. Other options include depth and IR cameras and segmentation view.</p>"},{"location":"sw_guides/airsim_settings/#capturesettingswidth-capturesettingsheight","title":"CaptureSettings.Width, CaptureSettings.Height","text":"<p>Size in pixels.</p>"},{"location":"sw_guides/airsim_settings/#capturesettingsfov_degrees","title":"CaptureSettings.FOV_Degrees","text":"<p>This sets the horizontal field of view of the camera. The conversion between FOV and focal length is</p>  FOV = 2tan^{-1}(\\frac{w}{2f})  <p>. Note that you can't convert between horizontal and vertical FOV by dividing by the image aspect ratio (For example, to simulate a rotated camera). Instead convert to focal length and back.</p>"},{"location":"sw_guides/airsim_settings/#gimbal","title":"Gimbal","text":"<p>The gimbal settings enable image stabilization in any or all axes.</p>"},{"location":"sw_guides/airsim_settings/#x-y-z-roll-pitch-yaw_1","title":"X, Y, Z, Roll, Pitch, Yaw","text":"<p>These set the pose of the camera w.r.t. the vehicle. By default, the camera is at the center of the vehicle, facing forward. Through the magic of computer graphics, the vehicle is transparent from the inside, but parts of the vehicle (quadrotor landing gear) may be visible if you don't move the camera.</p>"},{"location":"sw_guides/airsim_settings/#sensor-settings","title":"Sensor Settings","text":"<p>Multirotors come with an IMU by default. Adding an IMU manually allows you to specify noise settings. Available sensors are: barometer, IMU, GPS, magnetometer, distance sensor, and lidar.</p>"},{"location":"sw_guides/airsim_settings/#imu","title":"IMU","text":"<p>Note that AirSim uses continuous noise and drift parameters for the IMU, rather than discrete noise parameters, and so you will have to convert.</p>"},{"location":"sw_guides/ceres_solver/","title":"Intro to Ceres Solver","text":"<p>This is a tutorial put together by James Jackson to introduce the Ceres Solver, a powerful open source nonlinear optimization toolkit.</p>"},{"location":"sw_guides/install_cuda/","title":"Installing CUDA","text":""},{"location":"sw_guides/install_cuda/#background","title":"Background","text":"<p>The CUDA toolkit is Nvidia's GPGPU API and parallel computing platform. If you have an Nvidia graphics card, and you want to create and/or use a deep neural network (\"ai\"), or you want to quickly process imagery (OpenCV), you'll want to use libraries that can incorporate the CUDA API.</p>"},{"location":"sw_guides/install_cuda/#requirements","title":"Requirements","text":"<p>Depending on which version of CUDA you want to use and which architecture your GPU was built on, you need to first have a compatible Nvidia driver installed. As of the time of this writing, CUDA 10.1 requires the &gt;=418.39. The table on the docs.nvidia.com website shows the Pascal architecture (on which the GTX 1050 Ti is built) can be paired with various driver versions. Make sure you verify your system architecture and use the correct table at the above link to ensure a compatible and functional setup.</p>"},{"location":"sw_guides/install_cuda/#installation","title":"Installation","text":"<p>We assume you are using the Ubuntu OS on an X86 processor for this guide. JetPack will install the CUDA toolkit on the TX2. If you have a different machine architecture with a CUDA-enabled GPU, well, good luck. Google is your friend. Just do me a favor, and don't install CUDA 9.x at this point if you can avoid it. Do not use Python 2.x, either. It has been long enough; convert all your scripts to Python 3.x. Ok, I'm off my soapbox now.</p>"},{"location":"sw_guides/install_cuda/#driver","title":"Driver","text":"<ul> <li>Add the <code>graphics-drivers-ppa</code> to your system: <pre><code>sudo add-apt-repository ppa:graphics-drivers/ppa\nsudo apt update\n</code></pre></li> </ul>"},{"location":"sw_guides/install_cuda/#cuda","title":"CUDA","text":"<ul> <li>Download the CUDA <code>*.deb</code> file from the nvidia.com website<ul> <li>Select the Operating System, Architecture, Distribution, and Version</li> </ul> </li> <li>On Ubuntu 18.04 and above, you can <code>cd</code> to the location of the <code>*.deb</code> and install with: <pre><code>sudo apt install ./&lt;file_name&gt;.deb\n</code></pre> or by using <code>dpkg</code> <pre><code>sudo dpkg -i &lt;file_name&gt;.deb\nsudo apt install -f\n</code></pre></li> <li> <p>Your terminal output will give you the appropriate command to add the public CUDA GPG key with a command similar to the following: <pre><code>sudo apt-key add /var/cuda-repo-10-1-local-10.1.168-418.67/7fa2af80.pub\n</code></pre> You need to copy the specific one from your terminal output and run it.</p> </li> <li> <p>Update your local repos:  <pre><code>sudo apt update\n</code></pre></p> </li> <li>Finish installing CUDA:  <pre><code>sudo apt install cuda\n</code></pre></li> <li>Reboot your machine</li> </ul> <p>The installation will create two directories in <code>/usr/local</code>, one is <code>cuda</code> and another is <code>cuda-&lt;version&gt;</code>. The <code>cuda</code> directory is a symbolic link to the <code>cuda-&lt;version&gt;</code> directory.</p> <ul> <li>Add <code>/usr/local/cuda/bin</code> to your PATH environment variable by adding the following line to your <code>.bashrc</code> or equivalent: <pre><code>export PATH=/usr/local/cuda/bin:$PATH\n</code></pre></li> <li>Run <code>source ~/.bashrc</code>, open a new terminal window, or reboot</li> <li>Congratulations, you now have CUDA installed</li> </ul> <p>For the happy couple.</p> <p></p>"},{"location":"sw_guides/install_cuda/#up-keep","title":"Up-Keep","text":"<p>When future driver versions/updates are released by the ppa, just double check that the driver being used is correct after a reboot. According to this Nvidia page, you should be able to select a newer driver number without having to update CUDA.</p> <p>To update CUDA, download the newest <code>*.deb</code> file, install, and double check the <code>/usr/local/cuda</code> directory correctly sym-links to the new <code>/usr/local/cuda-&lt;version&gt;</code> directory. If it does not, update the sym-link. From there, the line you added to your <code>~/.bashrc</code> should not need editing. Just perform a reboot. You may also need to run <code>sudo ldconfig</code>, but this is untested at this time.</p>"},{"location":"sw_guides/install_cuda/#_1","title":"Installing CUDA","text":""},{"location":"sw_guides/mocap_room_tutorial/","title":"Motion Capture Room Tutorial","text":"<p>This tutorial gives basic information on how to collect data, set markers, and calibrate the motion capture room (mocap room). If more information is needed or any recommendations need to be made speak with the students responsible for the mocap room. They can be found in the lab duties section of the magicc lab wiki, and their duties include training operators, documentation, maintenance, calibration, and upgrade recommendations.</p>"},{"location":"sw_guides/mocap_room_tutorial/#collecting-data","title":"Collecting Data","text":"<ol> <li> <p>The mocap system software is set up on the windows computer between the flight room and the conference room. Near the computer is a gray Netgear box that is used for the mocap system. Plug in the power to that box.</p> </li> <li> <p>Open the program Motive, which can be found on the desktop. Circular lights on the mocap cameras around the lenses should come on soon after you open the program.</p> </li> <li> <p>In the view tab, select the assets pane.</p> </li> <li> <p>Be sure that an appropriate calibration is being used. This is usually the most recent calibration. This can be done by going to file/open and then selecting the calibration file, which is usually saved to the Desktop. Alternatively, the most recent calibrations used can be found near the bottom of the file tab. A new calibration should be done every month or two. The students assigned to the mocap room should periodically do this, but if you need to do the calibration see the section in this document on calibration.</p> </li> <li> <p>If the markers for your vehicle(s) or object(s) have already been set, check the box of each object of interest. You should see the markers on the perspective view. If they have not been set, refer to the setting markers section of this document.</p> </li> <li> <p>In the devices pane, it is suggested to change the camera frame rate to 100 Hz to reduce network congestion.</p> </li> <li> <p>Start a roscore on your device.</p> </li> <li> <p>(This step requires that the <code>optitrack_vrpn</code> package and <code>vrpn</code> library are installed. If you have not installed those, see the instructions below). Be sure that both the windows computer and your device are connected to the Magicc network. Open a seperate terminal and type the command <pre><code>rosrun optitrack_vrpn node\n</code></pre></p> </li> <li> <p>ROS topics will be published to your device with the object's pose. The topic <code>&lt;marker name&gt;_ned</code> publishes the pose in the NED frame, and the topic <code>&lt;marker name&gt;_enu</code> publishes the pose in the ROS standard ENU frame. These NED and ENU frames are mapped from Motive's native frame, which is X north, Y up, and Z east.</p> </li> <li> <p>When you are finished be sure to unplug the mocap system box from power.</p> </li> </ol>"},{"location":"sw_guides/mocap_room_tutorial/#setting-markers","title":"Setting Markers","text":"<ol> <li> <p>Place the markers, reflective balls, on your vehicle or object in an asymmetric pattern. This requires at least 4 markers. Also be sure that all of the markers are easy to see and not hidden by the object's physical features. Avoid touching the balls with your fingers, as the oil will impede their detection. Each marker is worth about $5 so be careful. Currently, the markers and their adhesives can be found in a box in the flight room in the far corner white cabinet.</p> </li> <li> <p>Follow steps 1-4 in the collecting data section of this document.</p> </li> <li> <p>By default, Motive will place the origin frame at the centroid of the markers, with the axes aligned with the room axes. Place the object in the middle of the mocap room to be easily seen, and lined up with the room's axes. Some orange points represent markers and should be seen in the perspective view. Select all of the markers for your object, right click one of them, and under rigid body select 'create from selected markers'. If necessary, refine the origin or orientation of the marker set in the \"Edit\" tab on the left pane.</p> </li> <li> <p>As always, be sure to unplug the power from the mocap system box.</p> </li> </ol>"},{"location":"sw_guides/mocap_room_tutorial/#calibration","title":"Calibration","text":"<ol> <li> <p>Follow steps 1-2 in the collecting data section of this document.</p> </li> <li> <p>Select the layout drop down menu and then select calibrate.</p> </li> <li> <p>Take all of the markers out of the room. The camera preview windows can help you see if you have missed any. One helpful tool in determining where missed markers are is the video type grayscale. This mode will help you to see other objects near the markers. You can switch to it on a specific camera by right clicking one of the camera preview windows, expanding the Video Type menu, and then selecting grayscale mode.</p> </li> <li> <p>Once you are sure that everything is out, hit the clear mask button. After clearing the mask, check each camera to make sure no other markers are visibile. It is possible for markers outside of the mocap room to be seen by the cameras.</p> </li> <li> <p>Next hit the mask visible button. This will mask pixels in each camera that pick up reflective surfaces (that aren't dots) in the mocap room.</p> </li> <li> <p>The next step is to start wanding. To do this, there is a wand in the white cabinets in the flight room as well as a rod that can be attached to it to improve your reach. This wand has 3 markers on it that are used to \"paint\" the entire view of the cameras; this is called wanding. To start, hit the start wanding button. The camera preview windows will change to show the areas you have \"painted\" over.</p> </li> <li> <p>Begin covering the entire mocap room with the wand. A good method is to start by waving the wand through each part of the room without really referencing the camera preview windows. Try to move your body so that you are not always blocking off a specific camera from the view of the wand. This should give you a good starting point covering. Then look at the cameras' circular lights. The areas that have been covered are blue, while the uncovered areas not lit up. Try to fill all of the cameras. Then finally, look at the camera preview windows and fill in the spots that have not been covered.</p> </li> <li> <p>When finished, press the calculate and then apply buttons. A window should pop up telling you what the quality of the coverage on this calibration is. It should be excellent. Below is an example of excellent coverage:  <li> <p>Now you need to set the ground plane. The ground plane is also contained in the white cabinets in the mocap room. Place the ground plane on the marked origin in the room. Place the x axis facing the North wall.</p> </li> <li> <p>Switch over to the ground plane on the camera calibration window. There should be default values of 19 mm for the ground plane calibration square vertical offset and 6 mm for the ground plane refinement vertical offset. After verifying these values press set ground plane. This will bring up an export camera calibration window. The default should already have this format, but the naming convention is as shown below. Also it is of a file type .cal. Be sure the date is correct. <pre><code>Calibration Exceptional (MeanErr 0.490 mm)2019-08-06 5.34pm\n</code></pre></p> </li> <li> <p>As always be sure to unplug the camera system.</p> </li>"},{"location":"sw_guides/mocap_room_tutorial/#vrpn-installation","title":"VRPN Installation","text":"<ol> <li> <p>Clone the following git repository into a catkin workspace and be sure to source it. https://github.com/byu-magicc/optitrack_vrpn</p> </li> <li> <p>It is likely that the vrpn dependency has not been installed. To install it input</p> </li> </ol> <pre><code>sudo apt install ros-noetic-vrpn\n</code></pre>"},{"location":"sw_guides/opencv/","title":"OpenCV with CUDA","text":"<p>Warning: Consider this guide as a list of suggestions and lessons learned rather than an exact pathway to get OpenCV installed. Your computer may be set up differently. You may have installed something that conflicts with one of the packages we reccommend installing. You may have a different use case. As such, consider these two tips: 1. Read through this entire guide before performing any actions. 2. Think before you type.</p> <p>In order to use OpenCV with CUDA-acceleration, you must compile OpenCV from source and tell CMake to include it when building.</p>"},{"location":"sw_guides/opencv/#building-opencv-from-source","title":"Building OpenCV from Source","text":"<ol> <li> <p>Install prerequisite packages required for cloning the latest OpenCV git repositories:</p> <pre><code>$ sudo apt install git curl\n</code></pre> </li> <li> <p>Download the OpenCV version you would like to install from the Releases tab of the OpenCV repo. The following installs the latest release of OpenCV from the github repo. To install an earlier version, replace \"$(curl --silent \"https://api.github.com/repos/opencv/opencv/releases/latest\" | grep '\"tag_name\":' | sed -E 's/.\"([^\"]+)\"./\\1/')\" with the desired version tag (e.g. 3.4.6)</p> <pre><code>$ cd ~/Downloads\n$ git clone https://github.com/opencv/opencv.git\n$ git clone https://github.com/opencv/opencv_contrib.git\n$ git clone https://github.com/opencv/opencv_extra.git\n$ cd opencv\n$ git checkout $(curl --silent \"https://api.github.com/repos/opencv/opencv/releases/latest\" | grep '\"tag_name\":' | sed -E 's/.*\"([^\"]+)\".*/\\1/')\n$ cd ../opencv_contrib\n$ git checkout $(curl --silent \"https://api.github.com/repos/opencv/opencv/releases/latest\" | grep '\"tag_name\":' | sed -E 's/.*\"([^\"]+)\".*/\\1/')\n$ cd ../opencv_extra\n$ git checkout $(curl --silent \"https://api.github.com/repos/opencv/opencv/releases/latest\" | grep '\"tag_name\":' | sed -E 's/.*\"([^\"]+)\".*/\\1/')\n$ cd ..\n</code></pre> </li> <li> <p>Install the following packages as prerequisites for building OpenCV with CUDA support. Note that we recommend installing <code>libvtk6-*</code> because ROS Melodic has a dependency on VTK 6. If you do not use ROS (i.e. if you do not have it installed), you can replace <code>libvtk6-*</code> with <code>libvtk7-*</code> in the following:</p> <p><pre><code>$ sudo apt install ccache cmake libopenblas-dev liblapacke-dev libjpeg-dev libtiff-dev libpng-dev libgtk2.0-dev libavcodec-dev libavformat-dev libswscale-dev libv4l-dev libatlas-base-dev gfortran libhdf5-serial-dev libeigen3-dev libeigen-stl-containers-dev libavresample-dev zlib1g libatlas3-base libatlas-base-dev liblapacke-dev libvtk6-jni libvtk6.3 libvtk6-dev libvtk6-java libopenjp2-tools libprotobuf-dev libgtkglext1-dev libdc1394-22-dev libtbb-dev libceres-dev libcaffe-cuda-dev libleptonica-dev coinor-libclp-dev libtesseract-dev tesseract-ocr libogre-1.9-dev ogre-1.9-tools ocl-icd-opencl-dev ocl-icd-libopencl1 opencl-headers clinfo ocl-icd-dev hdf5-tools pybind11-dev python-dev python3-dev python-pip python3-pip\n</code></pre> You may have an error installing one or more of these packages. If <code>apt</code> returns an error, <code>apt</code> will not install any of the packages after the package that errored, so make sure that all packages in this list get installed.</p> <p><pre><code>$ pip2 install --upgrade --user pip setuptools wheel\n$ pip3 install --upgrade --user pip setuptools wheel\n$ reboot\n</code></pre> You must reboot.</p> <p><pre><code>$ pip3 install --user ipython numpy scipy pybind11 pygame vtk matplotlib pyqt5 pyside2 pytesseract tesserocr jupyter gnupg\n$ pip3 install --user pyopencl\n</code></pre> If you need specific OpenCL features that are not provided by these packages, the following link may be informative (https://github.com/opencv/opencv/wiki/OpenCL-optimizations)</p> </li> <li> <p>Due to header file sourcing location issues with OpenBLAS, create a symlink for the BLAS header file in the appropriate path:</p> <p><pre><code>$ sudo ln -s /usr/include/x86_64-linux-gnu/cblas.h /usr/include/cblas.h\n</code></pre> 1. Similarly, create a symlink for the vtk binary</p> <pre><code>$ sudo update-alternatives --install /usr/bin/vtk vtk /usr/bin/vtk6 10\n</code></pre> </li> </ol> <p>Note: If you want to use the RealSense libraries with OpenCV, you need to first get the RealSense SDK from Intel's RealSense GitHub. For use with ROS, use our wiki page. Once the SDK is installed, add the following cmake flags between the <code>cmake</code> and the <code>..</code> at the end of the <code>cmake</code> command on the next step: <code>-DWITH_LIBREALSENSE=On \\</code> <code>-DLIBREALSENSE_INCLUDE_DIR=&lt;fill this in&gt; \\</code> <code>-DLIBREALSENSE_LIBRARIES=&lt;fill this in&gt; \\</code> <code>-Drealsense2_DIR=&lt;fill this in&gt; \\</code></p> <p>Note: If you are using a Python Virtual Environment (recommended), make sure you have activated the virtual environment before running <code>cmake</code>. Take a look at the PyImageSearch Tutorial. This does not provide instructions for building with CUDA, but it is a good, additional resource. As mentioned in step 3 of the tutorial, first install the NumPy package into your virtual environment before running <code>cmake</code>, as it is a requirement for working with Python and OpenCV.</p> <ol> <li> <p>Configure CMake (see below for some additional options you may want, you may need to check the paths for some of the components):</p> <pre><code>$ cd ~/Downloads/opencv\n$ mkdir build\n$ cd build\n$ cmake -DCMAKE_INSTALL_PREFIX=/usr/local/opencv \\\n            -DCMAKE_BUILD_TYPE=RELEASE \\\n            -DWITH_CUDA=ON \\\n            -DENABLE_FAST_MATH=1 \\\n            -DCUDA_FAST_MATH=1 \\\n            -DWITH_CUBLAS=1 \\\n            -DINSTALL_PYTHON_EXAMPLES=OFF \\\n            -DENABLE_PRECOMPILED_HEADERS=OFF \\\n            -DWITH_OPENMP=ON \\\n            -DWITH_NVCUVID=ON \\\n            -DOPENCV_EXTRA_MODULES_PATH=~/Downloads/opencv_contrib/modules \\\n            -DBUILD_opencv_cudacodec=OFF \\\n            -DPYTHON_DEFAULT_EXECUTABLE=$(which python3) \\\n            -DBUILD_USE_SYMLINKS=ON \\\n            -DBUILD_PERF_TESTS=OFF \\\n            -DBUILD_TESTS=OFF \\\n            -DBUILD_JAVA=OFF \\\n            -DBUILD_PROTOBUF=ON \\\n            -DBUILD_opencv_java_bindings_gen=OFF \\\n            -DBUILD_opencv_cnn_3dobj=OFF \\\n            -DWITH_GDAL=ON \\\n            -DWITH_CLP=ON \\\n            -DTesseract_INCLUDE_DIR=/usr/include/tesseract \\\n            -DTesseract_LIBRARY=/usr/lib/x86_64-linux-gnu/libtesseract.so \\\n            -DOpenBLAS_LIB=/usr/lib/x86_64-linux-gnu/openblas/libblas.so \\\n            -DWITH_OPENGL=ON \\\n            -DWITH_VULKAN=ON \\\n            -DPYTHON3_INCLUDE_DIR2=~/.local/include/python3.6m \\\n            ..\n$ cmake -DOPENCV_PYTHON3_VERSION=ON ..\n</code></pre> <p>In most cases you will also want to include the non-free OpenCV modules. These include algorithms that are free for personal and academic use, but require a license for commercial use, e.g. feature descriptors such as SURF and SIFT. Unless you have a specific reason not to (check the licenses, know your usage scenario), add them: <pre><code>-DOPENCV_ENABLE_NONFREE=ON \\\n</code></pre> Additional cmake flags to include for development computers (i.e. NOT Jetson TX* Devices): <pre><code>-DWITH_TBB=ON \\\n</code></pre> Note: the OPENCV_PYTHON3_VERSION flag will cause the build to fail if included in the initial cmake option list. It must be added during a second cmake configuration.</p> <p>Note: if you are on the TX1 it is likely that you will run out of storage space unless you have <code>-DENABLED_PRECOMPILED_HEADERS=OFF</code> set. See this OpenCV Building from Source for Tegra/CUDA tutorial for more flags/help.</p> <p>Make sure to check the output of that command and make sure the NVIDIA CUDA modules are all set. This includes the NVIDIA GPU arch, AKA, compute capability (see below). Also, you can use <code>ccmake</code> to visually check all the available CMake flags:</p> <pre><code>$ sudo apt install cmake-curses-gui\n$ ccmake .\n</code></pre> </li> </ol> <p>You will probably have errors of the following form as you run <code>cmake</code>: <pre><code>-- The imported target \"____\" references the file\n   \"_____\"\nbut this file does not exist.  Possible reasons include:\n* The file was deleted, renamed, or moved to another location.\n* An install or uninstall procedure did not complete successfully.\n* The installation package was faulty and contained\n   \"_____\"\nbut not all the files it references.\n</code></pre> You can reduce these errors by installing more packages or if the packages are installed, by tracking down the files and symlinking them to where <code>cmake</code> is looking for them. I was never able to get rid of all of them, specifically one concerning <code>vtkRendingPythonTkWidgets</code> and one concering <code>libopenjp</code> (OpenJPEG). I do not think either of these will actually cause issues. The core OpenCV libraries will still build.</p> <p>Note: The \"<code>vtkRendingPythonTkWidgets</code>\" warning may have something to do with installation of \"<code>tk</code>\", or \"<code>python-tk</code>\" or something like that from <code>apt</code>, or \"<code>vtk</code>\" or something similar from <code>pip</code>. If you find out the cause, please upstream the fix for the broader community's benefit and learning. Thanks!</p> <ol> <li> <p>Once everything is configured, go ahead and build and install:</p> <pre><code>$ make -j8\n$ sudo make install # alternatively, consider using checkinstall\n$ sudo ldconfig # update your shared library cache so ld knows about your new lib\n</code></pre> <p>The <code>-j8</code> flag tells CMake to use 8 threads. If you have an i7 processor, you probably have threading, so you can multiply the number of cores by 2. Otherwise, use <code>-j4</code> for a quadcore i5, for example. Also, if you are simultaneously running other cpu-intensive programs, you will likely want to lower the number to explicitly command how many threads to dedicate to CMake vs your other program(s).</p> <p>Note: The <code>make</code> process can take from 30-45 minutes, so go get a mug of meat. The build may spend a significant amount of time at \"[ 98%] Built target opencv_stitching\" (usually around 15-20 minutes). This is completely normal, just be patient.</p> </li> <li> <p>Finally add the INSTALL_DIR to the system PATH in your <code>.bashrc</code> (or equivalent): <pre><code>export PATH=/usr/local/opencv/bin:$PATH\n</code></pre></p> </li> <li> <p>and source it on the command line: <code>source .bashrc</code></p> </li> </ol> <p></p>"},{"location":"sw_guides/opencv/#compute-capability","title":"Compute Capability","text":"<p>You must select the correct \"compute capability\" for your platform. Failure to do so when building OpenCV can result in an error such as:</p> <pre><code>GPU API call (invalid device function)\n</code></pre> <p>The TX1 has a compute capability of 5.3 and TX2 has 6.2, as shown on Wikipedia. The take-home is that you must set the CMake variable <code>CUDA_ARCH_BIN</code> equal to that of the target device. Note that it may be possible to specify a list of target compute capabilities, e.g. <code>CUDA_ARCH_BIN=2.0 3.0 3.5 3.7 5.0 5.2 6.0 6.1</code></p> <p>More info can be found on the opencv repo</p>"},{"location":"sw_guides/opencv/#managing-multiple-opencv-versions-outside-of-ros","title":"Managing Multiple OpenCV Versions (outside of ROS)","text":"<p>When you have multiple versions of a given library, it is important to tell the linker which library to link to. Often, we use CMake to take care of finding libraries and building C/C++ code. In this case, we tell CMake where to find our new OpenCV lib. See this GitHub repo for a good (if I may say so myself) example. You can force CMake to know about your specific library by adding an environment variable before running cmake commands for your own code.</p> <pre><code>$ export OpenCV_DIR=/usr/local/share/OpenCV/\n</code></pre>"},{"location":"sw_guides/opencv/#more-on-opencv-with-python-virtual-environments","title":"More on OpenCV with Python virtual environments","text":"<p>Following the PyImageSearch Tutorial, you need to provide your Python virtual environment with the correct <code>cv2.so</code> binary. Refer to step 5 of the linked tutorial for more information, but for my install, the <code>cv2.so</code> file did not end up in the same place as in the tutorial.</p> <p>Here's the process I followed to create a symbolic link to the binary.</p> <p>Find the <code>cv2.cpython-36m-x86_64-linux-gnu.so</code> binary. (This binary name may be different depending on the python version you have). <pre><code>$ find /usr/ -name cv2\n</code></pre> This will (hopefully) return two different paths. Mine were:</p> <pre><code>/usr/local/opencv/lib/python3.6/site-packages/cv2\n/usr/local/opencv/lib/python2.7/dist-packages/cv2\n</code></pre> <p>Others have had <code>dist-packages</code> instead of <code>site-packages</code> or more than two paths here. You might need to poke around for a minute to figure out the path to <code>cv2.cpython-36m-x86_64-linux-gnu.so</code>. Assuming your paths were the same and you have python 3.6 installed, the binary is then in</p> <pre><code>/usr/local/opencv/lib/python3.6/site-packages/cv2/python-3.6/\n</code></pre> <p>Run the following, making sure to modify it if your paths were different. Make sure to replace <code>&lt;&lt;&lt;YOUR_VIRTUAL_ENV&gt;&gt;&gt;</code> with the name of your virtual environment.</p> <pre><code>sudo ln -s /usr/local/opencv/lib/python3.6/site-packages/cv2/python-3.6/cv2.cpython-36m-x86_64-linux-gnu.so ~/.virtualenvs/&lt;&lt;&lt;YOUR_VIRTUAL_ENV&gt;&gt;&gt;/lib/python3.6/site-packages/cv2.so\n</code></pre>"},{"location":"sw_guides/opencv/#using-your-newly-minted-opencv-with-ros","title":"Using Your Newly Minted OpenCV with ROS","text":"<p>ROS Kinetic (currently) packages OpenCV 3.2. In order to use your CUDA-enabled OpenCV version, you have to tell CMake, in no uncertain terms, from where to link OpenCV. Similarly to above, you can either point the environment variable <code>OpenCV_DIR</code> to your OpenCV cmake config location (likely <code>/usr/local/share/OpenCV</code>) or you can simply pass it to <code>catkin_make</code> as follows:</p> <pre><code>catkin_make -DOpenCV_DIR=/usr/local/share/OpenCV\n</code></pre> <p>Note that once you point <code>catkin_make</code> to your OpenCV install once, you can simply run <code>catkin_make</code> without passing the <code>-DOpenCV_DIR</code> option again. This is because it is saved in the CMake cache. You will need to add the option again if you delete the <code>devel</code> and <code>build</code> directories, of course. Remember that you can always check if that variable is set by running (inside of the <code>catkin_ws</code> directory):</p> <pre><code>ccmake build\n</code></pre> <p>Note that if any other packages require OpenCV (which is most of the time), catkin will also pull in the wrong dependencies. The solution to this problem is to add the vision_opencv package that provides <code>cv_bridge</code> into your <code>catkin_ws/src</code> directory. Then, when you build your packages with <code>catkin_make -DOpenCV_DIR=/usr/local/share/OpenCV</code>, the <code>vision_opencv</code> packages will also point to your CUDA-enabled OpenCV. And now your ROS code (inside your current <code>catkin_ws</code>) is using CUDA-enabled OpenCV!</p> <p>It can be helpful to be certain at runtime if you are linking to the correct OpenCV. This can be done with:</p> <p><pre><code>// Grab the install path of OpenCV\n  int s = cv::getBuildInformation().find(\"Install path:\");\n  int e = cv::getBuildInformation().find('\\n', s);\n  ROS_INFO(\"OpenCV %s\", cv::getBuildInformation().substr(s, e-s).c_str());\n#if OPENCV_CUDA\n  ROS_INFO(\"Visual MTT CUDA enabled with %i device(s).\", cv::cuda::getCudaEnabledDeviceCount());\n#endif\n</code></pre> Note that in this snippet we are also able to know at compile-time whether to use CUDA with OpenCV. For more details, see the <code>visual_mtt</code> repo.</p>"},{"location":"sw_guides/opencv/#understanding-opencv-cuda-development","title":"Understanding OpenCV / CUDA Development","text":""},{"location":"sw_guides/opencv/#common-errors-faqs","title":"Common Errors / FAQs","text":"<ol> <li>Errors with <code>ccache -- invalid option -E</code>. The CUDA compiler (nvcc) and ccache do not play well together, add the <code>-DCUDA_HOST_COMPILER=/usr/bin/g++</code> flag to the cmake command, as discussed here.</li> </ol>"},{"location":"sw_guides/opencv/#future-work","title":"Future Work","text":"<p>Further work may be done in the future to add additional feature capabilities to the OpenCV build. Below are notes regarding attempted implementation and troubleshooting of various features.</p> <p>While attempting to implement Python 3 functionality into the build, the manually-set option flags (found to be functional) and automatically-detected flags were recorded as follows:</p> <p><pre><code>\"manual\"\n-DPYTHON3_EXECUTABLE=/usr/bin/python3m\n-DPYTHON3_INCLUDE_DIR=/usr/include/python3.6m\n-DPYTHON3_LIBRARY=/usr/lib/x86_64-linux-gnu/libpython3.6m.so\n-DPYTHON3_PACKAGES_PATH=/usr/lib/python3/dist-packages\n</code></pre> <pre><code>\"automatic\"\n-DPYTHON3_EXECUTABLE=/usr/bin/python3\n-DPYTHON3_INCLUDE_DIR=/usr/include/python3.6m\n-DPYTHON3_LIBRARY=/usr/lib/x86_64-linux-gnu/libpython3.6m.so\n-DPYTHON3_PACKAGES_PATH=lib/python3.6/dist-packages\n</code></pre></p> <p>Typically the cmake compiler is able to successfully find the following directories. However, if cmake reports that it cannot be found, add the following option: <pre><code>-DPYTHON3_NUMPY_INCLUDE_DIRS=~/.local/lib/python3.6/site-packages/numpy/core/include\n</code></pre></p> <p>While trying to allow compatibility with OGRE, it was found that standard installation and linking to the following library did not work:</p> <pre><code>\"did not work\"\n-DOGRE_DIR=/usr/share/OGRE/cmake/modules\n</code></pre> <p>Other features that passed configuration errors during make include JASPER_LIBRARIES and JASPER_INCLUDE_DIR. The build also passed import errors for vtk and pvtk.</p>"},{"location":"sw_guides/opencv/#resources","title":"Resources","text":"<ul> <li> <p>Compiling OpenCV with CUDA Support</p> </li> <li> <p>ROS Kinetic and New OpenCV</p> </li> <li> <p>ROS Kinetic and OpenCV-CUDA</p> </li> </ul>"},{"location":"sw_guides/python/","title":"Python Know-how","text":"<p>Python is an excellent research and development tool because of its readability, intuitive syntax, and interactive ability. In addition, there is a plethora of popular 3<sup>rd</sup> party Python packages available for your procurement -- particularly for algorithm development and numerical computation.</p>"},{"location":"sw_guides/python/#tldr","title":"tl;dr","text":"<ul> <li>Use Python 3 when you can, but note that doing this is not really an option when creating ROS packages</li> <li>ROS uses Python 2.7, ROS2 will use Python 3</li> <li>Always use <code>pip</code> to install Python packages -- never use <code>sudo apt install ...</code>! (can make for messy paths)</li> <li>It is preferable to use <code>pip install &lt;package&gt; --user</code> over <code>sudo -H pip install &lt;package&gt;</code></li> <li>Do not install <code>anaconda</code>. It will probably make your life miserable (especially as a ROS user). Anaconda is nice for users who use Windows or who just want to start coding without learning about the Python ecosystem.</li> <li>Although you will often hear/read people refer to Python and <code>pip</code> without a version number, it is important to be aware of your system configuration and be specific when necessary. Always use the appropriate versions: <code>python3 main.py</code> or <code>pip3 install ... --user</code>.</li> <li>Virtual environments are good. But you probably won't see them used much in our ROS/research world.</li> </ul>"},{"location":"sw_guides/python/#python-versions","title":"Python Versions","text":"<p>At the time of this writing, there are commonly two versions of Python in use: versions <code>2.7.14</code> and <code>3.6.4</code>. This has historically (and probably currently) caused much heartache for seasoned and beginning Python developers alike. Further, Python does not really help itself with its use of <code>PYTHONPATH</code> and its package management. Because of this, it is important to be aware of the tools and commands for installing packages into their proper place. The aim of this article is to document what we've learned about best practices with using different Python versions on the same machine.</p>"},{"location":"sw_guides/python/#getting-started-with-python","title":"Getting Started with Python","text":"<p>On an Ubuntu 16.04 machine, system level <code>python</code> and <code>python3</code> will already be installed on your machine. Use <code>which</code> to see the path of the binary (i.e., <code>which python3</code>).</p> <p>Install <code>pip</code> with</p> <pre><code>$ sudo apt install python-pip # or python3-pip\n</code></pre> <p>Attention: This is the only exception for installing a Python thing with <code>apt</code></p> <p>Install <code>ipython</code> (interactive Python):</p> <pre><code>$ pip install ipython --user\n</code></pre> <p>Now, instead of using the <code>python</code> interpreter, you may wish to use the <code>ipython</code> interpreter. It has colors, autocomplete, history, and you can exit with just <code>exit</code> instead of <code>exit()</code>. Additionally, you can load a file and stop at the end of it with <code>ipython -i main.py</code>. This allows you to interact with the program state (i.e., variables, functions, etc) after it has run.</p>"},{"location":"sw_guides/python/#python-virtual-environments","title":"Python Virtual Environments","text":"<p>Because <code>pip</code> installs packages for all to see, it can become a hassle to deal with code that needs a specific version of a package -- especially if it is different than your system-wide install. Additionally, it can be unwieldy to have to communicate all your dependencies and their versions to run your package. To combat this, we use Python virtual environments, or <code>virtualenv</code>s for short. Using a <code>virtualenv</code> with <code>pip</code> allows one to create a <code>requirements.txt</code> file that can be easily installed into a new environment.</p> <p>Attention: A lot of times, this could be overkill for your project. Virtual environments are the right way to do it, but they may not help you graduate any sooner. Virtual environments are critical in the development/release life cycle of software as it helps keep your development and production environments the same. This fits very well with webservers, but not as well with robots and ROS.</p> <p>Note: that there are many different tools in the Python community (<code>virtualenv</code>, <code>pyenv</code>, <code>venv</code>, <code>pipenv</code>, etc). We limit this discussion to what seems to be the standard across the Python community: <code>virtualenv</code>. For a great executive summary, see SO: What is the difference between venv, virtualenvwrapper, etc?.</p> <p>To setup a <code>virtualenv</code>, we will install <code>virtualenvwrapper</code>, which contains a nice set of CLI extensions for the <code>virtualenv</code> package. For Python 2.7, the installation would look like:</p> <pre><code>$ pip install virtualenvwrapper --user\n</code></pre> <p>Then, add the following to your <code>~/.bashrc</code> file and resource (<code>. ~/.bashrc</code>):</p> <pre><code>export WORKON_HOME=$HOME/.virtualenvs\nexport VIRTUALENVWRAPPER_PYTHON=/usr/bin/python # python2 binary\nsource /home/plusk01/.local/bin/virtualenvwrapper.sh # python2 install\n</code></pre> <p>You can ensure that the paths are correct with commands like:</p> <pre><code>$ which python\n$ locate virtualenvwrapper # you may need to run sudo updatedb to refresh the file database\n</code></pre> <p>Now that everything is setup, run <code>pip list</code>. You should see a fair amount of packages listed. If the <code>virtualenv</code> is working correctly, those will be hidden once we create a new environment:</p> <pre><code>$ mkvirtualenv test # create an environment called 'test' &amp;&amp; automatically activates it\n(test) $ pip list # should show maybe 2 or 3 packages\n</code></pre> <p>Notice two things:</p> <ol> <li>There should be only 2 or 3 packages from <code>pip list</code> (unless you have ROS on your system, see below)</li> <li>The name of your <code>virtualenv</code> is prepended to your bash prompt (i.e., <code>(test)</code>).</li> </ol> <p>To exit your <code>virtualenv</code>, use <code>deactivate</code>. To activate it again, run <code>workon test</code> (tab complete).</p>"},{"location":"sw_guides/python/#ros-and-python","title":"ROS and Python","text":"<p>Because ROS pollutes the global Python namespace by adding its path to the <code>PYTHONPATH</code> (you know that line you add to your <code>~/.bashrc</code> when you install ROS? that is what does it), you will likely see a whole bunch of ROS specific Python packages when you <code>pip list</code> in your <code>virtualenv</code>. This is a shame, but most likely won't actually hurt anything.</p> <p>However, if you would like to gain the satisfaction of having a clean <code>pip list</code>, we can add a hook to remove ROS from the <code>PYTHONPATH</code> (or just comment out the ROS line in your <code>~/.bashrc</code>):</p> <ol> <li> <p>Add the following to the <code>~/.virtualenvs/test/bin/postactivate</code> hook:</p> <pre><code>export PYTHONPATH_TMP=`echo $PYTHONPATH`\nunset PYTHONPATH\n</code></pre> </li> <li> <p>Add the following to the <code>~/.virtualenvs/test/bin/postdeactivate</code> hook:</p> <pre><code>export PYTHONPATH=`echo $PYTHONPATH_TMP`\nunset PYTHONPATH_TMP\n</code></pre> </li> </ol>"},{"location":"sw_guides/python/#what-does-sudo-h-do","title":"What does <code>sudo -H</code> do?","text":"<p>It changes the home directory to be the current user, as opposed to <code>/root</code>. From the manual:</p> <pre><code>     -H, --set-home\n                 Request that the security policy set the HOME environment variable to the home directory specified by the target user's pass\u2010\n                 word database entry.  Depending on the policy, this may be the default behavior.\n</code></pre> <p>So, for example:</p> <pre><code>user@hostname:~$ echo $HOME $USER\n/home/user user\nuser@hostname:~$ sudo bash -c 'echo $HOME $USER'\n/home/user root\nuser@hostname:~$ sudo -H bash -c 'echo $HOME $USER'\n/root root\n</code></pre>"},{"location":"sw_guides/ublox_read/","title":"UBLOX_read Documentation","text":"<p>========================== This package allows any Linux computer to interact with the ZED-F9P module.</p> <p>UBLOX ZED-F9P hardware integration is found here.</p>"},{"location":"sw_guides/ublox_read/#key-features","title":"Key Features","text":"<ul> <li>Cross-platform support</li> <li>Runs headless in a terminal setting</li> <li>Optional ROS integration</li> </ul>"},{"location":"sw_guides/ublox_read/#terminology","title":"Terminology","text":"<p>Stationary Base assumes no movement and can thus provide a very stable global position, which translates to high-quality RTK corrections sent to the Rover. The Rover outputs positional data at 10 Hz.</p> <p>Moving Base is like a stationary base, but does not assume position is fixed. This generally results in heavier RTK computational solutions for the Rover. The Rover ouputs positional information at 5 Hz.</p> <p>Brover is a moving base which receives RTK corrections from a different base. While this approach helps increase the accuracy of the moving base, it places much more computational strain on the Brover, causing it to subsequently send less messages to its Rovers.</p> <p>Rover always has a Base that it listens to in order to receive RTK corrections. These corrections allow the Rover to compute its relative position to a Base with an extremely high degree of accuracy (standard deviations are around .025 m horizontally, and .1 m vertially)</p>"},{"location":"sw_guides/ublox_read/#communication-protocols","title":"Communication Protocols","text":"<p>The UBLOX GNSS module uses three distinct communication protocols</p> <ol> <li>[NMEA](#nmea-(National-Marine-Electronics-Association)</li> <li>[UBX](#ubx-(Ublox-Proprietary-Protocol)</li> <li>[RTCM](#rtcm-(Radio-Technical-Commission-for-Maritime-Services)</li> </ol>"},{"location":"sw_guides/ublox_read/#nmea-national-marine-electronics-association","title":"NMEA (National Marine Electronics Association)","text":"<p>See Section 4 of the Interface Description</p>"},{"location":"sw_guides/ublox_read/#ubx-ublox-proprietary-protocol","title":"UBX (Ublox Proprietary Protocol)","text":"<p>The computer configures settings on the UBLOX GNSS module via UBX protocol.</p> <p>The module sends messages containing GNSS data back to the computer via UBX protocol.</p> <p>These communications happen over a serial port.</p> <p></p> <p>Taken from UBLOX Interface Description: See Documentation and Citations</p>"},{"location":"sw_guides/ublox_read/#rtcm-radio-technical-commission-for-maritime-services","title":"RTCM (Radio Technical Commission for Maritime Services)","text":"<p>The UBLOX GNSS Base sends its GNSS data to the computer in RTCM format. The Base computer then sends this data to the Rover computer, which is then forwarded to the Rover module via the serial port. </p> <p>The Rover module then uses this information to calculate RTK corrections and achieve accurate relative position information. The relative position data is sent back to the Rover computer via the serial connections</p>"},{"location":"sw_guides/ublox_read/#non-ros-installation","title":"Non-ROS Installation","text":"<ol> <li><code>git clone https://github.com/byu-magicc/UBLOX_read.git</code></li> <li><code>cd UBLOX_read/</code></li> <li><code>git submodule update --init --recursive</code> </li> <li><code>mkdir build</code></li> <li><code>cd build/</code></li> <li><code>cmake ..</code></li> <li><code>make -j8</code></li> </ol>"},{"location":"sw_guides/ublox_read/#ros-installation","title":"ROS Installation","text":"<p>Given ROS is installed, 1. Make a catkin workspace if you don't already have one (<code>mkdir catkin_ws</code>) 2. <code>cd catkin_ws &amp;&amp; mkdir src</code> 3. <code>cd src &amp;&amp; git clone https://github.com/byu-magicc/UBLOX_read.git</code> 4. <code>cd UBLOX_read</code> 5. <code>git submodule update --init --recursive</code> 6. <code>cd ../.. &amp;&amp; catkin_make</code> 7. <code>source devel/setup.sh</code></p>"},{"location":"sw_guides/ublox_read/#ros-launch-files","title":"ROS Launch Files","text":"<p>Attention: Do not modify launch files in UBLOX_read. Only use them as templates for creating your own in a separate package.</p> <p>A single node corresponds to a single module. All nodes must specify 1. <code>serial_port</code>: Serial port to connect to the module from the the computer. Defaults to <code>/dev/ttyACM0</code> 2. <code>rover_quantity</code>: The number of rovers the computer must send GNSS data from the module to. 3. <code>local_host</code>/<code>local_host1</code>: The name of the computer on the network. Usually just <code>localhost</code> 4. <code>local_port</code>: A port number over which UDP communication will occur. See Communication Protocols</p> <p>Other optional parameters include 1. <code>rover_host</code>/<code>rover_host1</code>: The IP address of the Rover computer. 2. <code>rover_port</code>: The port number over which UDP communication will be received by the Rover computer. 3. <code>base_host</code>: The IP address of the Base computer from which the local computer recevies [RTCM](#rtcm-(Radio-Technical-Commission-for-Maritime-Services) correctional data. 4. <code>base_port</code>: The port number of the Base computer from which the [RTCM](#rtcm-(Radio-Technical-Commission-for-Maritime-Services) data was sent.</p> <p>Tip: Theoretically N number of rovers can be initialized to a single base by counting up from rover_host1 to rover_hostN, rover_port1 to rover_portN, and any other given param.</p>"},{"location":"sw_guides/ublox_read/#case-study-one-base-one-rover","title":"Case Study: One Base + One Rover","text":"<p>Attention: Do not modify these launch files. Only use them as templates for creating your own in a separate package.</p> <p> </p> <p>base.launch contains parameters for the base computer.</p> <p>rover.launch contains parameters for the rover computer.</p>"},{"location":"sw_guides/ublox_read/#case-study-one-base-two-rovers","title":"Case Study: One Base + Two Rovers","text":"<p>Attention: Do not modify these launch files. Only use them as templates for creating your own in a separate package.</p> <p> </p> <p>mult_rov_base.launch contains parameters for the base computer.</p> <p>mult_rov_rover1.launch contains parameters for the rover1 computer.</p> <p>mult_rov_rover2.launch contains parameters for the rover2 computer</p>"},{"location":"sw_guides/ublox_read/#case-study-one-base-one-brover-one-rover","title":"Case Study: One Base + One Brover + One Rover","text":"<p>Attention: Do not modify these launch files. Only use them as templates for creating your own in a separate package.</p> <p> </p> <p>chain_base.launch contains parameters for the base computer.</p> <p>chain_brover.launch contains parameters for the brover computer.</p> <p>chain_rover.launch contains parameters for the rover computer.</p>"},{"location":"sw_guides/ublox_read/#ros-messages","title":"ROS Messages","text":"<ul> <li>PosVelTime: GNSS Positional/Velocity Data given in LLA format with an accurate timestamp</li> <li>PosVelEcef GNSS Positional Data given in ECEF frame. (Velocity is copied from PosVelTime message)</li> <li>RelPos: RTK Corrected Relative Position of the module relative to its base (only output on rover)</li> <li>RelPosFlags: Flags from RelPos Message</li> <li>SurveyStatus: Information about Survey-in Parameters including current mean position accuracy (only outputs for a stationary base)</li> </ul>"},{"location":"sw_guides/ublox_read/#posveltime","title":"PosVelTime","text":"<p>GNSS Positional/Velocity Data given in LLA format with an accurate timestamp</p> Data Type Name Description Header header ROS Timestamp uint16 year Year (UTC) uint8 month Month, range 1..12 (UTC) uint8 day Day of month, range 1..31 (UTC) uint8 hour Hour of day, range 0..23 (UTC) uint8 min Minute of hour, range 0..59 (UTC) uint8 sec Seconds of minute, range 0..60 (UTC) int32 nano Fraction of second, range -1e9 .. 1e9 (UTC) uint32 tAcc Time accuracy estimate (UTC) uint8 valid Validity flags (see below ) uint8 fixType GNSSfix Type uint8 flags Fix status flags uint8 flags2 Additional flags uint8 numSV Number of satellites used in Nav Solution float64[3] lla lat, lon, altitude (deg, deg, m) float64 hMSL Height above mean sea level (m) float64 hAcc Horizontal accuracy estimate (m) float64 vAcc Vertical accuracy estimate (m) float64[3] velNED NED velocity (m/s) float64 gSpeed m/s Ground Speed (2-D) float64 headMot deg Heading of motion (2-D) float64 sAcc m/s Speed accuracy estimate float64 headAcc deg Heading accuracy estimate (both motion and vehicle) float64 pDOP Position DOP float64 headVeh deg Heading of vehicle (2-D)"},{"location":"sw_guides/ublox_read/#posvelecef","title":"PosVelEcef","text":"<p>GNSS Positional Data given in ECEF frame. (Velocity is copied from PosVelTime message)</p> Data Type Name Description Header header # Estimated ROS time at moment of measurement uint8 fix fix type, see below float64[3] lla deg, deg, m float64[3] position m, ECEF frame float64 horizontal_accuracy m float64 vertical_accuracy m float64[3] velocity m/s, ECEF frame float64 speed_accuracy m/s"},{"location":"sw_guides/ublox_read/#relpos","title":"RelPos","text":"<p>RTK Corrected Relative Position of the module relative to its base (only output on rover)</p> Data Type Name Description Header header ROS Timestamp uint16 refStationId Reference Station ID. Must be in the range 0..4095 float64[3] relPosNED NED component of relative position vector (m) float64 relPosLength Length of relative position vector (m) float64 relPosHeading Heading of the relative position vector. (rad) float64[3] relPosHPNED High precision NED, the measurment portion less than a mm. (m) float64 relPosHPLength High precision Length, the measurment portion less than a mm. (m) float64[3] accNED Accuracy of relative position North component (m) float64 accLength Accuracy of Length of the relative position vector (m) uint32 accHeading Accuracy of heading of the relative position vector (rad) uint32 flags See RelPosFlags float64[3] arrowNED Difference vector from one rover to the other. (m) float64 arrowLength Length of difference vector. (m) float64[3] arrowRPY Roll/Pitch/Yaw from rover1 to rover2 (rad)"},{"location":"sw_guides/ublox_read/#relposflags","title":"RelPosFlags","text":"<p>Flags from RelPos Message</p> <p></p> <p>Taken from UBLOX Interface Description: See Documentation and Citations</p>"},{"location":"sw_guides/ublox_read/#surveystatus","title":"SurveyStatus","text":"<p>Information about Survey-in Parameters including current mean position accuracy (only outputs for a stationary base)</p> Data Type Name Description Header header ROS Timestamp uint32 dur Passed survey-in observation time (s) float64[3] meanXYZ Current survey-in mean position ECEF coordinate frame cm uint32 meanAcc Current survey-in mean position accuracy mm uint32 obs number of position observations used during survey-in float64[3] meanXYZHP Current high-precision survey-in mean position ECEF coordinate frame 0.1_ mm (Range -99...+99) uint8 valid Survey-in postion validity flag, 1=valid, otherwise 0 uint8 active survey-in in progress flag, 1 = in-progress, otherwise 0"},{"location":"sw_guides/ublox_read/#configuration-key-ids","title":"Configuration Key IDs","text":"<p>Configurations in the ZED-F9P recevier are indexed by key IDs. These keys are always little endian and 4 bytes (32 bits) in length.</p> Bit # Meaning 0-7 (Byte 1) ID within Group 8-15 (Byte 2) Reserved 16-23 (Byte 3) Group 24-27 Reserved 28-30 Size of Configuration Value 31 Reserved <p>The size of Configuration Values is represented by bits 28-30 as follows:</p> # Size of Configuration Value # Size of Configuration Value 0x01 1 Bit (Uses 1 Byte to Store) 0x04 4 Bytes 0x02 1 Byte 0x05 8 Bytes 0x03 2 Bytes <p>Example: <code>CFG-RATE-MEAS</code> is key <code>0x30210001</code>. Its configuration value size identifier is given by second-to-left-most byte, which is <code>3</code>. This translates to 2 Bytes (see table above). Its group name is given by the middle word <code>RATE</code> This group corresponds to the ID <code>0x21</code>, which are digits 3-4 from the left. The next two digits <code>0x00</code> are reserved. The final two digits <code>0x01</code> represent the specific type within the group, in this case <code>MEAS</code>.</p> <p>Some keys function as wild cards that can mean more than one configuration.</p> Wild Card Key ID Group Wild Card Key ID Group 0x0fff0000 All 0x00c7ffff RINV 0x0024ffff GEOFENCE 0x0031ffff SIGNAL 0x00a3ffff HW (Hardware) 0x0064ffff SPI 0x0051ffff I2C 0x0079ffff SPIINPROT 0x0071ffff I2CINPROT 0x007affff SPIOUTPROT 0x0072ffff I2COUTPROT 0x0003ffff TMODE 0x0092ffff INFMSG 0x0005ffff TP 0x0041ffff ITFM 0x00a2ffff TXREADY 0x00deffff LOGFILTER 0x0052ffff UART1 0x0025ffff MOT 0x0073ffff UART1INPROT 0x0091ffff MSGOUT 0x0074ffff UART1OUTPROT 0x0014ffff NAVHPG 0x0053ffff UART2 0x0011ffff NAVSPG 0x0075ffff UART2INPROT 0x0093ffff NMEA 0x0076ffff UART2OUTPROT 0x0022ffff ODO 0x0065ffff USB 0x0021ffff RATE 0x0077ffff USBINPROT 0x0078ffff USBOUTPROT"},{"location":"sw_guides/ublox_read/#cfgvalget","title":"CfgValGet","text":"<p>Access configuration settings on the ZED-F9P module via [UBX protocol](#ubx-(Ublox-Proprietary-Protocol)</p>"},{"location":"sw_guides/ublox_read/#request","title":"Request","text":"<p>Template: <code>rosservice call /base/CfgValGet &lt;layer&gt; &lt;position&gt; &lt;keyID&gt; &lt;filepath&gt;</code> </p> <p><code>&lt;layer&gt;</code>: The layer to request configuration from. Usually 0</p> # Layer 0 RAM 1 BBR 2 Flash 7 Default <p><code>&lt;position&gt;</code>: How many key values to skip before responding. Usually 0</p> <p><code>&lt;keyId&gt;</code>: Key ID of the requested configuration value. May be in hexadecmial (prefix with <code>0x</code>), decimal (no prefix), or binary (prefix with <code>0b</code>) format.</p> <p><code>&lt;filepath&gt;</code>: Global path for writing the response to a text file. If the file does not exist, one is created. If the file already exists, its contents are overwritten by this service. Usually <code>''</code></p>"},{"location":"sw_guides/ublox_read/#specializations","title":"Specializations","text":"<p>CfgValGetAll: Gets every configuration setting from the module Template: <code>rosservice call /base/CfgValGetAll &lt;layer&gt; &lt;position&gt; &lt;filepath&gt;</code></p>"},{"location":"sw_guides/ublox_read/#response","title":"Response","text":"<p>The module returns a vector of Configuration Data, which is constructed as follows</p> <p>version     Always 1 layer       Layer data came from--matches request layer position    Number of key values skipped before output keyID       keyID returned keyName     Name of keyID returned data        Configuration Value</p> <p>The module also returns ack: The receiver acknowledged the request nack: The receiver did not acknowledge the request gotcfg: Received configuration value</p>"},{"location":"sw_guides/ublox_read/#cfgvaldel","title":"CfgValDel","text":"<p>Delete configuration settings. </p>"},{"location":"sw_guides/ublox_read/#request_1","title":"Request","text":"<p>Template: <code>rosservice call /base/CfgValDel &lt;layer&gt; &lt;keyID&gt;</code></p> <p><code>&lt;layer&gt;</code>: The layer to delete configuration from.</p> # Layer 2 BBR 4 Flash <p><code>&lt;keyID&gt;</code>: keyID of the configuration value to be deleted. May be in hexadecmial (prefix with <code>0x</code>), decimal (no prefix), or binary (prefix with <code>0b</code>) format.</p>"},{"location":"sw_guides/ublox_read/#response_1","title":"Response","text":"<p>The module returns ack: The receiver acknowledged the request (you may assume the configuration was deleted) nack: The receiver did not acknowledge the request (the configuration was not deleted)</p>"},{"location":"sw_guides/ublox_read/#cfgvalset","title":"CfgValSet","text":"<p>Set configuration settings.</p>"},{"location":"sw_guides/ublox_read/#request_2","title":"Request","text":"<p>Template: <code>rosservice call /base/CfgValGet &lt;layer&gt; &lt;keyID&gt; &lt;cfgData&gt;</code></p> <p><code>&lt;layer&gt;</code>: The layer to set configurations</p> # Layer 1 RAM 2 BBR 4 Flash <p><code>&lt;keyID&gt;</code>: keyID of the configuration value to be set. May be in hexadecmial (prefix with <code>0x</code>), decimal (no prefix), or binary (prefix with <code>0b</code>) format.</p> <p><code>&lt;cfgData&gt;</code>: The configuration is set to this value</p>"},{"location":"sw_guides/ublox_read/#response_2","title":"Response","text":"<p>The module returns ack: The receiver acknowledged the request (you may assume the configuration was set) nack: The receiver did not acknowledge the request (the configuration was not set)</p>"},{"location":"sw_guides/ublox_read/#cfgreset","title":"CfgReset","text":"<p>Resets the configurations on the module.</p>"},{"location":"sw_guides/ublox_read/#request_3","title":"Request","text":"<p>Template: <code>rosservice call /base/CfgReset &lt;uint16 navBbrMask&gt; &lt;uint8_t resetMode&gt;</code></p> <p><code>&lt;navBbrMask&gt;</code>: BBR sections to clear. </p> Special Codes Meaning 0x0000 Hot Start 0x0001 Warm Start 0xFFFF Cold Start <p></p> <p>Taken from UBLOX Interface Description: See Documentation and Citations</p> <p><code>&lt;resetMode&gt;</code>: Reset Type</p> # Reset Type 0 Immediate Hardware Reset (Watchdog triggered) 1 Controlled Software Reset 2 Controlled Software Reset (GNSS only) 4 Hardware Reset after shutdown 8 Controlled GNSS stop 9 Controlled GNSS start"},{"location":"sw_guides/ublox_read/#response_3","title":"Response","text":"<p>Responds with a translation of navBbrMask into boolean values</p>"},{"location":"sw_guides/ublox_read/#getversion","title":"GetVersion","text":"<p>Gets software and hardware versions of the module</p>"},{"location":"sw_guides/ublox_read/#response_4","title":"Response","text":"<p>string softwareVersion string hardwareVersion string[] extension contains extra information. See UBLOX Documentation for more details</p>"},{"location":"sw_guides/ublox_read/#ublox-documentation-and-citations","title":"UBLOX Documentation and Citations","text":"<ul> <li>Interface Description contains information about various messages from the module.</li> <li>Integration Manual</li> <li>Moving Base Application Note</li> <li>Data Sheet</li> <li>The Official UBLOX F9P Site contains more useful documents</li> </ul>"},{"location":"sw_guides/ublox_read/#credits","title":"Credits","text":"<p>A special thanks goes to  James Jackson, Matthew Rydalch, Taylor Pool: UBLOX_read Code Development</p>"},{"location":"sw_guides/vtol_airsim_qs_guide/","title":"VTOL AirSim Quickstart Guide","text":"<p>This guide is for running a simulation of a tiltrotor VTOL vehicle inside a prebuilt binary of the CityBlocks world - a custom world modified for AirSim by the MAGICC Lab. The driving script, complete with trajectory generation, controllers, and an AirSim client, is <code>geometric_control_airsim_sim.py</code>, located in the vtolsim repository.</p> <p>Here is what you will need to do to run the script <code>geometric_control_airsim_sim.py</code>:</p> <ol> <li>Download the latest CityBlocks zip archive here and unzip it to wherever you like</li> <li>Create a file at <code>~/Documents/AirSim/settings.json</code> - or modify it if it already exists - with the following settings (see the example <code>settings.json</code> below):<ul> <li><code>\"SimMode\": \"Vtol\"</code></li> <li>a vehicle with <code>\"VehicleType\": \"vtolsimple\"</code></li> </ul> </li> <li>Clone the BYU-MAGICC fork of Airsim somewhere - <code>git@github.com:byu-magicc/AirSim</code> or <code>https://github.com/byu-magicc/AirSim</code></li> <li>If you haven't already, create a python virtual environment specifically for AirSim (it will make everything simpler for AirSim)<ul> <li>e.g. <code>python -m venv ~/.virtualenvs/airsim</code></li> </ul> </li> <li>Activate your AirSim virtual environment<ul> <li>e.g. <code>source ~/.virtualenvs/airsim/bin/activate</code></li> </ul> </li> <li><code>cd</code> into <code>AirSim/PythonClient</code> and run <code>pip install -e .</code></li> <li>Now clone vtolsim: <code>git clone git@github.com:byu-magicc/vtolsim.git</code></li> <li><code>cd</code> into <code>controllers/geometric_control</code></li> <li>In another terminal session, start running <code>&lt;path to CityBlocks dir&gt;/LinuxNoEditor/CityBlocks.sh</code></li> <li>Now you can run <code>python geometric_control_airsim_sim.py</code> and it should fly the trajectory.</li> </ol>"},{"location":"sw_guides/vtol_airsim_qs_guide/#example-settingsjson","title":"Example <code>settings.json</code>:","text":"<pre><code>{\n  \"SettingsVersion\": 1.2,\n  \"SimMode\": \"Vtol\",\n  \"ClockSpeed\": 1.0,\n  \"LogMessagesVisible\": false,\n  \"Vehicles\": {\n    \"uav0\": {\n      \"VehicleType\": \"vtolsimple\"\n    }\n  }\n}\n</code></pre> <p>Notes:</p> <ul> <li>Lower the <code>ClockSpeed</code> setting if your machine is struggling to run vtolsim + AirSim.<ul> <li>e.g. <code>\"ClockSpeed\": 0.6</code> to run the simulation at 60% real time</li> </ul> </li> <li>Set <code>LogMessagesVisible: true</code> if you need that, but having it off is better for recording video.</li> </ul>"}]}